{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9586927,"sourceType":"datasetVersion","datasetId":5846557}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass GenerateC(nn.Module):\n    def __init__(self):\n        super(GenerateC, self).__init__()\n        \n    def forward(self, x):\n        mean = x[:, :128]  \n#         print(\"mean:\" , mean.shape)\n        log_sigma = x[:, 128:]\n#         print(\"logsigma:\", log_sigma.shape)\n        stddev = torch.exp(log_sigma)\n#         print(\"stdev shape:\",stddev.shape)\n        epsilon = torch.randn(mean.shape[0], mean.shape[1], device=mean.device)\n#         print(\"epsilon shape:\",epsilon.shape)\n        c = stddev * epsilon + mean\n        return c\n\nclass ConditionalAugmentation(nn.Module):\n    def __init__(self):\n        super(ConditionalAugmentation, self).__init__()\n        self.fc = nn.Linear(768, 256)  # Adjusted to 768 input and 256 output\n        self.lrelu = nn.LeakyReLU(0.2)\n        \n    def forward(self, x):\n        x = self.fc(x)\n        x = self.lrelu(x)\n        return x\n\nclass EmbeddingCompressor(nn.Module):\n    def __init__(self):\n        super(EmbeddingCompressor, self).__init__()\n        self.fc = nn.Linear(768, 256)  # Adjusted to 768 input and 256 output\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        x = self.fc(x)\n        x = self.relu(x)\n        return x\n\nclass Stage1Generator(nn.Module):\n    def __init__(self):\n        super(Stage1Generator, self).__init__()\n        self.fc1 = nn.Linear(768, 256)  # Adjusted to 768 input and 256 output\n        self.lrelu = nn.LeakyReLU(0.2)\n        self.generate_c = GenerateC()\n        \n        self.fc2 = nn.Linear(128 + 100, 128 * 8 * 4 * 4)  # Adjusted to 256 + 100\n        self.relu = nn.ReLU()\n        self.reshape = nn.Unflatten(1, (128 * 8, 4, 4))\n        \n        self.upconv1 = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(128 * 8, 512, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n        )\n        \n        self.upconv2 = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(512, 256, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU()\n        )\n        \n        self.upconv3 = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(256, 128, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU()\n        )\n        \n        self.upconv4 = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(128, 64, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n        \n        self.final_conv = nn.Conv2d(64, 3, kernel_size=3, padding=1, bias=False)\n        self.tanh = nn.Tanh()\n        \n    def forward(self, x1, x2):\n        x1= x1.squeeze(1)\n        x1=self.fc1(x1)\n        mean_logsigma = self.lrelu(x1)\n#         print(\"mean_logsigma shape:\", mean_logsigma.shape)\n        c = self.generate_c(mean_logsigma)\n#         print(\"c shape\",c.shape)\n        gen_input = torch.cat([c, x2], dim=1)\n#         print(\"shape after concatenate:\", gen_input.shape)\n        \n        x = self.fc2(gen_input)\n        x = self.relu(x)\n        x = self.reshape(x)\n        \n        x = self.upconv1(x)\n        x = self.upconv2(x)\n        x = self.upconv3(x)\n        x = self.upconv4(x)\n        x = self.final_conv(x)\n        x = self.tanh(x)\n        \n        return x, mean_logsigma\n\nclass Stage1Discriminator(nn.Module):\n    def __init__(self):\n        super(Stage1Discriminator, self).__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.LeakyReLU(0.2)\n        )\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2)\n        )\n        \n        self.conv3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2)\n        )\n        \n        self.conv4 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2)\n        )\n        \n        self.conv5 = nn.Conv2d(512, 64 * 8, kernel_size=1, stride=1)\n        self.batch_norm = nn.BatchNorm2d(64 * 8)\n        self.leaky_relu = nn.LeakyReLU(0.2)\n        \n        self.fc_embedding = nn.Linear(768, 512 * 4 * 4)\n        \n        self.conv5_convert = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0)\n        \n        self.flatten = nn.Flatten()\n        self.fc = nn.Linear(4 * 4 * 64 * 8, 1)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x1, x2):\n#         x1 is the image (generated or real one) x 2 is the text embedding\n        x = self.conv1(x1)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x2 = self.fc_embedding(x2)  # [batch_size, 512 * 4 * 4]\n        x2 = x2.view(x2.size(0), 512, 4, 4)\n#         print(x2.shape) \n\n        x2 = torch.cat([x, x2], dim=1)\n        \n        x2= self.conv5_convert(x2)\n        x2 = self.conv5(x2)\n        x2 = self.batch_norm(x2)\n        x2 = self.leaky_relu(x2)\n        x2 = self.flatten(x2)\n        x2 = self.fc(x2)\n        x2 = self.sigmoid(x2)\n        \n        return x2\n\nclass AdversarialModel(nn.Module):\n    def __init__(self, gen_model, dis_model):\n        super(AdversarialModel, self).__init__()\n        self.gen_model = gen_model\n        self.dis_model = dis_model\n        \n    def forward(self, x1, x2, x3):\n        x, mean_logsigma = self.gen_model(x1, x2)\n        self.dis_model.eval()\n        valid = self.dis_model(x, x3)\n        return valid, mean_logsigma\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T03:02:01.712332Z","iopub.execute_input":"2024-10-16T03:02:01.712654Z","iopub.status.idle":"2024-10-16T03:02:05.710872Z","shell.execute_reply.started":"2024-10-16T03:02:01.712619Z","shell.execute_reply":"2024-10-16T03:02:05.709927Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def KL_loss(y_pred):\n    # Extract mean and log_sigma from y_pred\n    mean = y_pred[:, :128]\n    log_sigma = y_pred[:, 128:]\n    \n    # Compute the KL divergence loss\n    loss = -log_sigma + 0.5 * (-1 + torch.exp(2. * log_sigma) + mean**2)\n    \n    # Average the loss over all elements\n    loss = loss.mean()\n    \n    return loss\n\ndef custom_generator_loss(y_true, y_pred):\n    # Create loss function\n    criterion = nn.BCEWithLogitsLoss()\n    \n    # Calculate binary cross-entropy loss\n    return criterion(y_pred, y_true)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T03:02:05.712539Z","iopub.execute_input":"2024-10-16T03:02:05.713063Z","iopub.status.idle":"2024-10-16T03:02:05.720967Z","shell.execute_reply.started":"2024-10-16T03:02:05.713026Z","shell.execute_reply":"2024-10-16T03:02:05.718948Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef save_rgb_img(img, path):\n    \"\"\"\n    Save an RGB image.\n    Args:\n        img (numpy.ndarray): Image to save. Shape should be (H, W, C).\n        path (str): Path to save the image.\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    \n    # Convert PyTorch tensor to numpy array if necessary\n    if isinstance(img, torch.Tensor):\n        img = img.detach().permute(1, 2, 0).cpu().numpy()  # Convert CHW to HWC and move to CPU\n    \n    ax.imshow(img)\n    ax.axis(\"off\")\n    ax.set_title(\"Image\")\n\n    plt.savefig(path)\n    plt.close()\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T03:02:05.722958Z","iopub.execute_input":"2024-10-16T03:02:05.723345Z","iopub.status.idle":"2024-10-16T03:02:05.751891Z","shell.execute_reply.started":"2024-10-16T03:02:05.723303Z","shell.execute_reply":"2024-10-16T03:02:05.750922Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\n\ndef write_log(writer, name, loss, global_step):\n    \"\"\"\n    Write training summary to TensorBoard.\n    Args:\n        writer (SummaryWriter): TensorBoard writer object.\n        name (str): The name of the summary.\n        loss (float): The loss value to log.\n        global_step (int): The global step value.\n    \"\"\"\n    writer.add_scalar(name, loss, global_step)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T03:02:05.753824Z","iopub.execute_input":"2024-10-16T03:02:05.754161Z","iopub.status.idle":"2024-10-16T03:02:20.316786Z","shell.execute_reply.started":"2024-10-16T03:02:05.754129Z","shell.execute_reply":"2024-10-16T03:02:20.315751Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Discriminator loss\ndef wasserstein_discriminator_loss(real_preds, fake_preds):\n    return torch.mean(fake_preds) - torch.mean(real_preds)\n\n# Generator loss\ndef wasserstein_generator_loss(fake_preds):\n    return -torch.mean(fake_preds)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T03:02:20.318475Z","iopub.execute_input":"2024-10-16T03:02:20.319030Z","iopub.status.idle":"2024-10-16T03:02:20.324085Z","shell.execute_reply.started":"2024-10-16T03:02:20.318994Z","shell.execute_reply":"2024-10-16T03:02:20.323093Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import autograd\n\ndef compute_gradient_penalty(dis_model, real_samples, fake_samples, embeddings):\n    \"\"\"\n    Computes the gradient penalty for WGAN-GP.\n\n    Args:\n        dis_model (torch.nn.Module): The discriminator model.\n        real_samples (torch.Tensor): Batch of real images.\n        fake_samples (torch.Tensor): Batch of generated (fake) images.\n        device (torch.device): The device (CPU or GPU) to perform calculations.\n\n    Returns:\n        torch.Tensor: The gradient penalty value.\n    \"\"\"\n    # Get the batch size from real samples\n    batch_size = real_samples.size(0)\n\n    # Create random interpolation factor\n    alpha = torch.rand(batch_size, 1, 1, 1).to(device)\n    \n    # Create interpolated samples\n    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n\n    # Pass interpolated samples through the discriminator\n    d_interpolates = dis_model(interpolates , embeddings)\n\n    # Create gradients with respect to the interpolated samples\n    gradients = autograd.grad(\n        outputs=d_interpolates,\n        inputs=interpolates,\n        grad_outputs=torch.ones_like(d_interpolates),\n        create_graph=True,\n        retain_graph=True,\n        only_inputs=True\n    )[0]\n\n    # Flatten the gradients and compute the gradient penalty\n    gradients = gradients.view(gradients.size(0), -1)\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n\n    return gradient_penalty\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T03:02:20.325430Z","iopub.execute_input":"2024-10-16T03:02:20.325804Z","iopub.status.idle":"2024-10-16T03:02:20.362160Z","shell.execute_reply.started":"2024-10-16T03:02:20.325757Z","shell.execute_reply":"2024-10-16T03:02:20.361302Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def plot_generated_images(images, epoch, n_images=8):\n    \"\"\"\n    Plot generated images in a grid.\n    \n    Args:\n        images (Tensor): A batch of generated images (batch_size, 3, 64, 64).\n        epoch (int): Current epoch for title.\n        n_images (int): Number of images to plot. Default is 8.\n    \"\"\"\n    fig, axes = plt.subplots(1, n_images, figsize=(n_images * 2, 2))  # Set up the figure and axes\n    for i in range(n_images):\n        ax = axes[i]\n        img = images[i].detach().permute(1, 2, 0).cpu().numpy()  # Convert CHW to HWC and move to CPU\n        ax.imshow(img)\n        ax.axis(\"off\")  # Turn off axis\n    plt.suptitle(f'Generated Images at Epoch {epoch}')  # Add a title\n    plt.show()  # Display the plot","metadata":{"execution":{"iopub.status.busy":"2024-10-16T06:34:01.881962Z","iopub.execute_input":"2024-10-16T06:34:01.882666Z","iopub.status.idle":"2024-10-16T06:34:01.889523Z","shell.execute_reply.started":"2024-10-16T06:34:01.882627Z","shell.execute_reply":"2024-10-16T06:34:01.888527Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nimport glob\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm  # Import tqdm for progress bars\n\ntorch.cuda.empty_cache()\n\n# Set device (use GPU if available)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# device = torch.device( \"cpu\")\n\n# Hyperparameters\nlr = 0.0002             # Learning rate\nlr_2 = 0.0001\nbeta1 = 0.5             # Beta1 for Adam optimizer\nbatch_size = 64         # Batch size\nepochs = 350   # Number of epochs\nlatent_dim = 100        # Dimension of latent vector (noise)\nimage_size = 64         # Image size (64x64)\ncondition_dim = 128     # Dimension of compressed text embeddings (to match your previous setup)\n\n# Directory to save generated images\noutput_dir = 'generated_images'\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs('weights', exist_ok=True)\n\n# Clear previous checkpoints\nfor checkpoint in glob.glob(os.path.join(output_dir, 'generator_epoch_*.pth')):\n    os.remove(checkpoint)\nfor checkpoint in glob.glob(os.path.join(output_dir, 'discriminator_epoch_*.pth')):\n    os.remove(checkpoint)\n\n# TensorBoard writer\nwriter = SummaryWriter('runs/GAN_training')\n\n# Define utility functions\ndef save_rgb_img(img, path):\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    if isinstance(img, torch.Tensor):\n        img = img.detach().permute(1, 2, 0).cpu().numpy()  # Convert CHW to HWC and move to CPU\n    ax.imshow(img)\n    ax.axis(\"off\")\n    ax.set_title(\"Generated Image\")\n    plt.savefig(path)\n    plt.close()\n\ndef write_log(writer, name, loss, global_step):\n    writer.add_scalar(name, loss, global_step)\n\n# Models\ngen_model = Stage1Generator().to(device)\ndis_model = Stage1Discriminator().to(device)\n\n# Optimizers\ngen_optimizer = optim.Adam(gen_model.parameters(), lr=0.00001, betas=(beta1, 0.999))\ndis_optimizer = optim.Adam(dis_model.parameters(), lr=0.00005, betas=(beta1, 0.999))\n\ngen_scheduler = lr_scheduler.ReduceLROnPlateau(gen_optimizer, mode='min', factor=0.5, patience=10, verbose=True)\ndis_scheduler = lr_scheduler.ReduceLROnPlateau(dis_optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n\n# Loss function\nadversarial_loss = torch.nn.BCELoss()\n\n# Labels for real and fake images\nreal_label = 1.0\nfake_label = 0.0\n\nsave_interval = 10\nimage_save_interval = 10\n\n# Load the resized images and their corresponding embeddings\ntrain_images = torch.load('/kaggle/input/qwerty-3/image_tensors.pt_2')# Load resized images as tensors (batch_size, 3, 64, 64)\ntrain_embeddings = torch.load('/kaggle/input/qwerty-3/text_embeddings')\ntrain_embeddings = torch.stack(train_embeddings).to(device)\n\n\nglobal_step = 0  # For logging steps\n\n# Lists to store generator and discriminator losses for plotting\ngen_losses = []\ndis_losses = []\n\nlambda_gp = 10  # Coefficient for gradient penalty\n\nfor epoch in tqdm(range(epochs), desc=\"Epochs\"):\n    gen_epoch_loss = 0\n    dis_epoch_loss = 0\n    num_batches = len(train_images) // batch_size\n\n    for i in range(0, len(train_images), batch_size):\n        real_images = train_images[i:i+batch_size].to(device)\n        real_embeddings = train_embeddings[i:i+batch_size].to(device)\n        batch_size = real_images.size(0)\n\n        ############################\n        # (1) Update Discriminator\n        ###########################\n        dis_model.zero_grad()\n\n        # Generate fake images\n        noise = torch.randn(batch_size, latent_dim, device=device)\n        fake_images, mean_logsigma = gen_model(real_embeddings, noise)\n\n        # Get discriminator outputs\n        real_output = dis_model(real_images, real_embeddings).view(-1)\n        fake_output = dis_model(fake_images.detach(), real_embeddings).view(-1)\n\n        # Compute Wasserstein loss\n        dis_loss = wasserstein_discriminator_loss(real_output, fake_output)\n\n        # Compute gradient penalty\n        gradient_penalty = compute_gradient_penalty(dis_model, real_images, fake_images, real_embeddings)\n        dis_loss += lambda_gp * gradient_penalty  # Add gradient penalty to discriminator loss\n\n        dis_loss.backward()\n        dis_optimizer.step()\n\n        ############################\n        # (2) Update Generator\n        ###########################\n        gen_model.zero_grad()\n\n        # Generate fake images and get critic output\n        fake_images, mean_logsigma = gen_model(real_embeddings, noise)\n        fake_output_gen = dis_model(fake_images, real_embeddings).view(-1)\n\n        # Compute Wasserstein generator loss\n        gen_loss = wasserstein_generator_loss(fake_output_gen)\n\n        # Add KL loss (optional, if used in your architecture)\n        kl_loss = KL_loss(mean_logsigma)\n        total_gen_loss = gen_loss + kl_loss\n\n        total_gen_loss.backward()\n        gen_optimizer.step()\n        \n        global_step += 1\n        write_log(writer, 'Discriminator Loss', dis_loss.item(), global_step)\n        write_log(writer, 'Generator Loss', total_gen_loss.item(), global_step)\n\n        # Print losses and save checkpoints\n        if i % 50 == 0:\n            print(f'Epoch [{epoch}/{epochs}] Step [{i}] Discriminator Loss: {dis_loss.item()} Generator Loss: {total_gen_loss.item()}')\n\n            # Save generated images\n            if i % 100 == 0:\n                img_path = os.path.join(output_dir, f'generated_img_epoch_{epoch}_step_{i}.png')\n                save_rgb_img(fake_images[0], img_path)  # Save first image in batch\n\n        # Accumulate epoch losses\n        dis_epoch_loss += dis_loss.item()\n        gen_epoch_loss += total_gen_loss.item()\n\n    # Store the average loss for each epoch\n    dis_losses.append(dis_epoch_loss / num_batches)\n    gen_losses.append(gen_epoch_loss / num_batches)\n    \n    avg_dis_losses = dis_losses[-1]\n    avg_gen_losses = gen_losses[-1]\n    \n    gen_scheduler.step(avg_gen_loss)  \n    dis_scheduler.step(avg_dis_loss)  \n    \n    if epoch % save_interval == 0:\n        torch.save(gen_model.state_dict(), f'weights/generator_epoch_{epoch}.pth')\n        torch.save(dis_model.state_dict(), f'weights/discriminator_epoch_{epoch}.pth')\n    # Print average losses per epoch\n    print(f'Epoch [{epoch}/{epochs}] Avg Discriminator Loss: {avg_dis_losses} Avg Generator Loss: {avg_gen_losses}')\n    \n    if epoch % image_save_interval == 0:\n        img_path = os.path.join(output_dir, f'generated_img_epoch_{epoch}.png')\n        save_rgb_img(fake_images[0], img_path)  # Save the first image in the batch for visualization\n        \n        # Plot generated images\n        plot_generated_images(fake_images, epoch)  # Plot a few generated images from the batch\n\n    \nprint('jaqnvi')    \n\n    \n\ntorch.save(gen_model.state_dict(), \"weights/stage1_gen_final.pth\")\ntorch.save(dis_model.state_dict(), \"weights/stage1_dis_final.pth\")\n\n\n# Plot the losses after training\nplt.figure(figsize=(10, 5))\nplt.plot(range(epochs), gen_losses, label='Generator Loss')\nplt.plot(range(epochs), dis_losses, label='Discriminator Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Generator and Discriminator Loss During Training')\nplt.legend()\nplt.grid()\nplt.show()\n\nprint(\"Training finished.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T03:02:30.767320Z","iopub.execute_input":"2024-10-16T03:02:30.767724Z","iopub.status.idle":"2024-10-16T05:37:11.229356Z","shell.execute_reply.started":"2024-10-16T03:02:30.767684Z","shell.execute_reply":"2024-10-16T05:37:11.228335Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3385041332.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  train_images = torch.load('/kaggle/input/qwerty-3/image_tensors.pt_2')# Load resized images as tensors (batch_size, 3, 64, 64)\n/tmp/ipykernel_30/3385041332.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  train_embeddings = torch.load('/kaggle/input/qwerty-3/text_embeddings')\nEpochs:   0%|          | 0/240 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [0/240] Step [0] Discriminator Loss: 3.5460424423217773 Generator Loss: -0.8906732797622681\nEpoch [0/240] Step [1600] Discriminator Loss: 0.356229692697525 Generator Loss: -0.25164464116096497\nEpoch [0/240] Step [3200] Discriminator Loss: 0.820697009563446 Generator Loss: -0.09623321890830994\nEpoch [0/240] Step [4800] Discriminator Loss: 0.04894110560417175 Generator Loss: -0.36905571818351746\nEpoch [0/240] Step [6400] Discriminator Loss: -0.3657190799713135 Generator Loss: -0.03865328058600426\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   0%|          | 1/240 [00:29<1:59:09, 29.91s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [0/240] Avg Discriminator Loss: 0.8715165225314159 Avg Generator Loss: -0.28116090891554074\nEpoch [1/240] Step [0] Discriminator Loss: 5.197966575622559 Generator Loss: -0.4865948557853699\nEpoch [1/240] Step [600] Discriminator Loss: -0.1149691492319107 Generator Loss: -0.28153514862060547\nEpoch [1/240] Step [1200] Discriminator Loss: -0.04294900596141815 Generator Loss: -0.3534291386604309\nEpoch [1/240] Step [1800] Discriminator Loss: 0.07151873409748077 Generator Loss: -0.31718793511390686\nEpoch [1/240] Step [2400] Discriminator Loss: 0.5240539908409119 Generator Loss: -0.31088903546333313\nEpoch [1/240] Step [3000] Discriminator Loss: 0.09884485602378845 Generator Loss: -0.31197983026504517\nEpoch [1/240] Step [3600] Discriminator Loss: 0.12263398617506027 Generator Loss: -0.356777548789978\nEpoch [1/240] Step [4200] Discriminator Loss: 0.5312337875366211 Generator Loss: -0.3043251633644104\nEpoch [1/240] Step [4800] Discriminator Loss: 0.1299757957458496 Generator Loss: -0.4916988015174866\nEpoch [1/240] Step [5400] Discriminator Loss: 0.4153240919113159 Generator Loss: -0.706777036190033\nEpoch [1/240] Step [6000] Discriminator Loss: -0.1782650351524353 Generator Loss: -0.24967479705810547\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   1%|          | 2/240 [01:06<2:13:21, 33.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/240] Avg Discriminator Loss: 0.405985720482938 Avg Generator Loss: -0.38101112489134836\nEpoch [2/240] Step [0] Discriminator Loss: 0.9890694618225098 Generator Loss: -0.9095785617828369\nEpoch [2/240] Step [600] Discriminator Loss: 0.19205114245414734 Generator Loss: -0.354276180267334\nEpoch [2/240] Step [1200] Discriminator Loss: 0.11831901967525482 Generator Loss: -0.4584021270275116\nEpoch [2/240] Step [1800] Discriminator Loss: 0.2530577480792999 Generator Loss: -0.47754526138305664\nEpoch [2/240] Step [2400] Discriminator Loss: 0.10454048216342926 Generator Loss: -0.4349641799926758\nEpoch [2/240] Step [3000] Discriminator Loss: -0.26216185092926025 Generator Loss: -0.28633859753608704\nEpoch [2/240] Step [3600] Discriminator Loss: 0.019784852862358093 Generator Loss: -0.4519104063510895\nEpoch [2/240] Step [4200] Discriminator Loss: -0.005407512187957764 Generator Loss: -0.42500436305999756\nEpoch [2/240] Step [4800] Discriminator Loss: -0.28703513741493225 Generator Loss: -0.33006367087364197\nEpoch [2/240] Step [5400] Discriminator Loss: -0.1778397113084793 Generator Loss: -0.20712940394878387\nEpoch [2/240] Step [6000] Discriminator Loss: -0.13194642961025238 Generator Loss: -0.3560381531715393\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   1%|▏         | 3/240 [01:43<2:19:03, 35.20s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/240] Avg Discriminator Loss: 0.40346639189910105 Avg Generator Loss: -0.38195339818877394\nEpoch [3/240] Step [0] Discriminator Loss: -0.08558404445648193 Generator Loss: -0.20850315690040588\nEpoch [3/240] Step [600] Discriminator Loss: 6.2816596031188965 Generator Loss: -0.15249787271022797\nEpoch [3/240] Step [1200] Discriminator Loss: -0.032224610447883606 Generator Loss: -0.41357508301734924\nEpoch [3/240] Step [1800] Discriminator Loss: 0.0866677314043045 Generator Loss: -0.46124181151390076\nEpoch [3/240] Step [2400] Discriminator Loss: 0.06369495391845703 Generator Loss: -0.41700148582458496\nEpoch [3/240] Step [3000] Discriminator Loss: -0.15319204330444336 Generator Loss: -0.2515229880809784\nEpoch [3/240] Step [3600] Discriminator Loss: 0.07569760084152222 Generator Loss: -0.3541460931301117\nEpoch [3/240] Step [4200] Discriminator Loss: -0.003417670726776123 Generator Loss: -0.3116263747215271\nEpoch [3/240] Step [4800] Discriminator Loss: 0.1090017557144165 Generator Loss: -0.3482930660247803\nEpoch [3/240] Step [5400] Discriminator Loss: -0.04648701846599579 Generator Loss: -0.4098105728626251\nEpoch [3/240] Step [6000] Discriminator Loss: -0.021723173558712006 Generator Loss: -0.22888872027397156\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   2%|▏         | 4/240 [02:20<2:21:34, 36.00s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [3/240] Avg Discriminator Loss: 0.20164489701062768 Avg Generator Loss: -0.39052704582502556\nEpoch [4/240] Step [0] Discriminator Loss: -0.11138071119785309 Generator Loss: -0.2914964258670807\nEpoch [4/240] Step [600] Discriminator Loss: -0.13942775130271912 Generator Loss: -0.32406434416770935\nEpoch [4/240] Step [1200] Discriminator Loss: -0.06645005941390991 Generator Loss: -0.25870874524116516\nEpoch [4/240] Step [1800] Discriminator Loss: -0.0442877933382988 Generator Loss: -0.396898478269577\nEpoch [4/240] Step [2400] Discriminator Loss: -0.177597776055336 Generator Loss: -0.3325045704841614\nEpoch [4/240] Step [3000] Discriminator Loss: 0.04191160202026367 Generator Loss: -0.3673550486564636\nEpoch [4/240] Step [3600] Discriminator Loss: 0.01412452757358551 Generator Loss: -0.4136628210544586\nEpoch [4/240] Step [4200] Discriminator Loss: -0.2818114161491394 Generator Loss: -0.15566223859786987\nEpoch [4/240] Step [4800] Discriminator Loss: 0.5926149487495422 Generator Loss: -0.08077514171600342\nEpoch [4/240] Step [5400] Discriminator Loss: -0.056550875306129456 Generator Loss: -0.6158789396286011\nEpoch [4/240] Step [6000] Discriminator Loss: -0.16629573702812195 Generator Loss: -0.17318834364414215\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   2%|▏         | 5/240 [02:57<2:23:04, 36.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [4/240] Avg Discriminator Loss: 0.26002744517729176 Avg Generator Loss: -0.34874960673024585\nEpoch [5/240] Step [0] Discriminator Loss: -0.04852362722158432 Generator Loss: -0.4093119204044342\nEpoch [5/240] Step [600] Discriminator Loss: 0.12243930995464325 Generator Loss: -0.3950914442539215\nEpoch [5/240] Step [1200] Discriminator Loss: 0.37767478823661804 Generator Loss: -0.45743227005004883\nEpoch [5/240] Step [1800] Discriminator Loss: 2.167487382888794 Generator Loss: -0.43849262595176697\nEpoch [5/240] Step [2400] Discriminator Loss: 0.08808678388595581 Generator Loss: -0.4238200783729553\nEpoch [5/240] Step [3000] Discriminator Loss: 0.4648858904838562 Generator Loss: -0.1001339852809906\nEpoch [5/240] Step [3600] Discriminator Loss: -0.18628469109535217 Generator Loss: -0.23442186415195465\nEpoch [5/240] Step [4200] Discriminator Loss: -0.1462242305278778 Generator Loss: -0.32337912917137146\nEpoch [5/240] Step [4800] Discriminator Loss: 0.04286475479602814 Generator Loss: -0.36541470885276794\nEpoch [5/240] Step [5400] Discriminator Loss: 0.038680851459503174 Generator Loss: -0.35280656814575195\nEpoch [5/240] Step [6000] Discriminator Loss: 0.005869001150131226 Generator Loss: -0.16587196290493011\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   2%|▎         | 6/240 [03:35<2:24:08, 36.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [5/240] Avg Discriminator Loss: 0.1397255795970286 Avg Generator Loss: -0.3268894169193048\nEpoch [6/240] Step [0] Discriminator Loss: -0.17899659276008606 Generator Loss: -0.3706156015396118\nEpoch [6/240] Step [600] Discriminator Loss: -0.397156298160553 Generator Loss: -0.17991098761558533\nEpoch [6/240] Step [1200] Discriminator Loss: 1.3754377365112305 Generator Loss: -0.9613977670669556\nEpoch [6/240] Step [1800] Discriminator Loss: 0.19270524382591248 Generator Loss: -0.6223914623260498\nEpoch [6/240] Step [2400] Discriminator Loss: 0.06381189823150635 Generator Loss: -0.5965891480445862\nEpoch [6/240] Step [3000] Discriminator Loss: 1.1778209209442139 Generator Loss: -0.29521194100379944\nEpoch [6/240] Step [3600] Discriminator Loss: -0.06822150945663452 Generator Loss: -0.40248969197273254\nEpoch [6/240] Step [4200] Discriminator Loss: -0.01473015546798706 Generator Loss: -0.4766785502433777\nEpoch [6/240] Step [4800] Discriminator Loss: 0.1687839776277542 Generator Loss: -0.3045671582221985\nEpoch [6/240] Step [5400] Discriminator Loss: 0.11508578062057495 Generator Loss: -0.5095116496086121\nEpoch [6/240] Step [6000] Discriminator Loss: 0.1609143614768982 Generator Loss: -0.38211241364479065\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   3%|▎         | 7/240 [04:13<2:24:49, 37.29s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [6/240] Avg Discriminator Loss: 0.2197940907007827 Avg Generator Loss: -0.35850598871871664\nEpoch [7/240] Step [0] Discriminator Loss: 0.6145893335342407 Generator Loss: -0.1566455066204071\nEpoch [7/240] Step [600] Discriminator Loss: -0.026924319565296173 Generator Loss: -0.3055642247200012\nEpoch [7/240] Step [1200] Discriminator Loss: -0.188387930393219 Generator Loss: -0.2927704155445099\nEpoch [7/240] Step [1800] Discriminator Loss: 0.14593657851219177 Generator Loss: -0.3801274299621582\nEpoch [7/240] Step [2400] Discriminator Loss: 0.3759726285934448 Generator Loss: -0.5026406645774841\nEpoch [7/240] Step [3000] Discriminator Loss: 1.0906059741973877 Generator Loss: -0.6194102764129639\nEpoch [7/240] Step [3600] Discriminator Loss: 0.1518257111310959 Generator Loss: -0.6479348540306091\nEpoch [7/240] Step [4200] Discriminator Loss: 0.04950705170631409 Generator Loss: -0.21961835026741028\nEpoch [7/240] Step [4800] Discriminator Loss: 0.1199478805065155 Generator Loss: -0.35569053888320923\nEpoch [7/240] Step [5400] Discriminator Loss: 0.44244110584259033 Generator Loss: -0.28648510575294495\nEpoch [7/240] Step [6000] Discriminator Loss: -0.14707937836647034 Generator Loss: -0.12798254191875458\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   3%|▎         | 8/240 [04:51<2:25:04, 37.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [7/240] Avg Discriminator Loss: 0.29519258413613936 Avg Generator Loss: -0.3829947613186507\nEpoch [8/240] Step [0] Discriminator Loss: -0.004928141832351685 Generator Loss: -0.4652542471885681\nEpoch [8/240] Step [600] Discriminator Loss: -0.11778683960437775 Generator Loss: -0.15149928629398346\nEpoch [8/240] Step [1200] Discriminator Loss: 6.911850452423096 Generator Loss: -0.7131953835487366\nEpoch [8/240] Step [1800] Discriminator Loss: -0.08477585762739182 Generator Loss: -0.33105412125587463\nEpoch [8/240] Step [2400] Discriminator Loss: -0.08604076504707336 Generator Loss: -0.3207298517227173\nEpoch [8/240] Step [3000] Discriminator Loss: -0.3195091485977173 Generator Loss: -0.2560512125492096\nEpoch [8/240] Step [3600] Discriminator Loss: 0.35714343190193176 Generator Loss: -0.4241170287132263\nEpoch [8/240] Step [4200] Discriminator Loss: 0.2829307019710541 Generator Loss: -0.1855146884918213\nEpoch [8/240] Step [4800] Discriminator Loss: -0.16495013236999512 Generator Loss: -0.22207100689411163\nEpoch [8/240] Step [5400] Discriminator Loss: -0.08069157600402832 Generator Loss: -0.2471141517162323\nEpoch [8/240] Step [6000] Discriminator Loss: 0.20132976770401 Generator Loss: -0.5609784126281738\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   4%|▍         | 9/240 [05:30<2:25:48, 37.87s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [8/240] Avg Discriminator Loss: 0.10068041558339919 Avg Generator Loss: -0.32428821984119033\nEpoch [9/240] Step [0] Discriminator Loss: -0.3232252299785614 Generator Loss: -0.23853425681591034\nEpoch [9/240] Step [600] Discriminator Loss: -0.23653459548950195 Generator Loss: -0.3825789988040924\nEpoch [9/240] Step [1200] Discriminator Loss: -0.29619914293289185 Generator Loss: -0.28651896119117737\nEpoch [9/240] Step [1800] Discriminator Loss: 0.22145438194274902 Generator Loss: -0.56914883852005\nEpoch [9/240] Step [2400] Discriminator Loss: 0.23142275214195251 Generator Loss: -0.4482940435409546\nEpoch [9/240] Step [3000] Discriminator Loss: 1.0325865745544434 Generator Loss: -0.17633581161499023\nEpoch [9/240] Step [3600] Discriminator Loss: 0.11679673939943314 Generator Loss: -0.4580520987510681\nEpoch [9/240] Step [4200] Discriminator Loss: -0.12729522585868835 Generator Loss: -0.3042873740196228\nEpoch [9/240] Step [4800] Discriminator Loss: -0.43801456689834595 Generator Loss: -0.17397591471672058\nEpoch [9/240] Step [5400] Discriminator Loss: 0.21000689268112183 Generator Loss: -0.3859408497810364\nEpoch [9/240] Step [6000] Discriminator Loss: 0.18458601832389832 Generator Loss: -0.4569718837738037\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   4%|▍         | 10/240 [06:08<2:25:52, 38.05s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [9/240] Avg Discriminator Loss: 0.2775652558566668 Avg Generator Loss: -0.37230439943640115\nEpoch [10/240] Step [0] Discriminator Loss: -0.1303916871547699 Generator Loss: -0.5400640964508057\nEpoch [10/240] Step [600] Discriminator Loss: -0.18751537799835205 Generator Loss: -0.20946434140205383\nEpoch [10/240] Step [1200] Discriminator Loss: -0.2952384948730469 Generator Loss: -0.1339116245508194\nEpoch [10/240] Step [1800] Discriminator Loss: 0.27818000316619873 Generator Loss: -0.3165743052959442\nEpoch [10/240] Step [2400] Discriminator Loss: -0.22190707921981812 Generator Loss: -0.29707053303718567\nEpoch [10/240] Step [3000] Discriminator Loss: 0.36225178837776184 Generator Loss: -0.16520023345947266\nEpoch [10/240] Step [3600] Discriminator Loss: 3.68530535697937 Generator Loss: -0.49628373980522156\nEpoch [10/240] Step [4200] Discriminator Loss: -0.30324211716651917 Generator Loss: -0.2411040961742401\nEpoch [10/240] Step [4800] Discriminator Loss: 0.23678702116012573 Generator Loss: -0.5312216877937317\nEpoch [10/240] Step [5400] Discriminator Loss: -0.37790802121162415 Generator Loss: -0.21085792779922485\nEpoch [10/240] Step [6000] Discriminator Loss: -0.4475129246711731 Generator Loss: -0.1418774425983429\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   5%|▍         | 11/240 [06:47<2:25:39, 38.16s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [10/240] Avg Discriminator Loss: 0.007646749430632854 Avg Generator Loss: -0.2823864720870942\nEpoch [11/240] Step [0] Discriminator Loss: 0.3211991786956787 Generator Loss: -0.5477399826049805\nEpoch [11/240] Step [600] Discriminator Loss: -0.23638856410980225 Generator Loss: -0.3638392984867096\nEpoch [11/240] Step [1200] Discriminator Loss: -0.19376340508460999 Generator Loss: -0.09878335893154144\nEpoch [11/240] Step [1800] Discriminator Loss: -0.08708760142326355 Generator Loss: -0.021054426208138466\nEpoch [11/240] Step [2400] Discriminator Loss: 0.0012344717979431152 Generator Loss: -0.24929234385490417\nEpoch [11/240] Step [3000] Discriminator Loss: 0.2025059461593628 Generator Loss: -0.36460477113723755\nEpoch [11/240] Step [3600] Discriminator Loss: -0.27388685941696167 Generator Loss: -0.308223694562912\nEpoch [11/240] Step [4200] Discriminator Loss: -0.41107332706451416 Generator Loss: -0.14676302671432495\nEpoch [11/240] Step [4800] Discriminator Loss: -0.0687815248966217 Generator Loss: -0.22500689327716827\nEpoch [11/240] Step [5400] Discriminator Loss: 0.482338547706604 Generator Loss: -0.4483906030654907\nEpoch [11/240] Step [6000] Discriminator Loss: -0.22272664308547974 Generator Loss: -0.10216245800256729\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   5%|▌         | 12/240 [07:25<2:25:25, 38.27s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [11/240] Avg Discriminator Loss: -0.024074540633858343 Avg Generator Loss: -0.2535854727916774\nEpoch [12/240] Step [0] Discriminator Loss: -0.31385692954063416 Generator Loss: -0.22347895801067352\nEpoch [12/240] Step [600] Discriminator Loss: 0.8500460982322693 Generator Loss: -0.25362101197242737\nEpoch [12/240] Step [1200] Discriminator Loss: -0.2912020683288574 Generator Loss: -0.22357884049415588\nEpoch [12/240] Step [1800] Discriminator Loss: -0.3640710115432739 Generator Loss: -0.2561529576778412\nEpoch [12/240] Step [2400] Discriminator Loss: -0.4585740864276886 Generator Loss: -0.019395101815462112\nEpoch [12/240] Step [3000] Discriminator Loss: 0.09299102425575256 Generator Loss: -0.38539591431617737\nEpoch [12/240] Step [3600] Discriminator Loss: -0.1759394109249115 Generator Loss: -0.30091720819473267\nEpoch [12/240] Step [4200] Discriminator Loss: -0.48713254928588867 Generator Loss: -0.16194358468055725\nEpoch [12/240] Step [4800] Discriminator Loss: -0.3323204815387726 Generator Loss: -0.07149598002433777\nEpoch [12/240] Step [5400] Discriminator Loss: 1.8904566764831543 Generator Loss: -0.6520624160766602\nEpoch [12/240] Step [6000] Discriminator Loss: 0.14102333784103394 Generator Loss: -0.2671584188938141\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   5%|▌         | 13/240 [08:04<2:25:01, 38.33s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [12/240] Avg Discriminator Loss: 0.07285726452485108 Avg Generator Loss: -0.26529325064162523\nEpoch [13/240] Step [0] Discriminator Loss: -0.3676319718360901 Generator Loss: -0.18660831451416016\nEpoch [13/240] Step [600] Discriminator Loss: -0.4933357238769531 Generator Loss: -0.08172869682312012\nEpoch [13/240] Step [1200] Discriminator Loss: -0.3449808657169342 Generator Loss: -0.3025272488594055\nEpoch [13/240] Step [1800] Discriminator Loss: -0.4163787066936493 Generator Loss: -0.0963686928153038\nEpoch [13/240] Step [2400] Discriminator Loss: -0.2772124409675598 Generator Loss: -0.1898087114095688\nEpoch [13/240] Step [3000] Discriminator Loss: 0.2569774389266968 Generator Loss: -0.16280320286750793\nEpoch [13/240] Step [3600] Discriminator Loss: -0.36042192578315735 Generator Loss: -0.2808187007904053\nEpoch [13/240] Step [4200] Discriminator Loss: -0.5048431754112244 Generator Loss: -0.13956031203269958\nEpoch [13/240] Step [4800] Discriminator Loss: -0.13210687041282654 Generator Loss: -0.9040288925170898\nEpoch [13/240] Step [5400] Discriminator Loss: -0.4817943572998047 Generator Loss: -0.04610026255249977\nEpoch [13/240] Step [6000] Discriminator Loss: -0.25156402587890625 Generator Loss: -0.10886165499687195\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   6%|▌         | 14/240 [08:42<2:24:48, 38.45s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [13/240] Avg Discriminator Loss: -0.13579171337869578 Avg Generator Loss: -0.17107053566724062\nEpoch [14/240] Step [0] Discriminator Loss: -0.5195522904396057 Generator Loss: -0.08466967940330505\nEpoch [14/240] Step [600] Discriminator Loss: -0.47724226117134094 Generator Loss: -0.1634688824415207\nEpoch [14/240] Step [1200] Discriminator Loss: -0.5116391181945801 Generator Loss: -0.13249558210372925\nEpoch [14/240] Step [1800] Discriminator Loss: -0.26815569400787354 Generator Loss: -0.2111106961965561\nEpoch [14/240] Step [2400] Discriminator Loss: 0.13296854496002197 Generator Loss: -0.16113056242465973\nEpoch [14/240] Step [3000] Discriminator Loss: -0.6809329986572266 Generator Loss: -0.09755280613899231\nEpoch [14/240] Step [3600] Discriminator Loss: -0.811042845249176 Generator Loss: -0.02892681211233139\nEpoch [14/240] Step [4200] Discriminator Loss: 0.2604694962501526 Generator Loss: -0.40885916352272034\nEpoch [14/240] Step [4800] Discriminator Loss: -0.2660883665084839 Generator Loss: -0.3109191358089447\nEpoch [14/240] Step [5400] Discriminator Loss: -0.5742464661598206 Generator Loss: -0.10433769226074219\nEpoch [14/240] Step [6000] Discriminator Loss: -0.15544945001602173 Generator Loss: -0.2548583149909973\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   6%|▋         | 15/240 [09:21<2:24:24, 38.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [14/240] Avg Discriminator Loss: -0.1982755544203105 Avg Generator Loss: -0.16501021552694478\nEpoch [15/240] Step [0] Discriminator Loss: -0.5609201788902283 Generator Loss: -0.0525948703289032\nEpoch [15/240] Step [600] Discriminator Loss: 0.10826045274734497 Generator Loss: -0.3909188508987427\nEpoch [15/240] Step [1200] Discriminator Loss: -0.5543245673179626 Generator Loss: -0.13754895329475403\nEpoch [15/240] Step [1800] Discriminator Loss: -0.13801631331443787 Generator Loss: -0.35435226559638977\nEpoch [15/240] Step [2400] Discriminator Loss: -0.40092208981513977 Generator Loss: -0.13523459434509277\nEpoch [15/240] Step [3000] Discriminator Loss: -0.1187543272972107 Generator Loss: -0.008552506566047668\nEpoch [15/240] Step [3600] Discriminator Loss: 0.16962116956710815 Generator Loss: -0.2474929690361023\nEpoch [15/240] Step [4200] Discriminator Loss: -0.052345871925354004 Generator Loss: -0.09806165099143982\nEpoch [15/240] Step [4800] Discriminator Loss: -0.6900081038475037 Generator Loss: -0.07186080515384674\nEpoch [15/240] Step [5400] Discriminator Loss: -0.35632094740867615 Generator Loss: -0.10219094157218933\nEpoch [15/240] Step [6000] Discriminator Loss: -0.44103267788887024 Generator Loss: -0.15702053904533386\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   7%|▋         | 16/240 [10:00<2:23:57, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [15/240] Avg Discriminator Loss: -0.17946851351758936 Avg Generator Loss: -0.1714384819247893\nEpoch [16/240] Step [0] Discriminator Loss: -0.36492371559143066 Generator Loss: -0.45095109939575195\nEpoch [16/240] Step [600] Discriminator Loss: 0.014138847589492798 Generator Loss: -0.18400496244430542\nEpoch [16/240] Step [1200] Discriminator Loss: -0.28793805837631226 Generator Loss: -0.21201558411121368\nEpoch [16/240] Step [1800] Discriminator Loss: 0.5400406122207642 Generator Loss: -0.22355300188064575\nEpoch [16/240] Step [2400] Discriminator Loss: -0.2757095396518707 Generator Loss: -0.26345643401145935\nEpoch [16/240] Step [3000] Discriminator Loss: -0.11424048244953156 Generator Loss: -0.3467361330986023\nEpoch [16/240] Step [3600] Discriminator Loss: 0.6102080941200256 Generator Loss: -0.026349222287535667\nEpoch [16/240] Step [4200] Discriminator Loss: -0.451735258102417 Generator Loss: -0.12220035493373871\nEpoch [16/240] Step [4800] Discriminator Loss: -0.4596811532974243 Generator Loss: -0.08739073574542999\nEpoch [16/240] Step [5400] Discriminator Loss: -0.06819361448287964 Generator Loss: -0.38557249307632446\nEpoch [16/240] Step [6000] Discriminator Loss: -0.5014190077781677 Generator Loss: -0.057030051946640015\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   7%|▋         | 17/240 [10:38<2:23:18, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [16/240] Avg Discriminator Loss: 0.027690132895668785 Avg Generator Loss: -0.23219109467493418\nEpoch [17/240] Step [0] Discriminator Loss: 0.05800190567970276 Generator Loss: -0.2567422091960907\nEpoch [17/240] Step [600] Discriminator Loss: -0.2554164528846741 Generator Loss: -0.10470469295978546\nEpoch [17/240] Step [1200] Discriminator Loss: -0.42771267890930176 Generator Loss: -0.16394294798374176\nEpoch [17/240] Step [1800] Discriminator Loss: -0.45443469285964966 Generator Loss: -0.10618243366479874\nEpoch [17/240] Step [2400] Discriminator Loss: -0.24777807295322418 Generator Loss: -0.26333439350128174\nEpoch [17/240] Step [3000] Discriminator Loss: -0.5168169736862183 Generator Loss: -0.07029598951339722\nEpoch [17/240] Step [3600] Discriminator Loss: 0.48970723152160645 Generator Loss: -0.012921469286084175\nEpoch [17/240] Step [4200] Discriminator Loss: -0.19221974909305573 Generator Loss: -0.28221234679222107\nEpoch [17/240] Step [4800] Discriminator Loss: 0.2573416829109192 Generator Loss: -0.27387335896492004\nEpoch [17/240] Step [5400] Discriminator Loss: -0.03560751676559448 Generator Loss: -0.1519462913274765\nEpoch [17/240] Step [6000] Discriminator Loss: 6.698855400085449 Generator Loss: -0.14712189137935638\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   8%|▊         | 18/240 [11:17<2:22:33, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [17/240] Avg Discriminator Loss: -0.1604787760274314 Avg Generator Loss: -0.22030143198581079\nEpoch [18/240] Step [0] Discriminator Loss: -0.3334648609161377 Generator Loss: -0.1355815827846527\nEpoch [18/240] Step [600] Discriminator Loss: -0.1952705681324005 Generator Loss: -0.263029545545578\nEpoch [18/240] Step [1200] Discriminator Loss: -0.28798621892929077 Generator Loss: -0.26317644119262695\nEpoch [18/240] Step [1800] Discriminator Loss: -0.011717498302459717 Generator Loss: -0.14767786860466003\nEpoch [18/240] Step [2400] Discriminator Loss: -0.19398128986358643 Generator Loss: -0.17732560634613037\nEpoch [18/240] Step [3000] Discriminator Loss: -0.551139771938324 Generator Loss: -0.08539853990077972\nEpoch [18/240] Step [3600] Discriminator Loss: -0.42634111642837524 Generator Loss: -0.16479846835136414\nEpoch [18/240] Step [4200] Discriminator Loss: 0.06500375270843506 Generator Loss: -0.2870121896266937\nEpoch [18/240] Step [4800] Discriminator Loss: 0.051258742809295654 Generator Loss: -0.2506698966026306\nEpoch [18/240] Step [5400] Discriminator Loss: -0.1724742203950882 Generator Loss: -0.23172806203365326\nEpoch [18/240] Step [6000] Discriminator Loss: -0.19868767261505127 Generator Loss: -0.4157269597053528\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   8%|▊         | 19/240 [11:55<2:21:51, 38.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [18/240] Avg Discriminator Loss: -0.06652096204541541 Avg Generator Loss: -0.27123739338401476\nEpoch [19/240] Step [0] Discriminator Loss: -0.22023585438728333 Generator Loss: -0.07078462094068527\nEpoch [19/240] Step [600] Discriminator Loss: -0.15915921330451965 Generator Loss: -0.6705576181411743\nEpoch [19/240] Step [1200] Discriminator Loss: -0.3629853427410126 Generator Loss: -0.17536303400993347\nEpoch [19/240] Step [1800] Discriminator Loss: -0.22197884321212769 Generator Loss: -0.10879618674516678\nEpoch [19/240] Step [2400] Discriminator Loss: -0.10777482390403748 Generator Loss: -0.16904641687870026\nEpoch [19/240] Step [3000] Discriminator Loss: -0.4797000288963318 Generator Loss: -0.1982404887676239\nEpoch [19/240] Step [3600] Discriminator Loss: -0.024820804595947266 Generator Loss: -0.17210616171360016\nEpoch [19/240] Step [4200] Discriminator Loss: -0.5972468852996826 Generator Loss: -0.06042616814374924\nEpoch [19/240] Step [4800] Discriminator Loss: 1.0938962697982788 Generator Loss: -0.6582110524177551\nEpoch [19/240] Step [5400] Discriminator Loss: -0.0807364284992218 Generator Loss: -0.22583431005477905\nEpoch [19/240] Step [6000] Discriminator Loss: -0.5684059858322144 Generator Loss: -0.1415753960609436\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   8%|▊         | 20/240 [12:33<2:20:55, 38.44s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [19/240] Avg Discriminator Loss: -0.12113842862102138 Avg Generator Loss: -0.265525987914221\nEpoch [20/240] Step [0] Discriminator Loss: -0.14252470433712006 Generator Loss: -0.5267636179924011\nEpoch [20/240] Step [600] Discriminator Loss: -0.5564591288566589 Generator Loss: -0.2403404712677002\nEpoch [20/240] Step [1200] Discriminator Loss: -0.2585417926311493 Generator Loss: -0.2567480206489563\nEpoch [20/240] Step [1800] Discriminator Loss: 0.5165627598762512 Generator Loss: -0.3511851131916046\nEpoch [20/240] Step [2400] Discriminator Loss: 0.06892800331115723 Generator Loss: -0.23162290453910828\nEpoch [20/240] Step [3000] Discriminator Loss: 0.3407376706600189 Generator Loss: -0.445466548204422\nEpoch [20/240] Step [3600] Discriminator Loss: -0.3285227119922638 Generator Loss: -0.13921092450618744\nEpoch [20/240] Step [4200] Discriminator Loss: -0.25122231245040894 Generator Loss: -0.14787070453166962\nEpoch [20/240] Step [4800] Discriminator Loss: 0.8932367563247681 Generator Loss: -0.4627678692340851\nEpoch [20/240] Step [5400] Discriminator Loss: -0.08327248692512512 Generator Loss: -0.37977921962738037\nEpoch [20/240] Step [6000] Discriminator Loss: -0.407176673412323 Generator Loss: -0.1653527170419693\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   9%|▉         | 21/240 [13:12<2:20:20, 38.45s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [20/240] Avg Discriminator Loss: 0.07142920270835088 Avg Generator Loss: -0.2999730352789928\nEpoch [21/240] Step [0] Discriminator Loss: -0.0679631233215332 Generator Loss: -0.5452890992164612\nEpoch [21/240] Step [600] Discriminator Loss: -0.36767226457595825 Generator Loss: -0.23693004250526428\nEpoch [21/240] Step [1200] Discriminator Loss: 0.028867006301879883 Generator Loss: -0.40699848532676697\nEpoch [21/240] Step [1800] Discriminator Loss: 0.0033634305000305176 Generator Loss: -0.1289016455411911\nEpoch [21/240] Step [2400] Discriminator Loss: -0.2876344323158264 Generator Loss: -0.18814939260482788\nEpoch [21/240] Step [3000] Discriminator Loss: -0.2032322883605957 Generator Loss: -0.03708472102880478\nEpoch [21/240] Step [3600] Discriminator Loss: -0.3863980174064636 Generator Loss: -0.23114080727100372\nEpoch [21/240] Step [4200] Discriminator Loss: -0.5434445142745972 Generator Loss: -0.14027220010757446\nEpoch [21/240] Step [4800] Discriminator Loss: -0.3901174068450928 Generator Loss: -0.12118876725435257\nEpoch [21/240] Step [5400] Discriminator Loss: -0.3275330662727356 Generator Loss: -0.1957785040140152\nEpoch [21/240] Step [6000] Discriminator Loss: -0.5357744097709656 Generator Loss: -0.10926918685436249\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   9%|▉         | 22/240 [13:51<2:19:49, 38.49s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [21/240] Avg Discriminator Loss: -0.13714370838342568 Avg Generator Loss: -0.22956598749309232\nEpoch [22/240] Step [0] Discriminator Loss: 0.9329622983932495 Generator Loss: -0.011791510507464409\nEpoch [22/240] Step [600] Discriminator Loss: -0.3413664698600769 Generator Loss: -0.21375854313373566\nEpoch [22/240] Step [1200] Discriminator Loss: -0.47527098655700684 Generator Loss: -0.11855555325746536\nEpoch [22/240] Step [1800] Discriminator Loss: -0.6217542886734009 Generator Loss: -0.09957258403301239\nEpoch [22/240] Step [2400] Discriminator Loss: -0.4202028512954712 Generator Loss: -0.3588722050189972\nEpoch [22/240] Step [3000] Discriminator Loss: 0.06242057681083679 Generator Loss: -0.40504583716392517\nEpoch [22/240] Step [3600] Discriminator Loss: -0.07419988512992859 Generator Loss: -0.5613536834716797\nEpoch [22/240] Step [4200] Discriminator Loss: -0.13214853405952454 Generator Loss: -0.1722961664199829\nEpoch [22/240] Step [4800] Discriminator Loss: -0.41308537125587463 Generator Loss: -0.1712416410446167\nEpoch [22/240] Step [5400] Discriminator Loss: -0.3650919198989868 Generator Loss: -0.3315645158290863\nEpoch [22/240] Step [6000] Discriminator Loss: -0.38547250628471375 Generator Loss: -0.11263620108366013\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  10%|▉         | 23/240 [14:29<2:19:14, 38.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [22/240] Avg Discriminator Loss: -0.16900063925610356 Avg Generator Loss: -0.22947386141197804\nEpoch [23/240] Step [0] Discriminator Loss: -0.08358079195022583 Generator Loss: -0.2656766176223755\nEpoch [23/240] Step [600] Discriminator Loss: -0.418255090713501 Generator Loss: -0.245528906583786\nEpoch [23/240] Step [1200] Discriminator Loss: -0.5164312124252319 Generator Loss: -0.19609399139881134\nEpoch [23/240] Step [1800] Discriminator Loss: -0.3791901469230652 Generator Loss: -0.1200438067317009\nEpoch [23/240] Step [2400] Discriminator Loss: 0.33354219794273376 Generator Loss: -0.4765304923057556\nEpoch [23/240] Step [3000] Discriminator Loss: 0.3487545847892761 Generator Loss: -0.17036277055740356\nEpoch [23/240] Step [3600] Discriminator Loss: -0.2112482637166977 Generator Loss: -0.34361621737480164\nEpoch [23/240] Step [4200] Discriminator Loss: -0.4776473641395569 Generator Loss: -0.16112969815731049\nEpoch [23/240] Step [4800] Discriminator Loss: -0.0020025819540023804 Generator Loss: -0.17947709560394287\nEpoch [23/240] Step [5400] Discriminator Loss: -0.17455630004405975 Generator Loss: -0.16077864170074463\nEpoch [23/240] Step [6000] Discriminator Loss: -0.34420642256736755 Generator Loss: -0.478873610496521\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  10%|█         | 24/240 [15:08<2:18:35, 38.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [23/240] Avg Discriminator Loss: -0.15408709421480968 Avg Generator Loss: -0.25366046010165205\nEpoch [24/240] Step [0] Discriminator Loss: 4.182915687561035 Generator Loss: -0.19151483476161957\nEpoch [24/240] Step [600] Discriminator Loss: -0.07961729168891907 Generator Loss: -0.3318288028240204\nEpoch [24/240] Step [1200] Discriminator Loss: -0.28208839893341064 Generator Loss: -0.5873546600341797\nEpoch [24/240] Step [1800] Discriminator Loss: 4.0137763023376465 Generator Loss: -0.10828901827335358\nEpoch [24/240] Step [2400] Discriminator Loss: 0.06816861033439636 Generator Loss: -0.10877552628517151\nEpoch [24/240] Step [3000] Discriminator Loss: -0.4053869843482971 Generator Loss: -0.32964780926704407\nEpoch [24/240] Step [3600] Discriminator Loss: -0.666050374507904 Generator Loss: -0.07175993919372559\nEpoch [24/240] Step [4200] Discriminator Loss: -0.23507657647132874 Generator Loss: -0.2505726218223572\nEpoch [24/240] Step [4800] Discriminator Loss: -0.222653329372406 Generator Loss: -0.36145785450935364\nEpoch [24/240] Step [5400] Discriminator Loss: -0.333396315574646 Generator Loss: -0.20583714544773102\nEpoch [24/240] Step [6000] Discriminator Loss: -0.5465003848075867 Generator Loss: -0.219551682472229\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  10%|█         | 25/240 [15:47<2:18:34, 38.67s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [24/240] Avg Discriminator Loss: -0.05031872368775881 Avg Generator Loss: -0.2592056981277662\nEpoch [25/240] Step [0] Discriminator Loss: -0.46100643277168274 Generator Loss: -0.13514956831932068\nEpoch [25/240] Step [600] Discriminator Loss: 0.09195223450660706 Generator Loss: -0.28275755047798157\nEpoch [25/240] Step [1200] Discriminator Loss: -0.03504607081413269 Generator Loss: -0.08681505173444748\nEpoch [25/240] Step [1800] Discriminator Loss: -0.0035646259784698486 Generator Loss: -0.29009202122688293\nEpoch [25/240] Step [2400] Discriminator Loss: 0.05293193459510803 Generator Loss: -0.8681868314743042\nEpoch [25/240] Step [3000] Discriminator Loss: -0.33868497610092163 Generator Loss: -0.24063442647457123\nEpoch [25/240] Step [3600] Discriminator Loss: 1.083905816078186 Generator Loss: -0.3621143698692322\nEpoch [25/240] Step [4200] Discriminator Loss: -0.5495465993881226 Generator Loss: -0.11779476702213287\nEpoch [25/240] Step [4800] Discriminator Loss: -0.5386729836463928 Generator Loss: -0.0992589220404625\nEpoch [25/240] Step [5400] Discriminator Loss: -0.6733458042144775 Generator Loss: -0.16986162960529327\nEpoch [25/240] Step [6000] Discriminator Loss: -0.10011903941631317 Generator Loss: -0.4897534251213074\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  11%|█         | 26/240 [16:25<2:17:28, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [25/240] Avg Discriminator Loss: -0.17919750568958429 Avg Generator Loss: -0.22506506087415384\nEpoch [26/240] Step [0] Discriminator Loss: -0.47008591890335083 Generator Loss: -0.23638828098773956\nEpoch [26/240] Step [600] Discriminator Loss: -0.3256111145019531 Generator Loss: -0.1799166202545166\nEpoch [26/240] Step [1200] Discriminator Loss: 1.270435094833374 Generator Loss: -0.3792186677455902\nEpoch [26/240] Step [1800] Discriminator Loss: 0.18287697434425354 Generator Loss: -0.3529345989227295\nEpoch [26/240] Step [2400] Discriminator Loss: -0.16613812744617462 Generator Loss: -0.2660753130912781\nEpoch [26/240] Step [3000] Discriminator Loss: -0.18486540019512177 Generator Loss: -0.4081975221633911\nEpoch [26/240] Step [3600] Discriminator Loss: -0.5335997939109802 Generator Loss: -0.19909237325191498\nEpoch [26/240] Step [4200] Discriminator Loss: -0.5004578232765198 Generator Loss: -0.21007095277309418\nEpoch [26/240] Step [4800] Discriminator Loss: 0.6892287135124207 Generator Loss: -0.21784909069538116\nEpoch [26/240] Step [5400] Discriminator Loss: -0.31403908133506775 Generator Loss: -0.22067007422447205\nEpoch [26/240] Step [6000] Discriminator Loss: -0.5203285217285156 Generator Loss: -0.053465135395526886\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  11%|█▏        | 27/240 [17:03<2:16:41, 38.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [26/240] Avg Discriminator Loss: -0.15166126923028367 Avg Generator Loss: -0.2849539318650743\nEpoch [27/240] Step [0] Discriminator Loss: -0.12209168076515198 Generator Loss: -0.35273152589797974\nEpoch [27/240] Step [600] Discriminator Loss: -0.7088515162467957 Generator Loss: -0.10125016421079636\nEpoch [27/240] Step [1200] Discriminator Loss: -0.29848894476890564 Generator Loss: -0.14451636373996735\nEpoch [27/240] Step [1800] Discriminator Loss: -0.264248788356781 Generator Loss: -0.2454007863998413\nEpoch [27/240] Step [2400] Discriminator Loss: -0.22249427437782288 Generator Loss: -0.04255436360836029\nEpoch [27/240] Step [3000] Discriminator Loss: -0.3405557870864868 Generator Loss: -0.30001938343048096\nEpoch [27/240] Step [3600] Discriminator Loss: -0.2577066719532013 Generator Loss: -0.28211599588394165\nEpoch [27/240] Step [4200] Discriminator Loss: -0.41906511783599854 Generator Loss: -0.34101319313049316\nEpoch [27/240] Step [4800] Discriminator Loss: -0.25348982214927673 Generator Loss: -0.2956068515777588\nEpoch [27/240] Step [5400] Discriminator Loss: -0.3670368492603302 Generator Loss: -0.27071714401245117\nEpoch [27/240] Step [6000] Discriminator Loss: -0.5040705800056458 Generator Loss: -0.19318869709968567\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  12%|█▏        | 28/240 [17:42<2:16:09, 38.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [27/240] Avg Discriminator Loss: -0.2216881540887085 Avg Generator Loss: -0.25058412402458896\nEpoch [28/240] Step [0] Discriminator Loss: -0.4742511212825775 Generator Loss: -0.1977873146533966\nEpoch [28/240] Step [600] Discriminator Loss: -0.29235225915908813 Generator Loss: -0.18502973020076752\nEpoch [28/240] Step [1200] Discriminator Loss: 0.1669265627861023 Generator Loss: -0.47136205434799194\nEpoch [28/240] Step [1800] Discriminator Loss: -0.43225932121276855 Generator Loss: -0.15117520093917847\nEpoch [28/240] Step [2400] Discriminator Loss: -0.27192434668540955 Generator Loss: -0.25994768738746643\nEpoch [28/240] Step [3000] Discriminator Loss: -0.016222715377807617 Generator Loss: -0.2167344093322754\nEpoch [28/240] Step [3600] Discriminator Loss: 0.01310497522354126 Generator Loss: -0.43524548411369324\nEpoch [28/240] Step [4200] Discriminator Loss: 1.4312915802001953 Generator Loss: -0.45382001996040344\nEpoch [28/240] Step [4800] Discriminator Loss: 0.04651838541030884 Generator Loss: -0.851263165473938\nEpoch [28/240] Step [5400] Discriminator Loss: -0.26266995072364807 Generator Loss: -0.3241582214832306\nEpoch [28/240] Step [6000] Discriminator Loss: -0.48887690901756287 Generator Loss: -0.24577470123767853\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  12%|█▏        | 29/240 [18:20<2:15:15, 38.46s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [28/240] Avg Discriminator Loss: -0.13470680128796633 Avg Generator Loss: -0.2788337440786017\nEpoch [29/240] Step [0] Discriminator Loss: -0.14452433586120605 Generator Loss: -0.4768331050872803\nEpoch [29/240] Step [600] Discriminator Loss: -0.48775768280029297 Generator Loss: -0.36500874161720276\nEpoch [29/240] Step [1200] Discriminator Loss: -0.14143994450569153 Generator Loss: -0.34888210892677307\nEpoch [29/240] Step [1800] Discriminator Loss: -0.45058566331863403 Generator Loss: -0.12155406177043915\nEpoch [29/240] Step [2400] Discriminator Loss: -0.06690099835395813 Generator Loss: -0.24531878530979156\nEpoch [29/240] Step [3000] Discriminator Loss: -0.19690392911434174 Generator Loss: -0.47912880778312683\nEpoch [29/240] Step [3600] Discriminator Loss: 0.009848833084106445 Generator Loss: -0.49619626998901367\nEpoch [29/240] Step [4200] Discriminator Loss: -0.5104718208312988 Generator Loss: -0.26869142055511475\nEpoch [29/240] Step [4800] Discriminator Loss: 0.4660557508468628 Generator Loss: -0.356309175491333\nEpoch [29/240] Step [5400] Discriminator Loss: -0.31952041387557983 Generator Loss: -0.25401929020881653\nEpoch [29/240] Step [6000] Discriminator Loss: -0.49997478723526 Generator Loss: -0.25431111454963684\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  12%|█▎        | 30/240 [18:59<2:14:49, 38.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [29/240] Avg Discriminator Loss: -0.14546552030267296 Avg Generator Loss: -0.28565793037551007\nEpoch [30/240] Step [0] Discriminator Loss: -0.4733349084854126 Generator Loss: -0.2537086009979248\nEpoch [30/240] Step [600] Discriminator Loss: -0.5825087428092957 Generator Loss: -0.11152443289756775\nEpoch [30/240] Step [1200] Discriminator Loss: -0.18201139569282532 Generator Loss: -0.20338301360607147\nEpoch [30/240] Step [1800] Discriminator Loss: -0.2984153628349304 Generator Loss: -0.4452812671661377\nEpoch [30/240] Step [2400] Discriminator Loss: 0.8012380003929138 Generator Loss: -0.2918958067893982\nEpoch [30/240] Step [3000] Discriminator Loss: -0.056916624307632446 Generator Loss: -0.5106946229934692\nEpoch [30/240] Step [3600] Discriminator Loss: -0.251787394285202 Generator Loss: -0.40068328380584717\nEpoch [30/240] Step [4200] Discriminator Loss: -0.11111100018024445 Generator Loss: -0.36736905574798584\nEpoch [30/240] Step [4800] Discriminator Loss: 0.12208938598632812 Generator Loss: -0.3376868963241577\nEpoch [30/240] Step [5400] Discriminator Loss: -0.2971192002296448 Generator Loss: -0.5587892532348633\nEpoch [30/240] Step [6000] Discriminator Loss: -0.4203073978424072 Generator Loss: -0.2719188630580902\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  13%|█▎        | 31/240 [19:37<2:14:13, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [30/240] Avg Discriminator Loss: -0.1380871988205246 Avg Generator Loss: -0.28202500224331795\nEpoch [31/240] Step [0] Discriminator Loss: -0.45895469188690186 Generator Loss: -0.24901539087295532\nEpoch [31/240] Step [600] Discriminator Loss: -0.09671354293823242 Generator Loss: -0.28330445289611816\nEpoch [31/240] Step [1200] Discriminator Loss: -0.39840713143348694 Generator Loss: -0.05619516596198082\nEpoch [31/240] Step [1800] Discriminator Loss: -0.4482964873313904 Generator Loss: -0.3013569414615631\nEpoch [31/240] Step [2400] Discriminator Loss: -0.5219114422798157 Generator Loss: -0.15345852077007294\nEpoch [31/240] Step [3000] Discriminator Loss: -0.4545556902885437 Generator Loss: -0.2938612401485443\nEpoch [31/240] Step [3600] Discriminator Loss: -0.07089489698410034 Generator Loss: -0.3445490002632141\nEpoch [31/240] Step [4200] Discriminator Loss: -0.18667328357696533 Generator Loss: -0.32766374945640564\nEpoch [31/240] Step [4800] Discriminator Loss: -0.015013694763183594 Generator Loss: -0.2278379499912262\nEpoch [31/240] Step [5400] Discriminator Loss: -0.24041661620140076 Generator Loss: -0.19781239330768585\nEpoch [31/240] Step [6000] Discriminator Loss: -0.45888668298721313 Generator Loss: -0.23629365861415863\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  13%|█▎        | 32/240 [20:16<2:13:44, 38.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [31/240] Avg Discriminator Loss: -0.21185658752044914 Avg Generator Loss: -0.27657223131248365\nEpoch [32/240] Step [0] Discriminator Loss: -0.4190634787082672 Generator Loss: -0.1977131962776184\nEpoch [32/240] Step [600] Discriminator Loss: -0.52586829662323 Generator Loss: -0.32124775648117065\nEpoch [32/240] Step [1200] Discriminator Loss: -0.4441564083099365 Generator Loss: -0.2488863468170166\nEpoch [32/240] Step [1800] Discriminator Loss: -0.4479387402534485 Generator Loss: -0.2834964990615845\nEpoch [32/240] Step [2400] Discriminator Loss: 0.2138323187828064 Generator Loss: -0.5483278036117554\nEpoch [32/240] Step [3000] Discriminator Loss: -0.23577438294887543 Generator Loss: -0.37279969453811646\nEpoch [32/240] Step [3600] Discriminator Loss: -0.31393036246299744 Generator Loss: -0.22694143652915955\nEpoch [32/240] Step [4200] Discriminator Loss: -0.6193462610244751 Generator Loss: -0.15550197660923004\nEpoch [32/240] Step [4800] Discriminator Loss: -0.19091016054153442 Generator Loss: -0.4083315432071686\nEpoch [32/240] Step [5400] Discriminator Loss: -0.34777867794036865 Generator Loss: -0.4138637185096741\nEpoch [32/240] Step [6000] Discriminator Loss: -0.2198794186115265 Generator Loss: -0.4898107945919037\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  14%|█▍        | 33/240 [20:55<2:12:56, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [32/240] Avg Discriminator Loss: -0.21588488021394708 Avg Generator Loss: -0.2724495522418629\nEpoch [33/240] Step [0] Discriminator Loss: -0.5866281390190125 Generator Loss: -0.2060289978981018\nEpoch [33/240] Step [600] Discriminator Loss: -0.5845628380775452 Generator Loss: -0.3364379107952118\nEpoch [33/240] Step [1200] Discriminator Loss: -0.4787275493144989 Generator Loss: -0.23654766380786896\nEpoch [33/240] Step [1800] Discriminator Loss: -0.6087127327919006 Generator Loss: -0.09217508882284164\nEpoch [33/240] Step [2400] Discriminator Loss: -0.03175315260887146 Generator Loss: -0.29959970712661743\nEpoch [33/240] Step [3000] Discriminator Loss: -0.7207302451133728 Generator Loss: -0.06714385002851486\nEpoch [33/240] Step [3600] Discriminator Loss: -0.12230890989303589 Generator Loss: -0.5321197509765625\nEpoch [33/240] Step [4200] Discriminator Loss: -0.4694001376628876 Generator Loss: -0.15954367816448212\nEpoch [33/240] Step [4800] Discriminator Loss: -0.38690534234046936 Generator Loss: -0.27990368008613586\nEpoch [33/240] Step [5400] Discriminator Loss: -0.32353347539901733 Generator Loss: -0.40231531858444214\nEpoch [33/240] Step [6000] Discriminator Loss: -0.5815338492393494 Generator Loss: -0.15299393236637115\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  14%|█▍        | 34/240 [21:33<2:12:04, 38.47s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [33/240] Avg Discriminator Loss: -0.3537373912858439 Avg Generator Loss: -0.2628209987730334\nEpoch [34/240] Step [0] Discriminator Loss: -0.7044591903686523 Generator Loss: -0.11129646003246307\nEpoch [34/240] Step [600] Discriminator Loss: -0.5042898058891296 Generator Loss: -0.16626934707164764\nEpoch [34/240] Step [1200] Discriminator Loss: -0.22883500158786774 Generator Loss: -0.4508618414402008\nEpoch [34/240] Step [1800] Discriminator Loss: 0.8783160448074341 Generator Loss: -0.33019542694091797\nEpoch [34/240] Step [2400] Discriminator Loss: 0.4951496422290802 Generator Loss: -0.6146313548088074\nEpoch [34/240] Step [3000] Discriminator Loss: -0.5667911767959595 Generator Loss: -0.17294983565807343\nEpoch [34/240] Step [3600] Discriminator Loss: -0.22529011964797974 Generator Loss: -0.4564390778541565\nEpoch [34/240] Step [4200] Discriminator Loss: -0.41429826617240906 Generator Loss: -0.2759663462638855\nEpoch [34/240] Step [4800] Discriminator Loss: -0.6886306405067444 Generator Loss: -0.10713081061840057\nEpoch [34/240] Step [5400] Discriminator Loss: -0.3374854624271393 Generator Loss: -0.28080153465270996\nEpoch [34/240] Step [6000] Discriminator Loss: -0.5007262825965881 Generator Loss: -0.35847631096839905\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  15%|█▍        | 35/240 [22:11<2:11:35, 38.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [34/240] Avg Discriminator Loss: -0.21491946877686532 Avg Generator Loss: -0.30283590081410533\nEpoch [35/240] Step [0] Discriminator Loss: 2.1807539463043213 Generator Loss: -0.1494394987821579\nEpoch [35/240] Step [600] Discriminator Loss: -0.2603355646133423 Generator Loss: -0.21297891438007355\nEpoch [35/240] Step [1200] Discriminator Loss: -0.34633272886276245 Generator Loss: -0.24556472897529602\nEpoch [35/240] Step [1800] Discriminator Loss: -0.5955180525779724 Generator Loss: -0.16095125675201416\nEpoch [35/240] Step [2400] Discriminator Loss: -0.09932330250740051 Generator Loss: -0.15712405741214752\nEpoch [35/240] Step [3000] Discriminator Loss: -0.6435899138450623 Generator Loss: -0.10542992502450943\nEpoch [35/240] Step [3600] Discriminator Loss: -0.48642852902412415 Generator Loss: -0.16739188134670258\nEpoch [35/240] Step [4200] Discriminator Loss: -0.5871180891990662 Generator Loss: -0.3071358799934387\nEpoch [35/240] Step [4800] Discriminator Loss: -0.22685474157333374 Generator Loss: -0.40266087651252747\nEpoch [35/240] Step [5400] Discriminator Loss: -0.38314616680145264 Generator Loss: -0.16719157993793488\nEpoch [35/240] Step [6000] Discriminator Loss: -0.015831708908081055 Generator Loss: -0.25425025820732117\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  15%|█▌        | 36/240 [22:51<2:11:36, 38.71s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [35/240] Avg Discriminator Loss: -0.16044345755989736 Avg Generator Loss: -0.2949970433993381\nEpoch [36/240] Step [0] Discriminator Loss: -0.0966259017586708 Generator Loss: -0.3947029709815979\nEpoch [36/240] Step [600] Discriminator Loss: -0.25710493326187134 Generator Loss: -0.2546229958534241\nEpoch [36/240] Step [1200] Discriminator Loss: -0.2621114253997803 Generator Loss: -0.3774370849132538\nEpoch [36/240] Step [1800] Discriminator Loss: -0.07809047400951385 Generator Loss: -0.3841371238231659\nEpoch [36/240] Step [2400] Discriminator Loss: 0.1699347198009491 Generator Loss: -0.2733999788761139\nEpoch [36/240] Step [3000] Discriminator Loss: -0.3831426203250885 Generator Loss: -0.3349587917327881\nEpoch [36/240] Step [3600] Discriminator Loss: 0.8288841247558594 Generator Loss: -0.18184927105903625\nEpoch [36/240] Step [4200] Discriminator Loss: -0.6987860202789307 Generator Loss: -0.07452618330717087\nEpoch [36/240] Step [4800] Discriminator Loss: -0.3598678410053253 Generator Loss: -0.26474565267562866\nEpoch [36/240] Step [5400] Discriminator Loss: -0.5236941576004028 Generator Loss: -0.17380070686340332\nEpoch [36/240] Step [6000] Discriminator Loss: -0.5558671951293945 Generator Loss: -0.4055919349193573\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  15%|█▌        | 37/240 [23:29<2:10:38, 38.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [36/240] Avg Discriminator Loss: -0.2540395143595371 Avg Generator Loss: -0.28956209051323845\nEpoch [37/240] Step [0] Discriminator Loss: -0.5760367512702942 Generator Loss: -0.09947069734334946\nEpoch [37/240] Step [600] Discriminator Loss: 0.043633997440338135 Generator Loss: -0.31236767768859863\nEpoch [37/240] Step [1200] Discriminator Loss: -0.14118026196956635 Generator Loss: -0.3715292811393738\nEpoch [37/240] Step [1800] Discriminator Loss: -0.24523775279521942 Generator Loss: -0.3160463273525238\nEpoch [37/240] Step [2400] Discriminator Loss: 0.1419202983379364 Generator Loss: -0.4309481978416443\nEpoch [37/240] Step [3000] Discriminator Loss: -0.3689129054546356 Generator Loss: -0.415657103061676\nEpoch [37/240] Step [3600] Discriminator Loss: -0.057316213846206665 Generator Loss: -0.5528114438056946\nEpoch [37/240] Step [4200] Discriminator Loss: -0.5877153873443604 Generator Loss: -0.25198689103126526\nEpoch [37/240] Step [4800] Discriminator Loss: -0.006228536367416382 Generator Loss: -0.25352948904037476\nEpoch [37/240] Step [5400] Discriminator Loss: -0.3617432415485382 Generator Loss: -0.1257367879152298\nEpoch [37/240] Step [6000] Discriminator Loss: -0.3200829327106476 Generator Loss: -0.272696316242218\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  16%|█▌        | 38/240 [24:08<2:10:01, 38.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [37/240] Avg Discriminator Loss: -0.11874549722660592 Avg Generator Loss: -0.3222098451094095\nEpoch [38/240] Step [0] Discriminator Loss: -0.38316258788108826 Generator Loss: -0.2398822158575058\nEpoch [38/240] Step [600] Discriminator Loss: -0.5435928702354431 Generator Loss: -0.28399157524108887\nEpoch [38/240] Step [1200] Discriminator Loss: -0.26652467250823975 Generator Loss: -0.2842438519001007\nEpoch [38/240] Step [1800] Discriminator Loss: -0.685320258140564 Generator Loss: -0.1438092589378357\nEpoch [38/240] Step [2400] Discriminator Loss: -0.14427921175956726 Generator Loss: -0.2660711109638214\nEpoch [38/240] Step [3000] Discriminator Loss: -0.625873327255249 Generator Loss: -0.12824325263500214\nEpoch [38/240] Step [3600] Discriminator Loss: 0.263839989900589 Generator Loss: -0.2952698767185211\nEpoch [38/240] Step [4200] Discriminator Loss: -0.24046288430690765 Generator Loss: -0.3311235010623932\nEpoch [38/240] Step [4800] Discriminator Loss: -0.13223527371883392 Generator Loss: -0.44714993238449097\nEpoch [38/240] Step [5400] Discriminator Loss: 0.016055747866630554 Generator Loss: -0.3224424123764038\nEpoch [38/240] Step [6000] Discriminator Loss: -0.557658314704895 Generator Loss: -0.10489139705896378\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  16%|█▋        | 39/240 [24:46<2:09:08, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [38/240] Avg Discriminator Loss: -0.2177956093361963 Avg Generator Loss: -0.280298936395691\nEpoch [39/240] Step [0] Discriminator Loss: -0.17829632759094238 Generator Loss: -0.22808235883712769\nEpoch [39/240] Step [600] Discriminator Loss: -0.3611519932746887 Generator Loss: -0.7324783802032471\nEpoch [39/240] Step [1200] Discriminator Loss: -0.08412793278694153 Generator Loss: -0.27710065245628357\nEpoch [39/240] Step [1800] Discriminator Loss: 1.1068568229675293 Generator Loss: -0.582303524017334\nEpoch [39/240] Step [2400] Discriminator Loss: 0.09601938724517822 Generator Loss: -0.6133619546890259\nEpoch [39/240] Step [3000] Discriminator Loss: 0.09326374530792236 Generator Loss: -0.12321999669075012\nEpoch [39/240] Step [3600] Discriminator Loss: 0.16414505243301392 Generator Loss: -0.3378312587738037\nEpoch [39/240] Step [4200] Discriminator Loss: -0.11467650532722473 Generator Loss: -0.16863170266151428\nEpoch [39/240] Step [4800] Discriminator Loss: -0.734606921672821 Generator Loss: -0.10032650828361511\nEpoch [39/240] Step [5400] Discriminator Loss: -0.2477094531059265 Generator Loss: -0.2952422797679901\nEpoch [39/240] Step [6000] Discriminator Loss: -0.49758222699165344 Generator Loss: -0.2126346379518509\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  17%|█▋        | 40/240 [25:25<2:08:25, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [39/240] Avg Discriminator Loss: -0.2531278704876428 Avg Generator Loss: -0.26775497519462316\nEpoch [40/240] Step [0] Discriminator Loss: -0.4120649993419647 Generator Loss: -0.3496808707714081\nEpoch [40/240] Step [600] Discriminator Loss: -0.5186401605606079 Generator Loss: -0.19178332388401031\nEpoch [40/240] Step [1200] Discriminator Loss: -0.6384353041648865 Generator Loss: -0.1296946108341217\nEpoch [40/240] Step [1800] Discriminator Loss: -0.5508083701133728 Generator Loss: -0.17893439531326294\nEpoch [40/240] Step [2400] Discriminator Loss: -0.39672601222991943 Generator Loss: -0.1784568876028061\nEpoch [40/240] Step [3000] Discriminator Loss: -0.7653138041496277 Generator Loss: -0.06160397827625275\nEpoch [40/240] Step [3600] Discriminator Loss: -0.5483875870704651 Generator Loss: -0.1098359078168869\nEpoch [40/240] Step [4200] Discriminator Loss: -0.5546098351478577 Generator Loss: -0.14838376641273499\nEpoch [40/240] Step [4800] Discriminator Loss: -0.5124446749687195 Generator Loss: -0.14490529894828796\nEpoch [40/240] Step [5400] Discriminator Loss: -0.575736403465271 Generator Loss: -0.14568769931793213\nEpoch [40/240] Step [6000] Discriminator Loss: -0.614433765411377 Generator Loss: -0.21835292875766754\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  17%|█▋        | 41/240 [26:03<2:08:04, 38.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [40/240] Avg Discriminator Loss: -0.3559466385361039 Avg Generator Loss: -0.2338909176502363\nEpoch [41/240] Step [0] Discriminator Loss: -0.4973708391189575 Generator Loss: -0.43437060713768005\nEpoch [41/240] Step [600] Discriminator Loss: -0.5970878601074219 Generator Loss: -0.12207341194152832\nEpoch [41/240] Step [1200] Discriminator Loss: -0.05030056834220886 Generator Loss: -0.8060505986213684\nEpoch [41/240] Step [1800] Discriminator Loss: 1.5338788032531738 Generator Loss: -0.0833314061164856\nEpoch [41/240] Step [2400] Discriminator Loss: -0.31163501739501953 Generator Loss: -0.18557550013065338\nEpoch [41/240] Step [3000] Discriminator Loss: -0.5129067897796631 Generator Loss: -0.0653507187962532\nEpoch [41/240] Step [3600] Discriminator Loss: -0.6288068294525146 Generator Loss: -0.12196673452854156\nEpoch [41/240] Step [4200] Discriminator Loss: -0.724067747592926 Generator Loss: -0.1539192646741867\nEpoch [41/240] Step [4800] Discriminator Loss: -0.20577117800712585 Generator Loss: -0.17070022225379944\nEpoch [41/240] Step [5400] Discriminator Loss: -0.4763307571411133 Generator Loss: -0.5170896053314209\nEpoch [41/240] Step [6000] Discriminator Loss: 1.4715805053710938 Generator Loss: -0.33531591296195984\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  18%|█▊        | 42/240 [26:42<2:07:23, 38.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [41/240] Avg Discriminator Loss: -0.308214912211502 Avg Generator Loss: -0.2577421485340639\nEpoch [42/240] Step [0] Discriminator Loss: -0.10241612792015076 Generator Loss: -0.22900590300559998\nEpoch [42/240] Step [600] Discriminator Loss: -0.2996803820133209 Generator Loss: -0.3374612629413605\nEpoch [42/240] Step [1200] Discriminator Loss: 0.2717514634132385 Generator Loss: -0.5200415849685669\nEpoch [42/240] Step [1800] Discriminator Loss: -0.7388777732849121 Generator Loss: -0.10821004956960678\nEpoch [42/240] Step [2400] Discriminator Loss: -0.020674943923950195 Generator Loss: -0.06998369097709656\nEpoch [42/240] Step [3000] Discriminator Loss: -0.5099537968635559 Generator Loss: -0.34981924295425415\nEpoch [42/240] Step [3600] Discriminator Loss: -0.5285873413085938 Generator Loss: -0.2974116802215576\nEpoch [42/240] Step [4200] Discriminator Loss: -0.2755362391471863 Generator Loss: -0.45616576075553894\nEpoch [42/240] Step [4800] Discriminator Loss: -0.6878025531768799 Generator Loss: -0.20473171770572662\nEpoch [42/240] Step [5400] Discriminator Loss: -0.48909029364585876 Generator Loss: -0.21125586330890656\nEpoch [42/240] Step [6000] Discriminator Loss: -0.5691180229187012 Generator Loss: -0.19402392208576202\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  18%|█▊        | 43/240 [27:20<2:06:40, 38.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [42/240] Avg Discriminator Loss: -0.3519421602179716 Avg Generator Loss: -0.24833674645631304\nEpoch [43/240] Step [0] Discriminator Loss: -0.29621291160583496 Generator Loss: -0.3063879609107971\nEpoch [43/240] Step [600] Discriminator Loss: -0.6717063188552856 Generator Loss: -0.12079226225614548\nEpoch [43/240] Step [1200] Discriminator Loss: -0.5375913381576538 Generator Loss: -0.1973997950553894\nEpoch [43/240] Step [1800] Discriminator Loss: -0.5338618755340576 Generator Loss: -0.21941111981868744\nEpoch [43/240] Step [2400] Discriminator Loss: -0.16562114655971527 Generator Loss: -0.21062369644641876\nEpoch [43/240] Step [3000] Discriminator Loss: -0.4773540496826172 Generator Loss: -0.20395027101039886\nEpoch [43/240] Step [3600] Discriminator Loss: -0.3912951350212097 Generator Loss: -0.4096151292324066\nEpoch [43/240] Step [4200] Discriminator Loss: -0.7233762145042419 Generator Loss: -0.09975089132785797\nEpoch [43/240] Step [4800] Discriminator Loss: 0.47469276189804077 Generator Loss: -0.47485285997390747\nEpoch [43/240] Step [5400] Discriminator Loss: -0.4004315137863159 Generator Loss: -0.41147661209106445\nEpoch [43/240] Step [6000] Discriminator Loss: -0.2657533288002014 Generator Loss: -0.4872939884662628\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  18%|█▊        | 44/240 [27:59<2:05:52, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [43/240] Avg Discriminator Loss: -0.22951570753649478 Avg Generator Loss: -0.27602758187282106\nEpoch [44/240] Step [0] Discriminator Loss: -0.5013113021850586 Generator Loss: -0.1424025297164917\nEpoch [44/240] Step [600] Discriminator Loss: -0.5749508142471313 Generator Loss: -0.22195303440093994\nEpoch [44/240] Step [1200] Discriminator Loss: -0.21920521557331085 Generator Loss: -0.2758476734161377\nEpoch [44/240] Step [1800] Discriminator Loss: -0.6324966549873352 Generator Loss: -0.2383526861667633\nEpoch [44/240] Step [2400] Discriminator Loss: -0.38497865200042725 Generator Loss: -0.19347892701625824\nEpoch [44/240] Step [3000] Discriminator Loss: -0.27938657999038696 Generator Loss: -0.1994824856519699\nEpoch [44/240] Step [3600] Discriminator Loss: -0.24337512254714966 Generator Loss: -0.2326786369085312\nEpoch [44/240] Step [4200] Discriminator Loss: -0.33309927582740784 Generator Loss: -0.2106514722108841\nEpoch [44/240] Step [4800] Discriminator Loss: -0.5416649580001831 Generator Loss: -0.09653697907924652\nEpoch [44/240] Step [5400] Discriminator Loss: -0.6988404989242554 Generator Loss: -0.12105419486761093\nEpoch [44/240] Step [6000] Discriminator Loss: -0.6439241766929626 Generator Loss: -0.22446352243423462\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  19%|█▉        | 45/240 [28:38<2:05:26, 38.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [44/240] Avg Discriminator Loss: -0.3524182956024404 Avg Generator Loss: -0.24157085901146735\nEpoch [45/240] Step [0] Discriminator Loss: -0.5620989203453064 Generator Loss: -0.2301660031080246\nEpoch [45/240] Step [600] Discriminator Loss: -0.6229936480522156 Generator Loss: -0.11522704362869263\nEpoch [45/240] Step [1200] Discriminator Loss: -0.06970930099487305 Generator Loss: -0.19882996380329132\nEpoch [45/240] Step [1800] Discriminator Loss: -0.19105404615402222 Generator Loss: -0.3785559833049774\nEpoch [45/240] Step [2400] Discriminator Loss: -0.41879579424858093 Generator Loss: -0.45817434787750244\nEpoch [45/240] Step [3000] Discriminator Loss: -0.6417015194892883 Generator Loss: -0.22385619580745697\nEpoch [45/240] Step [3600] Discriminator Loss: -0.5666948556900024 Generator Loss: -0.3145640790462494\nEpoch [45/240] Step [4200] Discriminator Loss: -0.36542361974716187 Generator Loss: -0.13716015219688416\nEpoch [45/240] Step [4800] Discriminator Loss: -0.4220423102378845 Generator Loss: -0.3310959041118622\nEpoch [45/240] Step [5400] Discriminator Loss: -0.4751749038696289 Generator Loss: -0.1552860289812088\nEpoch [45/240] Step [6000] Discriminator Loss: -0.7334309816360474 Generator Loss: -0.08938740193843842\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  19%|█▉        | 46/240 [29:16<2:04:39, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [45/240] Avg Discriminator Loss: -0.3292681228219371 Avg Generator Loss: -0.2520323385767666\nEpoch [46/240] Step [0] Discriminator Loss: -0.6260802745819092 Generator Loss: -0.23769640922546387\nEpoch [46/240] Step [600] Discriminator Loss: -0.6981611847877502 Generator Loss: -0.1905757188796997\nEpoch [46/240] Step [1200] Discriminator Loss: -0.32098275423049927 Generator Loss: -0.24467454850673676\nEpoch [46/240] Step [1800] Discriminator Loss: -0.6080575585365295 Generator Loss: -0.24430440366268158\nEpoch [46/240] Step [2400] Discriminator Loss: -0.2778458595275879 Generator Loss: -0.3216468393802643\nEpoch [46/240] Step [3000] Discriminator Loss: -0.8025343418121338 Generator Loss: -0.061601221561431885\nEpoch [46/240] Step [3600] Discriminator Loss: -0.5507141351699829 Generator Loss: -0.2954552471637726\nEpoch [46/240] Step [4200] Discriminator Loss: -0.4353126287460327 Generator Loss: -0.15764661133289337\nEpoch [46/240] Step [4800] Discriminator Loss: -0.04975917935371399 Generator Loss: -0.38622793555259705\nEpoch [46/240] Step [5400] Discriminator Loss: -0.7468806505203247 Generator Loss: -0.08899948000907898\nEpoch [46/240] Step [6000] Discriminator Loss: -0.36438077688217163 Generator Loss: -0.21802952885627747\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  20%|█▉        | 47/240 [29:55<2:03:55, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [46/240] Avg Discriminator Loss: -0.40479323448060633 Avg Generator Loss: -0.24656026106969123\nEpoch [47/240] Step [0] Discriminator Loss: -0.12281143665313721 Generator Loss: -0.11007755994796753\nEpoch [47/240] Step [600] Discriminator Loss: -0.1662755012512207 Generator Loss: -0.34189116954803467\nEpoch [47/240] Step [1200] Discriminator Loss: -0.048119544982910156 Generator Loss: -0.4016239643096924\nEpoch [47/240] Step [1800] Discriminator Loss: -0.31881073117256165 Generator Loss: -0.3298991918563843\nEpoch [47/240] Step [2400] Discriminator Loss: -0.5526074171066284 Generator Loss: -0.21030022203922272\nEpoch [47/240] Step [3000] Discriminator Loss: -0.6730425953865051 Generator Loss: -0.24833589792251587\nEpoch [47/240] Step [3600] Discriminator Loss: 0.18795621395111084 Generator Loss: -0.15857020020484924\nEpoch [47/240] Step [4200] Discriminator Loss: -0.6876016855239868 Generator Loss: -0.2076624631881714\nEpoch [47/240] Step [4800] Discriminator Loss: -0.2567678987979889 Generator Loss: -0.5518338084220886\nEpoch [47/240] Step [5400] Discriminator Loss: -0.19027888774871826 Generator Loss: -0.3853796124458313\nEpoch [47/240] Step [6000] Discriminator Loss: -0.5946074724197388 Generator Loss: -0.1696314811706543\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  20%|██        | 48/240 [30:33<2:03:12, 38.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [47/240] Avg Discriminator Loss: -0.3254728158151274 Avg Generator Loss: -0.2385582191248735\nEpoch [48/240] Step [0] Discriminator Loss: -0.09939426183700562 Generator Loss: -0.1393498331308365\nEpoch [48/240] Step [600] Discriminator Loss: -0.3728237748146057 Generator Loss: -0.3896617293357849\nEpoch [48/240] Step [1200] Discriminator Loss: -0.42125388979911804 Generator Loss: -0.17134644091129303\nEpoch [48/240] Step [1800] Discriminator Loss: -0.6539206504821777 Generator Loss: -0.13909003138542175\nEpoch [48/240] Step [2400] Discriminator Loss: -0.1456412374973297 Generator Loss: -0.34653791785240173\nEpoch [48/240] Step [3000] Discriminator Loss: -0.7659812569618225 Generator Loss: -0.02781175635755062\nEpoch [48/240] Step [3600] Discriminator Loss: -0.6486167907714844 Generator Loss: -0.1226944625377655\nEpoch [48/240] Step [4200] Discriminator Loss: 1.6294974088668823 Generator Loss: -0.048722557723522186\nEpoch [48/240] Step [4800] Discriminator Loss: -0.5991307497024536 Generator Loss: -0.09932572394609451\nEpoch [48/240] Step [5400] Discriminator Loss: 0.4157339334487915 Generator Loss: -0.6013069152832031\nEpoch [48/240] Step [6000] Discriminator Loss: -0.4958961308002472 Generator Loss: -0.2046109139919281\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  20%|██        | 49/240 [31:12<2:02:44, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [48/240] Avg Discriminator Loss: -0.3008472747254721 Avg Generator Loss: -0.2336281891298163\nEpoch [49/240] Step [0] Discriminator Loss: -0.6194758415222168 Generator Loss: -0.09809084236621857\nEpoch [49/240] Step [600] Discriminator Loss: -0.11920753121376038 Generator Loss: -0.16039039194583893\nEpoch [49/240] Step [1200] Discriminator Loss: -0.24777156114578247 Generator Loss: -0.2518005967140198\nEpoch [49/240] Step [1800] Discriminator Loss: -0.6418541669845581 Generator Loss: -0.14978057146072388\nEpoch [49/240] Step [2400] Discriminator Loss: -0.7459018230438232 Generator Loss: -0.1361638456583023\nEpoch [49/240] Step [3000] Discriminator Loss: -0.10273972153663635 Generator Loss: -0.34649762511253357\nEpoch [49/240] Step [3600] Discriminator Loss: 0.24794793128967285 Generator Loss: -0.2282896190881729\nEpoch [49/240] Step [4200] Discriminator Loss: -0.7373156547546387 Generator Loss: -0.12954825162887573\nEpoch [49/240] Step [4800] Discriminator Loss: -0.2908387780189514 Generator Loss: -0.518680214881897\nEpoch [49/240] Step [5400] Discriminator Loss: -0.7020260691642761 Generator Loss: -0.05833633244037628\nEpoch [49/240] Step [6000] Discriminator Loss: -0.5166531801223755 Generator Loss: -0.24147425591945648\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  21%|██        | 50/240 [31:51<2:02:53, 38.81s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [49/240] Avg Discriminator Loss: -0.39275220265755284 Avg Generator Loss: -0.23237691558692808\nEpoch [50/240] Step [0] Discriminator Loss: 0.07891684770584106 Generator Loss: -0.6822317242622375\nEpoch [50/240] Step [600] Discriminator Loss: -0.5938354730606079 Generator Loss: -0.27062898874282837\nEpoch [50/240] Step [1200] Discriminator Loss: -0.3701894283294678 Generator Loss: -0.31109818816185\nEpoch [50/240] Step [1800] Discriminator Loss: -0.6255690455436707 Generator Loss: -0.13327285647392273\nEpoch [50/240] Step [2400] Discriminator Loss: -0.3323020040988922 Generator Loss: -0.18484215438365936\nEpoch [50/240] Step [3000] Discriminator Loss: -0.5971181988716125 Generator Loss: -0.2587440311908722\nEpoch [50/240] Step [3600] Discriminator Loss: -0.459191232919693 Generator Loss: -0.2578415870666504\nEpoch [50/240] Step [4200] Discriminator Loss: -0.6099011898040771 Generator Loss: -0.17959308624267578\nEpoch [50/240] Step [4800] Discriminator Loss: -0.47495192289352417 Generator Loss: -0.31848955154418945\nEpoch [50/240] Step [5400] Discriminator Loss: -0.6432957649230957 Generator Loss: -0.15869563817977905\nEpoch [50/240] Step [6000] Discriminator Loss: -0.10169166326522827 Generator Loss: -0.1477605700492859\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  21%|██▏       | 51/240 [32:30<2:02:00, 38.73s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [50/240] Avg Discriminator Loss: -0.42368355759115883 Avg Generator Loss: -0.21418209084661016\nEpoch [51/240] Step [0] Discriminator Loss: -0.774655818939209 Generator Loss: -0.09969193488359451\nEpoch [51/240] Step [600] Discriminator Loss: -0.2532415986061096 Generator Loss: -0.3660062551498413\nEpoch [51/240] Step [1200] Discriminator Loss: -0.30403661727905273 Generator Loss: -0.4530186653137207\nEpoch [51/240] Step [1800] Discriminator Loss: -0.6327346563339233 Generator Loss: -0.09600178897380829\nEpoch [51/240] Step [2400] Discriminator Loss: -0.18078339099884033 Generator Loss: -0.24302737414836884\nEpoch [51/240] Step [3000] Discriminator Loss: -0.4150194823741913 Generator Loss: -0.385356605052948\nEpoch [51/240] Step [3600] Discriminator Loss: -0.647821307182312 Generator Loss: -0.3691484034061432\nEpoch [51/240] Step [4200] Discriminator Loss: -0.6288148760795593 Generator Loss: -0.16623136401176453\nEpoch [51/240] Step [4800] Discriminator Loss: -0.5240083932876587 Generator Loss: -0.4188075065612793\nEpoch [51/240] Step [5400] Discriminator Loss: -0.530353307723999 Generator Loss: -0.27751636505126953\nEpoch [51/240] Step [6000] Discriminator Loss: -0.5167354941368103 Generator Loss: -0.21821987628936768\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  22%|██▏       | 52/240 [33:08<2:01:08, 38.66s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [51/240] Avg Discriminator Loss: -0.4145863190729976 Avg Generator Loss: -0.2570297438446637\nEpoch [52/240] Step [0] Discriminator Loss: -0.5221505165100098 Generator Loss: -0.045923586934804916\nEpoch [52/240] Step [600] Discriminator Loss: -0.4741055965423584 Generator Loss: -0.11932438611984253\nEpoch [52/240] Step [1200] Discriminator Loss: -0.1120166927576065 Generator Loss: -0.17729370296001434\nEpoch [52/240] Step [1800] Discriminator Loss: -0.6742085814476013 Generator Loss: -0.178372323513031\nEpoch [52/240] Step [2400] Discriminator Loss: -0.06751632690429688 Generator Loss: -0.06988420337438583\nEpoch [52/240] Step [3000] Discriminator Loss: -0.3587411642074585 Generator Loss: -0.26224491000175476\nEpoch [52/240] Step [3600] Discriminator Loss: -0.10522185266017914 Generator Loss: -0.7924785614013672\nEpoch [52/240] Step [4200] Discriminator Loss: -0.5079119205474854 Generator Loss: -0.13755211234092712\nEpoch [52/240] Step [4800] Discriminator Loss: -0.39029461145401 Generator Loss: -0.42544567584991455\nEpoch [52/240] Step [5400] Discriminator Loss: -0.6102524995803833 Generator Loss: -0.20666897296905518\nEpoch [52/240] Step [6000] Discriminator Loss: -0.6502557992935181 Generator Loss: -0.1788095384836197\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  22%|██▏       | 53/240 [33:47<2:00:19, 38.61s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [52/240] Avg Discriminator Loss: -0.2171327653767425 Avg Generator Loss: -0.2768659139181668\nEpoch [53/240] Step [0] Discriminator Loss: -0.6788128614425659 Generator Loss: -0.1519223153591156\nEpoch [53/240] Step [600] Discriminator Loss: -0.10532251000404358 Generator Loss: -0.24104343354701996\nEpoch [53/240] Step [1200] Discriminator Loss: -0.485446572303772 Generator Loss: -0.2436656504869461\nEpoch [53/240] Step [1800] Discriminator Loss: 0.032860323786735535 Generator Loss: -0.38022667169570923\nEpoch [53/240] Step [2400] Discriminator Loss: -0.1069665253162384 Generator Loss: -0.20318476855754852\nEpoch [53/240] Step [3000] Discriminator Loss: 0.29734688997268677 Generator Loss: -0.589279055595398\nEpoch [53/240] Step [3600] Discriminator Loss: 0.067402184009552 Generator Loss: -0.40152329206466675\nEpoch [53/240] Step [4200] Discriminator Loss: -0.3344452381134033 Generator Loss: -0.37572693824768066\nEpoch [53/240] Step [4800] Discriminator Loss: -0.7120864987373352 Generator Loss: -0.08262934535741806\nEpoch [53/240] Step [5400] Discriminator Loss: -0.40312233567237854 Generator Loss: -0.3637782633304596\nEpoch [53/240] Step [6000] Discriminator Loss: -0.5538584589958191 Generator Loss: -0.1618305742740631\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  22%|██▎       | 54/240 [34:25<1:59:48, 38.65s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [53/240] Avg Discriminator Loss: -0.24529148351687652 Avg Generator Loss: -0.27755711817834183\nEpoch [54/240] Step [0] Discriminator Loss: -0.3909034729003906 Generator Loss: -0.6204033493995667\nEpoch [54/240] Step [600] Discriminator Loss: -0.21623528003692627 Generator Loss: -0.3730679750442505\nEpoch [54/240] Step [1200] Discriminator Loss: -0.32897844910621643 Generator Loss: -0.4087985157966614\nEpoch [54/240] Step [1800] Discriminator Loss: -0.4837278127670288 Generator Loss: -0.039682239294052124\nEpoch [54/240] Step [2400] Discriminator Loss: -0.531707763671875 Generator Loss: -0.2703406512737274\nEpoch [54/240] Step [3000] Discriminator Loss: -0.5136998891830444 Generator Loss: -0.27580857276916504\nEpoch [54/240] Step [3600] Discriminator Loss: -0.42910128831863403 Generator Loss: -0.05781903117895126\nEpoch [54/240] Step [4200] Discriminator Loss: -0.5388531684875488 Generator Loss: -0.21282050013542175\nEpoch [54/240] Step [4800] Discriminator Loss: -0.5632537603378296 Generator Loss: -0.07981117069721222\nEpoch [54/240] Step [5400] Discriminator Loss: -0.672031044960022 Generator Loss: -0.06553932279348373\nEpoch [54/240] Step [6000] Discriminator Loss: -0.2515544593334198 Generator Loss: -0.2878272533416748\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  23%|██▎       | 55/240 [35:04<1:59:08, 38.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [54/240] Avg Discriminator Loss: -0.37771708649265895 Avg Generator Loss: -0.22857209329831077\nEpoch [55/240] Step [0] Discriminator Loss: 0.021499454975128174 Generator Loss: -0.27595990896224976\nEpoch [55/240] Step [600] Discriminator Loss: -0.600457489490509 Generator Loss: -0.0662403553724289\nEpoch [55/240] Step [1200] Discriminator Loss: -0.46523717045783997 Generator Loss: -0.22298994660377502\nEpoch [55/240] Step [1800] Discriminator Loss: -0.7189204692840576 Generator Loss: -0.13167162239551544\nEpoch [55/240] Step [2400] Discriminator Loss: -0.3985465168952942 Generator Loss: -0.055772870779037476\nEpoch [55/240] Step [3000] Discriminator Loss: -0.6198121309280396 Generator Loss: -0.335471510887146\nEpoch [55/240] Step [3600] Discriminator Loss: -0.5036863088607788 Generator Loss: -0.24540820717811584\nEpoch [55/240] Step [4200] Discriminator Loss: -0.450417697429657 Generator Loss: -0.12790365517139435\nEpoch [55/240] Step [4800] Discriminator Loss: -0.5949174165725708 Generator Loss: -0.2603466808795929\nEpoch [55/240] Step [5400] Discriminator Loss: -0.07011663913726807 Generator Loss: -0.2571530044078827\nEpoch [55/240] Step [6000] Discriminator Loss: -0.7363851070404053 Generator Loss: -0.0799546092748642\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  23%|██▎       | 56/240 [35:42<1:58:21, 38.59s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [55/240] Avg Discriminator Loss: -0.44591190073734677 Avg Generator Loss: -0.2161658933256572\nEpoch [56/240] Step [0] Discriminator Loss: -0.7306697964668274 Generator Loss: -0.0747775137424469\nEpoch [56/240] Step [600] Discriminator Loss: -0.783444344997406 Generator Loss: -0.043781302869319916\nEpoch [56/240] Step [1200] Discriminator Loss: -0.46966803073883057 Generator Loss: -0.273459792137146\nEpoch [56/240] Step [1800] Discriminator Loss: -0.7416423559188843 Generator Loss: -0.0667978972196579\nEpoch [56/240] Step [2400] Discriminator Loss: -0.5782222747802734 Generator Loss: -0.06476438045501709\nEpoch [56/240] Step [3000] Discriminator Loss: 2.104693651199341 Generator Loss: -0.3666408956050873\nEpoch [56/240] Step [3600] Discriminator Loss: -0.1604110151529312 Generator Loss: -0.36427560448646545\nEpoch [56/240] Step [4200] Discriminator Loss: -0.3925703465938568 Generator Loss: -0.21823854744434357\nEpoch [56/240] Step [4800] Discriminator Loss: -0.15044674277305603 Generator Loss: -0.2997821569442749\nEpoch [56/240] Step [5400] Discriminator Loss: -0.5554772019386292 Generator Loss: -0.1678282469511032\nEpoch [56/240] Step [6000] Discriminator Loss: -0.6688866019248962 Generator Loss: -0.1065276563167572\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  24%|██▍       | 57/240 [36:21<1:57:37, 38.57s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [56/240] Avg Discriminator Loss: -0.31775343871160305 Avg Generator Loss: -0.23035992344247772\nEpoch [57/240] Step [0] Discriminator Loss: -0.4290991723537445 Generator Loss: -0.3495723009109497\nEpoch [57/240] Step [600] Discriminator Loss: -0.5895404815673828 Generator Loss: -0.20761317014694214\nEpoch [57/240] Step [1200] Discriminator Loss: -0.1715766191482544 Generator Loss: -0.4092191755771637\nEpoch [57/240] Step [1800] Discriminator Loss: -0.5329974293708801 Generator Loss: -0.19638517498970032\nEpoch [57/240] Step [2400] Discriminator Loss: 0.6273622512817383 Generator Loss: -0.3654303550720215\nEpoch [57/240] Step [3000] Discriminator Loss: -0.2745073437690735 Generator Loss: -0.4358551800251007\nEpoch [57/240] Step [3600] Discriminator Loss: -0.4833095073699951 Generator Loss: -0.11413193494081497\nEpoch [57/240] Step [4200] Discriminator Loss: -0.21368752419948578 Generator Loss: -0.3721054792404175\nEpoch [57/240] Step [4800] Discriminator Loss: -0.058497726917266846 Generator Loss: -0.29043564200401306\nEpoch [57/240] Step [5400] Discriminator Loss: -0.5899616479873657 Generator Loss: -0.2859325408935547\nEpoch [57/240] Step [6000] Discriminator Loss: 0.042606890201568604 Generator Loss: -0.2087699919939041\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  24%|██▍       | 58/240 [36:59<1:56:47, 38.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [57/240] Avg Discriminator Loss: -0.3411501588729712 Avg Generator Loss: -0.2334790475284442\nEpoch [58/240] Step [0] Discriminator Loss: -0.4510110318660736 Generator Loss: -0.2194620668888092\nEpoch [58/240] Step [600] Discriminator Loss: -0.6349151134490967 Generator Loss: -0.08083679527044296\nEpoch [58/240] Step [1200] Discriminator Loss: -0.6078709363937378 Generator Loss: -0.12674880027770996\nEpoch [58/240] Step [1800] Discriminator Loss: -0.480892151594162 Generator Loss: -0.17689484357833862\nEpoch [58/240] Step [2400] Discriminator Loss: -0.4209008812904358 Generator Loss: -0.08986556529998779\nEpoch [58/240] Step [3000] Discriminator Loss: -0.804594874382019 Generator Loss: -0.03145679086446762\nEpoch [58/240] Step [3600] Discriminator Loss: -0.13450482487678528 Generator Loss: -0.31855446100234985\nEpoch [58/240] Step [4200] Discriminator Loss: -0.2778546214103699 Generator Loss: -0.17989063262939453\nEpoch [58/240] Step [4800] Discriminator Loss: -0.7154187560081482 Generator Loss: -0.0970875695347786\nEpoch [58/240] Step [5400] Discriminator Loss: 0.14676761627197266 Generator Loss: -0.4875508248806\nEpoch [58/240] Step [6000] Discriminator Loss: 0.0512007474899292 Generator Loss: -0.276408851146698\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  25%|██▍       | 59/240 [37:38<1:56:01, 38.46s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [58/240] Avg Discriminator Loss: -0.3205085126307858 Avg Generator Loss: -0.23073734633706428\nEpoch [59/240] Step [0] Discriminator Loss: 1.0576595067977905 Generator Loss: -0.25593823194503784\nEpoch [59/240] Step [600] Discriminator Loss: -0.4903317987918854 Generator Loss: -0.21402110159397125\nEpoch [59/240] Step [1200] Discriminator Loss: -0.5015344619750977 Generator Loss: -0.2864460349082947\nEpoch [59/240] Step [1800] Discriminator Loss: -0.5894805788993835 Generator Loss: -0.2824719250202179\nEpoch [59/240] Step [2400] Discriminator Loss: -0.4422457814216614 Generator Loss: -0.224981427192688\nEpoch [59/240] Step [3000] Discriminator Loss: -0.5236128568649292 Generator Loss: -0.22039726376533508\nEpoch [59/240] Step [3600] Discriminator Loss: -0.3744591176509857 Generator Loss: -0.2967031002044678\nEpoch [59/240] Step [4200] Discriminator Loss: -0.5510348081588745 Generator Loss: -0.3732062578201294\nEpoch [59/240] Step [4800] Discriminator Loss: -0.5119218826293945 Generator Loss: -0.20323312282562256\nEpoch [59/240] Step [5400] Discriminator Loss: -0.475532203912735 Generator Loss: -0.2767125964164734\nEpoch [59/240] Step [6000] Discriminator Loss: -0.4283953607082367 Generator Loss: -0.060585811734199524\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  25%|██▌       | 60/240 [38:16<1:55:29, 38.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [59/240] Avg Discriminator Loss: -0.4161670303224644 Avg Generator Loss: -0.23379053580728207\nEpoch [60/240] Step [0] Discriminator Loss: -0.6519374251365662 Generator Loss: -0.16881684958934784\nEpoch [60/240] Step [600] Discriminator Loss: -0.3158179521560669 Generator Loss: -0.40124404430389404\nEpoch [60/240] Step [1200] Discriminator Loss: -0.6259146332740784 Generator Loss: -0.22041180729866028\nEpoch [60/240] Step [1800] Discriminator Loss: -0.71010822057724 Generator Loss: -0.08906376361846924\nEpoch [60/240] Step [2400] Discriminator Loss: -0.5082889199256897 Generator Loss: -0.17397728562355042\nEpoch [60/240] Step [3000] Discriminator Loss: -0.6743826866149902 Generator Loss: -0.11258314549922943\nEpoch [60/240] Step [3600] Discriminator Loss: -0.6522430181503296 Generator Loss: -0.09968627244234085\nEpoch [60/240] Step [4200] Discriminator Loss: -0.5093298554420471 Generator Loss: -0.40242618322372437\nEpoch [60/240] Step [4800] Discriminator Loss: 0.12597429752349854 Generator Loss: -0.3860214650630951\nEpoch [60/240] Step [5400] Discriminator Loss: -0.4947633743286133 Generator Loss: -0.12380187958478928\nEpoch [60/240] Step [6000] Discriminator Loss: -0.6829328536987305 Generator Loss: -0.17106859385967255\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  25%|██▌       | 61/240 [38:55<1:54:53, 38.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [60/240] Avg Discriminator Loss: -0.4601739498721811 Avg Generator Loss: -0.20203272600559305\nEpoch [61/240] Step [0] Discriminator Loss: -0.6655351519584656 Generator Loss: -0.10251641273498535\nEpoch [61/240] Step [600] Discriminator Loss: 0.7619302272796631 Generator Loss: -0.2574106752872467\nEpoch [61/240] Step [1200] Discriminator Loss: -0.2372455894947052 Generator Loss: -0.419449120759964\nEpoch [61/240] Step [1800] Discriminator Loss: -0.6985875368118286 Generator Loss: -0.09424340724945068\nEpoch [61/240] Step [2400] Discriminator Loss: -0.5477580428123474 Generator Loss: -0.07058198750019073\nEpoch [61/240] Step [3000] Discriminator Loss: -0.7793961763381958 Generator Loss: -0.06433006376028061\nEpoch [61/240] Step [3600] Discriminator Loss: -0.16727465391159058 Generator Loss: -0.18176577985286713\nEpoch [61/240] Step [4200] Discriminator Loss: -0.4807644784450531 Generator Loss: -0.08883363753557205\nEpoch [61/240] Step [4800] Discriminator Loss: -0.3147331774234772 Generator Loss: -0.08396642655134201\nEpoch [61/240] Step [5400] Discriminator Loss: -0.7312936186790466 Generator Loss: -0.08401656150817871\nEpoch [61/240] Step [6000] Discriminator Loss: -0.6580336093902588 Generator Loss: -0.15899261832237244\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  26%|██▌       | 62/240 [39:33<1:54:08, 38.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [61/240] Avg Discriminator Loss: -0.42253140199097083 Avg Generator Loss: -0.18318885284383873\nEpoch [62/240] Step [0] Discriminator Loss: -0.5369054079055786 Generator Loss: -0.22007304430007935\nEpoch [62/240] Step [600] Discriminator Loss: -0.5145424604415894 Generator Loss: -0.20617765188217163\nEpoch [62/240] Step [1200] Discriminator Loss: -0.6651802062988281 Generator Loss: -0.2021612823009491\nEpoch [62/240] Step [1800] Discriminator Loss: 0.015074431896209717 Generator Loss: -0.375180721282959\nEpoch [62/240] Step [2400] Discriminator Loss: -0.5167498588562012 Generator Loss: -0.19375289976596832\nEpoch [62/240] Step [3000] Discriminator Loss: -0.7603130340576172 Generator Loss: -0.034247417002916336\nEpoch [62/240] Step [3600] Discriminator Loss: 0.728594958782196 Generator Loss: -0.35205650329589844\nEpoch [62/240] Step [4200] Discriminator Loss: -0.6731671690940857 Generator Loss: -0.11904136836528778\nEpoch [62/240] Step [4800] Discriminator Loss: -0.6074056625366211 Generator Loss: -0.19472406804561615\nEpoch [62/240] Step [5400] Discriminator Loss: -0.7057341933250427 Generator Loss: -0.04915543645620346\nEpoch [62/240] Step [6000] Discriminator Loss: -0.43462660908699036 Generator Loss: -0.2666676640510559\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  26%|██▋       | 63/240 [40:12<1:53:36, 38.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [62/240] Avg Discriminator Loss: -0.3680605263118342 Avg Generator Loss: -0.2246709551471166\nEpoch [63/240] Step [0] Discriminator Loss: -0.5971028804779053 Generator Loss: -0.20803110301494598\nEpoch [63/240] Step [600] Discriminator Loss: -0.6327909231185913 Generator Loss: -0.14451119303703308\nEpoch [63/240] Step [1200] Discriminator Loss: -0.31073659658432007 Generator Loss: -0.12237201631069183\nEpoch [63/240] Step [1800] Discriminator Loss: -0.7150697112083435 Generator Loss: -0.15138649940490723\nEpoch [63/240] Step [2400] Discriminator Loss: -0.7723391652107239 Generator Loss: -0.0716637372970581\nEpoch [63/240] Step [3000] Discriminator Loss: -0.2419651448726654 Generator Loss: -0.14348763227462769\nEpoch [63/240] Step [3600] Discriminator Loss: -0.42739927768707275 Generator Loss: -0.5697736740112305\nEpoch [63/240] Step [4200] Discriminator Loss: -0.2762107849121094 Generator Loss: -0.5841004252433777\nEpoch [63/240] Step [4800] Discriminator Loss: -0.76272052526474 Generator Loss: -0.11599546670913696\nEpoch [63/240] Step [5400] Discriminator Loss: -0.27630114555358887 Generator Loss: -0.17330674827098846\nEpoch [63/240] Step [6000] Discriminator Loss: -0.5200031995773315 Generator Loss: -0.17767708003520966\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  27%|██▋       | 64/240 [40:50<1:52:58, 38.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [63/240] Avg Discriminator Loss: -0.33350560530310586 Avg Generator Loss: -0.23699305027095607\nEpoch [64/240] Step [0] Discriminator Loss: 0.046518176794052124 Generator Loss: -0.3721064329147339\nEpoch [64/240] Step [600] Discriminator Loss: -0.4534505605697632 Generator Loss: -0.13226649165153503\nEpoch [64/240] Step [1200] Discriminator Loss: -0.3636915683746338 Generator Loss: -0.15015743672847748\nEpoch [64/240] Step [1800] Discriminator Loss: -0.6023242473602295 Generator Loss: -0.11408964544534683\nEpoch [64/240] Step [2400] Discriminator Loss: -0.5559226870536804 Generator Loss: -0.15752193331718445\nEpoch [64/240] Step [3000] Discriminator Loss: -0.28354412317276 Generator Loss: -0.1168665960431099\nEpoch [64/240] Step [3600] Discriminator Loss: -0.5882106423377991 Generator Loss: -0.3076247572898865\nEpoch [64/240] Step [4200] Discriminator Loss: -0.6919313669204712 Generator Loss: -0.12999527156352997\nEpoch [64/240] Step [4800] Discriminator Loss: -0.31925249099731445 Generator Loss: -0.22303684055805206\nEpoch [64/240] Step [5400] Discriminator Loss: -0.766842246055603 Generator Loss: -0.1464095562696457\nEpoch [64/240] Step [6000] Discriminator Loss: -0.7127121686935425 Generator Loss: -0.01931821182370186\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  27%|██▋       | 65/240 [41:29<1:52:19, 38.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [64/240] Avg Discriminator Loss: -0.42855100958666087 Avg Generator Loss: -0.2207148822618055\nEpoch [65/240] Step [0] Discriminator Loss: -0.1780529022216797 Generator Loss: -0.2853880822658539\nEpoch [65/240] Step [600] Discriminator Loss: -0.5972445011138916 Generator Loss: -0.15102145075798035\nEpoch [65/240] Step [1200] Discriminator Loss: 0.013808727264404297 Generator Loss: -0.32670027017593384\nEpoch [65/240] Step [1800] Discriminator Loss: -0.7442438006401062 Generator Loss: -0.036850061267614365\nEpoch [65/240] Step [2400] Discriminator Loss: -0.19855016469955444 Generator Loss: -0.22174690663814545\nEpoch [65/240] Step [3000] Discriminator Loss: -0.6034062504768372 Generator Loss: -0.0702841579914093\nEpoch [65/240] Step [3600] Discriminator Loss: -0.4708617031574249 Generator Loss: -0.21382039785385132\nEpoch [65/240] Step [4200] Discriminator Loss: -0.5371590852737427 Generator Loss: -0.2749742865562439\nEpoch [65/240] Step [4800] Discriminator Loss: -0.4514748454093933 Generator Loss: -0.079885333776474\nEpoch [65/240] Step [5400] Discriminator Loss: 0.505516767501831 Generator Loss: -0.5007514357566833\nEpoch [65/240] Step [6000] Discriminator Loss: -0.31872063875198364 Generator Loss: -0.14622530341148376\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  28%|██▊       | 66/240 [42:07<1:51:45, 38.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [65/240] Avg Discriminator Loss: -0.4413941285876564 Avg Generator Loss: -0.21395853412893664\nEpoch [66/240] Step [0] Discriminator Loss: -0.6440705060958862 Generator Loss: -0.1240035817027092\nEpoch [66/240] Step [600] Discriminator Loss: -0.6641353964805603 Generator Loss: -0.19326187670230865\nEpoch [66/240] Step [1200] Discriminator Loss: 3.6919901371002197 Generator Loss: -0.40021055936813354\nEpoch [66/240] Step [1800] Discriminator Loss: -0.7134656310081482 Generator Loss: -0.11390890181064606\nEpoch [66/240] Step [2400] Discriminator Loss: -0.4242486357688904 Generator Loss: -0.1863699108362198\nEpoch [66/240] Step [3000] Discriminator Loss: -0.3135521411895752 Generator Loss: -0.347401887178421\nEpoch [66/240] Step [3600] Discriminator Loss: -0.07426008582115173 Generator Loss: -0.3854145407676697\nEpoch [66/240] Step [4200] Discriminator Loss: -0.3323526978492737 Generator Loss: -0.1249246895313263\nEpoch [66/240] Step [4800] Discriminator Loss: -0.4211418330669403 Generator Loss: -0.008933549746870995\nEpoch [66/240] Step [5400] Discriminator Loss: -0.7236844897270203 Generator Loss: -0.06331777572631836\nEpoch [66/240] Step [6000] Discriminator Loss: -0.4768191874027252 Generator Loss: -0.13426220417022705\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  28%|██▊       | 67/240 [42:46<1:51:27, 38.66s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [66/240] Avg Discriminator Loss: -0.3635621726676658 Avg Generator Loss: -0.2288406369081893\nEpoch [67/240] Step [0] Discriminator Loss: -0.01239001750946045 Generator Loss: -0.15121598541736603\nEpoch [67/240] Step [600] Discriminator Loss: 1.0344250202178955 Generator Loss: -0.5505276918411255\nEpoch [67/240] Step [1200] Discriminator Loss: -0.3518334627151489 Generator Loss: -0.053541913628578186\nEpoch [67/240] Step [1800] Discriminator Loss: -0.6960193514823914 Generator Loss: -0.17697679996490479\nEpoch [67/240] Step [2400] Discriminator Loss: -0.572722315788269 Generator Loss: -0.15249043703079224\nEpoch [67/240] Step [3000] Discriminator Loss: 0.023450493812561035 Generator Loss: -0.06922152638435364\nEpoch [67/240] Step [3600] Discriminator Loss: -0.45034563541412354 Generator Loss: -0.3072598874568939\nEpoch [67/240] Step [4200] Discriminator Loss: -0.5420324802398682 Generator Loss: -0.2627638876438141\nEpoch [67/240] Step [4800] Discriminator Loss: -0.5167854428291321 Generator Loss: -0.24033816158771515\nEpoch [67/240] Step [5400] Discriminator Loss: -0.11934864521026611 Generator Loss: -0.19229935109615326\nEpoch [67/240] Step [6000] Discriminator Loss: -0.6160041093826294 Generator Loss: -0.18690702319145203\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  28%|██▊       | 68/240 [43:26<1:51:43, 38.98s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [67/240] Avg Discriminator Loss: -0.4621447189932778 Avg Generator Loss: -0.21248822144809223\nEpoch [68/240] Step [0] Discriminator Loss: -0.5210021138191223 Generator Loss: -0.21583043038845062\nEpoch [68/240] Step [600] Discriminator Loss: -0.31411033868789673 Generator Loss: -0.25467634201049805\nEpoch [68/240] Step [1200] Discriminator Loss: -0.5724826455116272 Generator Loss: -0.1583467423915863\nEpoch [68/240] Step [1800] Discriminator Loss: -0.806732177734375 Generator Loss: -0.05977776274085045\nEpoch [68/240] Step [2400] Discriminator Loss: -0.45920902490615845 Generator Loss: -0.5797747373580933\nEpoch [68/240] Step [3000] Discriminator Loss: -0.7147088050842285 Generator Loss: -0.17123281955718994\nEpoch [68/240] Step [3600] Discriminator Loss: -0.47859716415405273 Generator Loss: -0.49948060512542725\nEpoch [68/240] Step [4200] Discriminator Loss: -0.6788880825042725 Generator Loss: -0.12478433549404144\nEpoch [68/240] Step [4800] Discriminator Loss: -0.2708449363708496 Generator Loss: -0.26967862248420715\nEpoch [68/240] Step [5400] Discriminator Loss: -0.5759575366973877 Generator Loss: -0.13077600300312042\nEpoch [68/240] Step [6000] Discriminator Loss: -0.35284659266471863 Generator Loss: -0.2694036662578583\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  29%|██▉       | 69/240 [44:05<1:50:52, 38.90s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [68/240] Avg Discriminator Loss: -0.4760885092092084 Avg Generator Loss: -0.22451050425350885\nEpoch [69/240] Step [0] Discriminator Loss: -0.42572465538978577 Generator Loss: -0.43282970786094666\nEpoch [69/240] Step [600] Discriminator Loss: -0.6167023181915283 Generator Loss: -0.07667094469070435\nEpoch [69/240] Step [1200] Discriminator Loss: -0.25531408190727234 Generator Loss: -0.37311655282974243\nEpoch [69/240] Step [1800] Discriminator Loss: -0.4897482395172119 Generator Loss: -0.13222192227840424\nEpoch [69/240] Step [2400] Discriminator Loss: -0.47666382789611816 Generator Loss: -0.22013545036315918\nEpoch [69/240] Step [3000] Discriminator Loss: -0.5654017329216003 Generator Loss: -0.183496356010437\nEpoch [69/240] Step [3600] Discriminator Loss: -0.49925801157951355 Generator Loss: -0.24132005870342255\nEpoch [69/240] Step [4200] Discriminator Loss: -0.6161796450614929 Generator Loss: -0.04761171340942383\nEpoch [69/240] Step [4800] Discriminator Loss: -0.028954312205314636 Generator Loss: -0.29232293367385864\nEpoch [69/240] Step [5400] Discriminator Loss: -0.6910020112991333 Generator Loss: -0.1196243166923523\nEpoch [69/240] Step [6000] Discriminator Loss: -0.7395690679550171 Generator Loss: -0.09497827291488647\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  29%|██▉       | 70/240 [44:44<1:50:13, 38.90s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [69/240] Avg Discriminator Loss: -0.3659068412068999 Avg Generator Loss: -0.22057515973627786\nEpoch [70/240] Step [0] Discriminator Loss: -0.7167046070098877 Generator Loss: -0.12209336459636688\nEpoch [70/240] Step [600] Discriminator Loss: -0.7577863931655884 Generator Loss: -0.10952556878328323\nEpoch [70/240] Step [1200] Discriminator Loss: -0.7688474655151367 Generator Loss: -0.14702652394771576\nEpoch [70/240] Step [1800] Discriminator Loss: -0.8056024312973022 Generator Loss: -0.09793166071176529\nEpoch [70/240] Step [2400] Discriminator Loss: -0.45572522282600403 Generator Loss: -0.30038267374038696\nEpoch [70/240] Step [3000] Discriminator Loss: -0.598926305770874 Generator Loss: -0.1011894941329956\nEpoch [70/240] Step [3600] Discriminator Loss: -0.33640599250793457 Generator Loss: -0.2563614845275879\nEpoch [70/240] Step [4200] Discriminator Loss: -0.3797447979450226 Generator Loss: -0.13947135210037231\nEpoch [70/240] Step [4800] Discriminator Loss: -0.39530259370803833 Generator Loss: -0.20243972539901733\nEpoch [70/240] Step [5400] Discriminator Loss: -0.5961074233055115 Generator Loss: -0.19672822952270508\nEpoch [70/240] Step [6000] Discriminator Loss: -0.18561622500419617 Generator Loss: -0.5126775503158569\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  30%|██▉       | 71/240 [45:23<1:49:29, 38.88s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [70/240] Avg Discriminator Loss: -0.4174099767601097 Avg Generator Loss: -0.23014310792074863\nEpoch [71/240] Step [0] Discriminator Loss: -0.5708035230636597 Generator Loss: -0.118313729763031\nEpoch [71/240] Step [600] Discriminator Loss: -0.09020597487688065 Generator Loss: -0.3652997314929962\nEpoch [71/240] Step [1200] Discriminator Loss: -0.22406545281410217 Generator Loss: -0.22150367498397827\nEpoch [71/240] Step [1800] Discriminator Loss: -0.5394321084022522 Generator Loss: -0.15939724445343018\nEpoch [71/240] Step [2400] Discriminator Loss: -0.48641151189804077 Generator Loss: -0.15228521823883057\nEpoch [71/240] Step [3000] Discriminator Loss: -0.30588847398757935 Generator Loss: -0.15112654864788055\nEpoch [71/240] Step [3600] Discriminator Loss: -0.42429161071777344 Generator Loss: -0.4272451400756836\nEpoch [71/240] Step [4200] Discriminator Loss: -0.4834805727005005 Generator Loss: -0.04739457368850708\nEpoch [71/240] Step [4800] Discriminator Loss: -0.4088636636734009 Generator Loss: -0.154625803232193\nEpoch [71/240] Step [5400] Discriminator Loss: -0.6439865231513977 Generator Loss: -0.14142322540283203\nEpoch [71/240] Step [6000] Discriminator Loss: -0.5742747187614441 Generator Loss: -0.2332448661327362\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  30%|███       | 72/240 [46:01<1:48:48, 38.86s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [71/240] Avg Discriminator Loss: -0.2648980785093028 Avg Generator Loss: -0.24290501834285674\nEpoch [72/240] Step [0] Discriminator Loss: -0.7281813025474548 Generator Loss: -0.09642353653907776\nEpoch [72/240] Step [600] Discriminator Loss: -0.7368280291557312 Generator Loss: -0.12491467595100403\nEpoch [72/240] Step [1200] Discriminator Loss: -0.7044703364372253 Generator Loss: -0.1586805135011673\nEpoch [72/240] Step [1800] Discriminator Loss: -0.708139181137085 Generator Loss: -0.11407846212387085\nEpoch [72/240] Step [2400] Discriminator Loss: -0.4008229374885559 Generator Loss: -0.39889320731163025\nEpoch [72/240] Step [3000] Discriminator Loss: 0.18942469358444214 Generator Loss: -0.44031330943107605\nEpoch [72/240] Step [3600] Discriminator Loss: 0.14989417791366577 Generator Loss: -0.5367641448974609\nEpoch [72/240] Step [4200] Discriminator Loss: -0.3736829459667206 Generator Loss: -0.31833145022392273\nEpoch [72/240] Step [4800] Discriminator Loss: -0.20638515055179596 Generator Loss: -0.2558709383010864\nEpoch [72/240] Step [5400] Discriminator Loss: -0.4179534912109375 Generator Loss: -0.22726339101791382\nEpoch [72/240] Step [6000] Discriminator Loss: -0.27759161591529846 Generator Loss: -0.15176908671855927\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  30%|███       | 73/240 [46:40<1:48:10, 38.87s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [72/240] Avg Discriminator Loss: -0.3166485639773446 Avg Generator Loss: -0.2801407232450751\nEpoch [73/240] Step [0] Discriminator Loss: -0.5914274454116821 Generator Loss: -0.13337266445159912\nEpoch [73/240] Step [600] Discriminator Loss: -0.519473671913147 Generator Loss: -0.11445273458957672\nEpoch [73/240] Step [1200] Discriminator Loss: -0.43676888942718506 Generator Loss: -0.32800254225730896\nEpoch [73/240] Step [1800] Discriminator Loss: -0.7100256085395813 Generator Loss: -0.11918429285287857\nEpoch [73/240] Step [2400] Discriminator Loss: -0.5576005578041077 Generator Loss: -0.25247859954833984\nEpoch [73/240] Step [3000] Discriminator Loss: -0.5429372787475586 Generator Loss: -0.39635494351387024\nEpoch [73/240] Step [3600] Discriminator Loss: -0.4663968086242676 Generator Loss: -0.2080189287662506\nEpoch [73/240] Step [4200] Discriminator Loss: -0.09394145011901855 Generator Loss: -0.41766226291656494\nEpoch [73/240] Step [4800] Discriminator Loss: 0.8531683087348938 Generator Loss: -0.9416645765304565\nEpoch [73/240] Step [5400] Discriminator Loss: -0.35130104422569275 Generator Loss: -0.23859436810016632\nEpoch [73/240] Step [6000] Discriminator Loss: -0.4517551064491272 Generator Loss: -0.21181868016719818\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  31%|███       | 74/240 [47:19<1:47:22, 38.81s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [73/240] Avg Discriminator Loss: -0.34168710379482625 Avg Generator Loss: -0.2651739914120335\nEpoch [74/240] Step [0] Discriminator Loss: -0.2688670754432678 Generator Loss: -0.08967617899179459\nEpoch [74/240] Step [600] Discriminator Loss: -0.7647013664245605 Generator Loss: -0.1147046685218811\nEpoch [74/240] Step [1200] Discriminator Loss: 0.17644721269607544 Generator Loss: -0.5257501006126404\nEpoch [74/240] Step [1800] Discriminator Loss: -0.14706936478614807 Generator Loss: -0.27870050072669983\nEpoch [74/240] Step [2400] Discriminator Loss: -0.2521267533302307 Generator Loss: -0.2081693708896637\nEpoch [74/240] Step [3000] Discriminator Loss: -0.4807155728340149 Generator Loss: -0.14840997755527496\nEpoch [74/240] Step [3600] Discriminator Loss: -0.39434635639190674 Generator Loss: -0.4292665421962738\nEpoch [74/240] Step [4200] Discriminator Loss: -0.6008650660514832 Generator Loss: -0.23496806621551514\nEpoch [74/240] Step [4800] Discriminator Loss: -0.7903864979743958 Generator Loss: -0.16845126450061798\nEpoch [74/240] Step [5400] Discriminator Loss: -0.5187239646911621 Generator Loss: -0.1885337084531784\nEpoch [74/240] Step [6000] Discriminator Loss: -0.5550243258476257 Generator Loss: -0.16130991280078888\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  31%|███▏      | 75/240 [47:58<1:46:40, 38.79s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [74/240] Avg Discriminator Loss: -0.4018265497444313 Avg Generator Loss: -0.23556344401800916\nEpoch [75/240] Step [0] Discriminator Loss: -0.6043471693992615 Generator Loss: -0.19765877723693848\nEpoch [75/240] Step [600] Discriminator Loss: -0.7010399699211121 Generator Loss: -0.252888560295105\nEpoch [75/240] Step [1200] Discriminator Loss: -0.5947408676147461 Generator Loss: -0.18838095664978027\nEpoch [75/240] Step [1800] Discriminator Loss: -0.6175153255462646 Generator Loss: -0.248317688703537\nEpoch [75/240] Step [2400] Discriminator Loss: -0.5519882440567017 Generator Loss: -0.17896977066993713\nEpoch [75/240] Step [3000] Discriminator Loss: -0.7257806062698364 Generator Loss: -0.2105879783630371\nEpoch [75/240] Step [3600] Discriminator Loss: -0.6456807851791382 Generator Loss: -0.20963653922080994\nEpoch [75/240] Step [4200] Discriminator Loss: -0.7145066857337952 Generator Loss: -0.19372707605361938\nEpoch [75/240] Step [4800] Discriminator Loss: 0.05096612870693207 Generator Loss: -0.2567094564437866\nEpoch [75/240] Step [5400] Discriminator Loss: 0.011014103889465332 Generator Loss: -0.28690603375434875\nEpoch [75/240] Step [6000] Discriminator Loss: -0.3267827033996582 Generator Loss: -0.3574867248535156\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  32%|███▏      | 76/240 [48:37<1:46:09, 38.84s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [75/240] Avg Discriminator Loss: -0.4305972959641572 Avg Generator Loss: -0.2472958131642132\nEpoch [76/240] Step [0] Discriminator Loss: -0.46786829829216003 Generator Loss: -0.21253669261932373\nEpoch [76/240] Step [600] Discriminator Loss: -0.575417697429657 Generator Loss: -0.13161638379096985\nEpoch [76/240] Step [1200] Discriminator Loss: -0.5928876996040344 Generator Loss: -0.21684269607067108\nEpoch [76/240] Step [1800] Discriminator Loss: -0.4981013536453247 Generator Loss: -0.37309786677360535\nEpoch [76/240] Step [2400] Discriminator Loss: -0.6124464869499207 Generator Loss: -0.21607357263565063\nEpoch [76/240] Step [3000] Discriminator Loss: -0.5872681140899658 Generator Loss: -0.16865196824073792\nEpoch [76/240] Step [3600] Discriminator Loss: -0.6410685777664185 Generator Loss: -0.19809594750404358\nEpoch [76/240] Step [4200] Discriminator Loss: -0.7198894619941711 Generator Loss: -0.15306667983531952\nEpoch [76/240] Step [4800] Discriminator Loss: -0.6689484119415283 Generator Loss: -0.23041342198848724\nEpoch [76/240] Step [5400] Discriminator Loss: -0.32777225971221924 Generator Loss: -0.39048027992248535\nEpoch [76/240] Step [6000] Discriminator Loss: -0.6732591986656189 Generator Loss: -0.16547437012195587\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  32%|███▏      | 77/240 [49:15<1:45:30, 38.84s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [76/240] Avg Discriminator Loss: -0.5076955525211362 Avg Generator Loss: -0.2210248232078858\nEpoch [77/240] Step [0] Discriminator Loss: -0.4415510594844818 Generator Loss: -0.14995375275611877\nEpoch [77/240] Step [600] Discriminator Loss: -0.6792361736297607 Generator Loss: -0.09680528938770294\nEpoch [77/240] Step [1200] Discriminator Loss: -0.47313588857650757 Generator Loss: -0.28337010741233826\nEpoch [77/240] Step [1800] Discriminator Loss: -0.6911324858665466 Generator Loss: -0.121808722615242\nEpoch [77/240] Step [2400] Discriminator Loss: -0.4862012267112732 Generator Loss: -0.25343334674835205\nEpoch [77/240] Step [3000] Discriminator Loss: -0.20044559240341187 Generator Loss: -0.17426760494709015\nEpoch [77/240] Step [3600] Discriminator Loss: -0.2730675935745239 Generator Loss: -0.3295048177242279\nEpoch [77/240] Step [4200] Discriminator Loss: -0.4998956024646759 Generator Loss: -0.16299159824848175\nEpoch [77/240] Step [4800] Discriminator Loss: -0.7305964827537537 Generator Loss: -0.039796292781829834\nEpoch [77/240] Step [5400] Discriminator Loss: -0.528316855430603 Generator Loss: -0.2281865030527115\nEpoch [77/240] Step [6000] Discriminator Loss: -0.533086895942688 Generator Loss: -0.12888012826442719\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  32%|███▎      | 78/240 [49:54<1:44:57, 38.87s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [77/240] Avg Discriminator Loss: -0.5279042852885557 Avg Generator Loss: -0.1611831504339864\nEpoch [78/240] Step [0] Discriminator Loss: -0.4922358989715576 Generator Loss: -0.6347401738166809\nEpoch [78/240] Step [600] Discriminator Loss: -0.415346622467041 Generator Loss: -0.2100328505039215\nEpoch [78/240] Step [1200] Discriminator Loss: -0.14880673587322235 Generator Loss: -0.397529274225235\nEpoch [78/240] Step [1800] Discriminator Loss: -0.7230513095855713 Generator Loss: -0.14477229118347168\nEpoch [78/240] Step [2400] Discriminator Loss: 0.5129299163818359 Generator Loss: -0.6961105465888977\nEpoch [78/240] Step [3000] Discriminator Loss: -0.3389800786972046 Generator Loss: -0.34199759364128113\nEpoch [78/240] Step [3600] Discriminator Loss: -0.5847331285476685 Generator Loss: -0.2789911925792694\nEpoch [78/240] Step [4200] Discriminator Loss: -0.19935885071754456 Generator Loss: -0.610935389995575\nEpoch [78/240] Step [4800] Discriminator Loss: -0.3965553939342499 Generator Loss: -0.24407315254211426\nEpoch [78/240] Step [5400] Discriminator Loss: -0.5656142234802246 Generator Loss: -0.13887658715248108\nEpoch [78/240] Step [6000] Discriminator Loss: -0.5888458490371704 Generator Loss: -0.15832915902137756\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  33%|███▎      | 79/240 [50:33<1:44:26, 38.92s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [78/240] Avg Discriminator Loss: -0.3835572680055877 Avg Generator Loss: -0.24136238139900532\nEpoch [79/240] Step [0] Discriminator Loss: -0.4656856060028076 Generator Loss: -0.15091896057128906\nEpoch [79/240] Step [600] Discriminator Loss: -0.6602168679237366 Generator Loss: -0.14129963517189026\nEpoch [79/240] Step [1200] Discriminator Loss: -0.6419663429260254 Generator Loss: -0.15513624250888824\nEpoch [79/240] Step [1800] Discriminator Loss: -0.5863448977470398 Generator Loss: -0.19476665556430817\nEpoch [79/240] Step [2400] Discriminator Loss: -0.4995110034942627 Generator Loss: -0.2354174554347992\nEpoch [79/240] Step [3000] Discriminator Loss: -0.6500121355056763 Generator Loss: -0.15418413281440735\nEpoch [79/240] Step [3600] Discriminator Loss: -0.6938158869743347 Generator Loss: -0.24568825960159302\nEpoch [79/240] Step [4200] Discriminator Loss: -0.7306818962097168 Generator Loss: -0.07372672855854034\nEpoch [79/240] Step [4800] Discriminator Loss: -0.5912373065948486 Generator Loss: -0.2820815145969391\nEpoch [79/240] Step [5400] Discriminator Loss: -0.6561117768287659 Generator Loss: -0.043611690402030945\nEpoch [79/240] Step [6000] Discriminator Loss: -0.4741145074367523 Generator Loss: -0.30259501934051514\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  33%|███▎      | 80/240 [51:12<1:43:50, 38.94s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [79/240] Avg Discriminator Loss: -0.5239841361895149 Avg Generator Loss: -0.21214832540860762\nEpoch [80/240] Step [0] Discriminator Loss: -0.7263524532318115 Generator Loss: -0.16513314843177795\nEpoch [80/240] Step [600] Discriminator Loss: -0.6260907649993896 Generator Loss: -0.11983741819858551\nEpoch [80/240] Step [1200] Discriminator Loss: 0.08065836131572723 Generator Loss: -0.44385573267936707\nEpoch [80/240] Step [1800] Discriminator Loss: -0.48753470182418823 Generator Loss: -0.2345174252986908\nEpoch [80/240] Step [2400] Discriminator Loss: -0.7280576229095459 Generator Loss: -0.12233786284923553\nEpoch [80/240] Step [3000] Discriminator Loss: -0.5556381344795227 Generator Loss: -0.17080743610858917\nEpoch [80/240] Step [3600] Discriminator Loss: 0.974419355392456 Generator Loss: -0.3292946219444275\nEpoch [80/240] Step [4200] Discriminator Loss: -0.666062593460083 Generator Loss: -0.17291156947612762\nEpoch [80/240] Step [4800] Discriminator Loss: 0.5351413488388062 Generator Loss: -0.4897056221961975\nEpoch [80/240] Step [5400] Discriminator Loss: 0.19679027795791626 Generator Loss: -0.2676113545894623\nEpoch [80/240] Step [6000] Discriminator Loss: 0.10391556471586227 Generator Loss: -0.3108415901660919\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  34%|███▍      | 81/240 [51:51<1:43:16, 38.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [80/240] Avg Discriminator Loss: -0.2826085997943258 Avg Generator Loss: -0.2748696255146256\nEpoch [81/240] Step [0] Discriminator Loss: -0.4095383882522583 Generator Loss: -0.29549553990364075\nEpoch [81/240] Step [600] Discriminator Loss: -0.5647419095039368 Generator Loss: -0.1605617105960846\nEpoch [81/240] Step [1200] Discriminator Loss: -0.609173059463501 Generator Loss: -0.136154443025589\nEpoch [81/240] Step [1800] Discriminator Loss: 0.16120022535324097 Generator Loss: -0.28864702582359314\nEpoch [81/240] Step [2400] Discriminator Loss: -0.6480870246887207 Generator Loss: -0.17481976747512817\nEpoch [81/240] Step [3000] Discriminator Loss: -0.6285662651062012 Generator Loss: -0.14110463857650757\nEpoch [81/240] Step [3600] Discriminator Loss: -0.6704529523849487 Generator Loss: -0.17139199376106262\nEpoch [81/240] Step [4200] Discriminator Loss: -0.6114563345909119 Generator Loss: -0.19867612421512604\nEpoch [81/240] Step [4800] Discriminator Loss: -0.3056756258010864 Generator Loss: -0.22392265498638153\nEpoch [81/240] Step [5400] Discriminator Loss: -0.6116807460784912 Generator Loss: -0.25006431341171265\nEpoch [81/240] Step [6000] Discriminator Loss: -0.587535560131073 Generator Loss: -0.1269380748271942\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  34%|███▍      | 82/240 [52:30<1:42:37, 38.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [81/240] Avg Discriminator Loss: -0.45359537878752626 Avg Generator Loss: -0.23831266328528689\nEpoch [82/240] Step [0] Discriminator Loss: -0.6632206439971924 Generator Loss: -0.13220864534378052\nEpoch [82/240] Step [600] Discriminator Loss: -0.7780088782310486 Generator Loss: -0.105948805809021\nEpoch [82/240] Step [1200] Discriminator Loss: -0.3989561200141907 Generator Loss: -0.3333929181098938\nEpoch [82/240] Step [1800] Discriminator Loss: -0.517270028591156 Generator Loss: -0.12760069966316223\nEpoch [82/240] Step [2400] Discriminator Loss: -0.4081254005432129 Generator Loss: -0.21552348136901855\nEpoch [82/240] Step [3000] Discriminator Loss: -0.7568364143371582 Generator Loss: -0.12626108527183533\nEpoch [82/240] Step [3600] Discriminator Loss: -0.32807597517967224 Generator Loss: -0.45477059483528137\nEpoch [82/240] Step [4200] Discriminator Loss: -0.5902742743492126 Generator Loss: -0.2284168154001236\nEpoch [82/240] Step [4800] Discriminator Loss: -0.33744174242019653 Generator Loss: -0.3050636649131775\nEpoch [82/240] Step [5400] Discriminator Loss: -0.14766128361225128 Generator Loss: -0.3214143216609955\nEpoch [82/240] Step [6000] Discriminator Loss: 0.21700865030288696 Generator Loss: -0.8834362626075745\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  35%|███▍      | 83/240 [53:10<1:42:07, 39.03s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [82/240] Avg Discriminator Loss: -0.24990853218313974 Avg Generator Loss: -0.27076216474953263\nEpoch [83/240] Step [0] Discriminator Loss: -0.21007704734802246 Generator Loss: -0.42480358481407166\nEpoch [83/240] Step [600] Discriminator Loss: -0.4960848093032837 Generator Loss: -0.2414434850215912\nEpoch [83/240] Step [1200] Discriminator Loss: -0.23945094645023346 Generator Loss: -0.40968769788742065\nEpoch [83/240] Step [1800] Discriminator Loss: -0.2516629993915558 Generator Loss: -0.2730562388896942\nEpoch [83/240] Step [2400] Discriminator Loss: -0.3516303300857544 Generator Loss: -0.4100247621536255\nEpoch [83/240] Step [3000] Discriminator Loss: -0.7211388945579529 Generator Loss: -0.11344175040721893\nEpoch [83/240] Step [3600] Discriminator Loss: -0.4687293469905853 Generator Loss: -0.35235846042633057\nEpoch [83/240] Step [4200] Discriminator Loss: -0.6755269169807434 Generator Loss: -0.1754467636346817\nEpoch [83/240] Step [4800] Discriminator Loss: -0.007875442504882812 Generator Loss: -0.1708265095949173\nEpoch [83/240] Step [5400] Discriminator Loss: -0.04684439301490784 Generator Loss: -0.41624799370765686\nEpoch [83/240] Step [6000] Discriminator Loss: -0.5119973421096802 Generator Loss: -0.3208636939525604\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  35%|███▌      | 84/240 [53:48<1:41:18, 38.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [83/240] Avg Discriminator Loss: -0.2264273451579796 Avg Generator Loss: -0.2768844979688962\nEpoch [84/240] Step [0] Discriminator Loss: -0.46892425417900085 Generator Loss: -0.29354554414749146\nEpoch [84/240] Step [600] Discriminator Loss: -0.6033273935317993 Generator Loss: -0.11472989618778229\nEpoch [84/240] Step [1200] Discriminator Loss: -0.6860358715057373 Generator Loss: -0.08900292962789536\nEpoch [84/240] Step [1800] Discriminator Loss: 0.016102179884910583 Generator Loss: -0.15978579223155975\nEpoch [84/240] Step [2400] Discriminator Loss: -0.5747514963150024 Generator Loss: -0.18989287316799164\nEpoch [84/240] Step [3000] Discriminator Loss: -0.6921356916427612 Generator Loss: -0.10976454615592957\nEpoch [84/240] Step [3600] Discriminator Loss: -0.639576256275177 Generator Loss: -0.2072456330060959\nEpoch [84/240] Step [4200] Discriminator Loss: -0.6247676014900208 Generator Loss: -0.19221310317516327\nEpoch [84/240] Step [4800] Discriminator Loss: -0.7255258560180664 Generator Loss: -0.18632103502750397\nEpoch [84/240] Step [5400] Discriminator Loss: 0.09780150651931763 Generator Loss: -0.657724142074585\nEpoch [84/240] Step [6000] Discriminator Loss: -0.6510494947433472 Generator Loss: -0.10311859101057053\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  35%|███▌      | 85/240 [54:28<1:40:46, 39.01s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [84/240] Avg Discriminator Loss: -0.3797914830374194 Avg Generator Loss: -0.25658521866732903\nEpoch [85/240] Step [0] Discriminator Loss: -0.6075230836868286 Generator Loss: -0.26040118932724\nEpoch [85/240] Step [600] Discriminator Loss: -0.6269546151161194 Generator Loss: -0.24567678570747375\nEpoch [85/240] Step [1200] Discriminator Loss: -0.5424180626869202 Generator Loss: -0.3031712472438812\nEpoch [85/240] Step [1800] Discriminator Loss: -0.6762018799781799 Generator Loss: -0.130563423037529\nEpoch [85/240] Step [2400] Discriminator Loss: -0.3393213450908661 Generator Loss: -0.2826825976371765\nEpoch [85/240] Step [3000] Discriminator Loss: -0.6878167390823364 Generator Loss: -0.14981988072395325\nEpoch [85/240] Step [3600] Discriminator Loss: -0.7372972965240479 Generator Loss: -0.16650673747062683\nEpoch [85/240] Step [4200] Discriminator Loss: -0.6366659998893738 Generator Loss: -0.1925259232521057\nEpoch [85/240] Step [4800] Discriminator Loss: 0.5834237337112427 Generator Loss: -0.6165066957473755\nEpoch [85/240] Step [5400] Discriminator Loss: -0.40129971504211426 Generator Loss: -0.13119828701019287\nEpoch [85/240] Step [6000] Discriminator Loss: -0.7559304237365723 Generator Loss: -0.07394424825906754\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  36%|███▌      | 86/240 [55:06<1:40:02, 38.98s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [85/240] Avg Discriminator Loss: -0.5062787453115205 Avg Generator Loss: -0.22265674978931307\nEpoch [86/240] Step [0] Discriminator Loss: -0.5723307132720947 Generator Loss: -0.1708703339099884\nEpoch [86/240] Step [600] Discriminator Loss: -0.41124576330184937 Generator Loss: -0.3073349595069885\nEpoch [86/240] Step [1200] Discriminator Loss: 0.7751117944717407 Generator Loss: -0.22209621965885162\nEpoch [86/240] Step [1800] Discriminator Loss: -0.6904485821723938 Generator Loss: -0.1712796986103058\nEpoch [86/240] Step [2400] Discriminator Loss: -0.6290385127067566 Generator Loss: -0.17902937531471252\nEpoch [86/240] Step [3000] Discriminator Loss: -0.2992284297943115 Generator Loss: -0.18457956612110138\nEpoch [86/240] Step [3600] Discriminator Loss: -0.4416118264198303 Generator Loss: -0.2696937322616577\nEpoch [86/240] Step [4200] Discriminator Loss: -0.5669699907302856 Generator Loss: -0.23694655299186707\nEpoch [86/240] Step [4800] Discriminator Loss: -0.7322635650634766 Generator Loss: -0.17986293137073517\nEpoch [86/240] Step [5400] Discriminator Loss: -0.4737521708011627 Generator Loss: -0.2371198832988739\nEpoch [86/240] Step [6000] Discriminator Loss: -0.4710068702697754 Generator Loss: -0.29402363300323486\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  36%|███▋      | 87/240 [55:45<1:39:26, 39.00s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [86/240] Avg Discriminator Loss: -0.49743827675288416 Avg Generator Loss: -0.2355430062873896\nEpoch [87/240] Step [0] Discriminator Loss: -0.6545008420944214 Generator Loss: -0.1589099019765854\nEpoch [87/240] Step [600] Discriminator Loss: -0.5883626937866211 Generator Loss: -0.24241769313812256\nEpoch [87/240] Step [1200] Discriminator Loss: -0.5580157041549683 Generator Loss: -0.36383724212646484\nEpoch [87/240] Step [1800] Discriminator Loss: -0.7982349991798401 Generator Loss: -0.07719136029481888\nEpoch [87/240] Step [2400] Discriminator Loss: -0.7750901579856873 Generator Loss: -0.10892977565526962\nEpoch [87/240] Step [3000] Discriminator Loss: -0.5893200635910034 Generator Loss: -0.04405732452869415\nEpoch [87/240] Step [3600] Discriminator Loss: -0.217629075050354 Generator Loss: -0.485152006149292\nEpoch [87/240] Step [4200] Discriminator Loss: -0.2640593647956848 Generator Loss: -0.561785876750946\nEpoch [87/240] Step [4800] Discriminator Loss: 0.2003096342086792 Generator Loss: -0.01625743880867958\nEpoch [87/240] Step [5400] Discriminator Loss: -0.6587910652160645 Generator Loss: -0.0725095123052597\nEpoch [87/240] Step [6000] Discriminator Loss: -0.5272586345672607 Generator Loss: -0.13081517815589905\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  37%|███▋      | 88/240 [56:24<1:38:38, 38.94s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [87/240] Avg Discriminator Loss: -0.4486223198336996 Avg Generator Loss: -0.1996389655635143\nEpoch [88/240] Step [0] Discriminator Loss: -0.6527812480926514 Generator Loss: -0.16742372512817383\nEpoch [88/240] Step [600] Discriminator Loss: -0.11931559443473816 Generator Loss: -0.1455441266298294\nEpoch [88/240] Step [1200] Discriminator Loss: -0.5668663382530212 Generator Loss: -0.2908812463283539\nEpoch [88/240] Step [1800] Discriminator Loss: -0.711464524269104 Generator Loss: -0.10858907550573349\nEpoch [88/240] Step [2400] Discriminator Loss: -0.6745141744613647 Generator Loss: -0.1366885006427765\nEpoch [88/240] Step [3000] Discriminator Loss: -0.5644176602363586 Generator Loss: -0.35387349128723145\nEpoch [88/240] Step [3600] Discriminator Loss: -0.34184589982032776 Generator Loss: -0.3665977418422699\nEpoch [88/240] Step [4200] Discriminator Loss: -0.2965705692768097 Generator Loss: -0.21440577507019043\nEpoch [88/240] Step [4800] Discriminator Loss: -0.37603580951690674 Generator Loss: -0.3417259454727173\nEpoch [88/240] Step [5400] Discriminator Loss: -0.6316143274307251 Generator Loss: -0.15995557606220245\nEpoch [88/240] Step [6000] Discriminator Loss: -0.5225380063056946 Generator Loss: -0.21539202332496643\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  37%|███▋      | 89/240 [57:04<1:38:53, 39.29s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [88/240] Avg Discriminator Loss: -0.4593778249599558 Avg Generator Loss: -0.21970102326746607\nEpoch [89/240] Step [0] Discriminator Loss: -0.6487240791320801 Generator Loss: -0.16820760071277618\nEpoch [89/240] Step [600] Discriminator Loss: 0.20754605531692505 Generator Loss: -0.2707805335521698\nEpoch [89/240] Step [1200] Discriminator Loss: -0.42477184534072876 Generator Loss: -0.3769776225090027\nEpoch [89/240] Step [1800] Discriminator Loss: -0.7026509642601013 Generator Loss: -0.10356265306472778\nEpoch [89/240] Step [2400] Discriminator Loss: -0.3974266052246094 Generator Loss: -0.5168187618255615\nEpoch [89/240] Step [3000] Discriminator Loss: -0.522243082523346 Generator Loss: -0.18240487575531006\nEpoch [89/240] Step [3600] Discriminator Loss: -0.15283840894699097 Generator Loss: -0.407690167427063\nEpoch [89/240] Step [4200] Discriminator Loss: -0.018871769309043884 Generator Loss: -0.7009605169296265\nEpoch [89/240] Step [4800] Discriminator Loss: -0.4967850148677826 Generator Loss: -0.13086320459842682\nEpoch [89/240] Step [5400] Discriminator Loss: -0.5570573806762695 Generator Loss: -0.18030396103858948\nEpoch [89/240] Step [6000] Discriminator Loss: -0.5578179359436035 Generator Loss: -0.22819750010967255\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  38%|███▊      | 90/240 [57:44<1:38:11, 39.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [89/240] Avg Discriminator Loss: -0.44542576721954696 Avg Generator Loss: -0.2471058926111831\nEpoch [90/240] Step [0] Discriminator Loss: -0.6921911835670471 Generator Loss: -0.10622289031744003\nEpoch [90/240] Step [600] Discriminator Loss: 0.6260123252868652 Generator Loss: -0.2550657093524933\nEpoch [90/240] Step [1200] Discriminator Loss: -0.6365979313850403 Generator Loss: -0.2103906273841858\nEpoch [90/240] Step [1800] Discriminator Loss: -0.6188648343086243 Generator Loss: -0.29736387729644775\nEpoch [90/240] Step [2400] Discriminator Loss: -0.34182214736938477 Generator Loss: -0.18717484176158905\nEpoch [90/240] Step [3000] Discriminator Loss: -0.6405203342437744 Generator Loss: -0.17744344472885132\nEpoch [90/240] Step [3600] Discriminator Loss: -0.5090094804763794 Generator Loss: -0.3551819622516632\nEpoch [90/240] Step [4200] Discriminator Loss: -0.5412057638168335 Generator Loss: -0.3055429756641388\nEpoch [90/240] Step [4800] Discriminator Loss: -0.5146296620368958 Generator Loss: -0.1869548261165619\nEpoch [90/240] Step [5400] Discriminator Loss: -0.23562012612819672 Generator Loss: -0.28132951259613037\nEpoch [90/240] Step [6000] Discriminator Loss: -0.5170606970787048 Generator Loss: -0.2475263476371765\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  38%|███▊      | 91/240 [58:23<1:37:19, 39.19s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [90/240] Avg Discriminator Loss: -0.5424951425456739 Avg Generator Loss: -0.2221473579741878\nEpoch [91/240] Step [0] Discriminator Loss: -0.44792449474334717 Generator Loss: -0.3074605464935303\nEpoch [91/240] Step [600] Discriminator Loss: 0.25031718611717224 Generator Loss: -0.48907268047332764\nEpoch [91/240] Step [1200] Discriminator Loss: -0.14083066582679749 Generator Loss: -0.10494248569011688\nEpoch [91/240] Step [1800] Discriminator Loss: -0.5790659189224243 Generator Loss: -0.1725427806377411\nEpoch [91/240] Step [2400] Discriminator Loss: -0.3378208875656128 Generator Loss: -0.547333836555481\nEpoch [91/240] Step [3000] Discriminator Loss: -0.6625544428825378 Generator Loss: -0.15107083320617676\nEpoch [91/240] Step [3600] Discriminator Loss: -0.1742784082889557 Generator Loss: -0.5020007491111755\nEpoch [91/240] Step [4200] Discriminator Loss: 1.3903083801269531 Generator Loss: -0.1275779753923416\nEpoch [91/240] Step [4800] Discriminator Loss: -0.7151311635971069 Generator Loss: -0.06164490804076195\nEpoch [91/240] Step [5400] Discriminator Loss: 0.13358080387115479 Generator Loss: -0.7671436667442322\nEpoch [91/240] Step [6000] Discriminator Loss: -0.506521999835968 Generator Loss: -0.15717996656894684\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  38%|███▊      | 92/240 [59:02<1:36:42, 39.21s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [91/240] Avg Discriminator Loss: -0.36529835965825525 Avg Generator Loss: -0.2409824114736347\nEpoch [92/240] Step [0] Discriminator Loss: -0.5076131820678711 Generator Loss: -0.43760818243026733\nEpoch [92/240] Step [600] Discriminator Loss: -0.20722907781600952 Generator Loss: -0.469273179769516\nEpoch [92/240] Step [1200] Discriminator Loss: -0.6325555443763733 Generator Loss: -0.16253647208213806\nEpoch [92/240] Step [1800] Discriminator Loss: -0.23188643157482147 Generator Loss: -0.5427142977714539\nEpoch [92/240] Step [2400] Discriminator Loss: -0.6429415345191956 Generator Loss: -0.13807979226112366\nEpoch [92/240] Step [3000] Discriminator Loss: -0.7513372302055359 Generator Loss: -0.1370018571615219\nEpoch [92/240] Step [3600] Discriminator Loss: -0.37543410062789917 Generator Loss: -0.3877946138381958\nEpoch [92/240] Step [4200] Discriminator Loss: -0.7270709872245789 Generator Loss: -0.11712539196014404\nEpoch [92/240] Step [4800] Discriminator Loss: -0.4856584072113037 Generator Loss: -0.36156728863716125\nEpoch [92/240] Step [5400] Discriminator Loss: -0.7307350039482117 Generator Loss: -0.22063761949539185\nEpoch [92/240] Step [6000] Discriminator Loss: -0.7827889323234558 Generator Loss: -0.09362571686506271\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  39%|███▉      | 93/240 [59:41<1:35:53, 39.14s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [92/240] Avg Discriminator Loss: -0.5080792603420687 Avg Generator Loss: -0.2215613753094778\nEpoch [93/240] Step [0] Discriminator Loss: -0.6234282851219177 Generator Loss: -0.18804681301116943\nEpoch [93/240] Step [600] Discriminator Loss: -0.7157652378082275 Generator Loss: -0.28547751903533936\nEpoch [93/240] Step [1200] Discriminator Loss: -0.31780382990837097 Generator Loss: -0.43948525190353394\nEpoch [93/240] Step [1800] Discriminator Loss: -0.7576909065246582 Generator Loss: -0.13667453825473785\nEpoch [93/240] Step [2400] Discriminator Loss: -0.40140438079833984 Generator Loss: -0.33879342675209045\nEpoch [93/240] Step [3000] Discriminator Loss: -0.6986668705940247 Generator Loss: -0.1574682742357254\nEpoch [93/240] Step [3600] Discriminator Loss: -0.4554339647293091 Generator Loss: -0.33642813563346863\nEpoch [93/240] Step [4200] Discriminator Loss: -0.6967417597770691 Generator Loss: -0.2055954784154892\nEpoch [93/240] Step [4800] Discriminator Loss: -0.6898624897003174 Generator Loss: -0.22760145366191864\nEpoch [93/240] Step [5400] Discriminator Loss: -0.6104075908660889 Generator Loss: -0.2355554699897766\nEpoch [93/240] Step [6000] Discriminator Loss: -0.4634820222854614 Generator Loss: -0.21025249361991882\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  39%|███▉      | 94/240 [1:00:20<1:35:09, 39.10s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [93/240] Avg Discriminator Loss: -0.5235124486379135 Avg Generator Loss: -0.21794678771615902\nEpoch [94/240] Step [0] Discriminator Loss: -0.5732110142707825 Generator Loss: -0.43341490626335144\nEpoch [94/240] Step [600] Discriminator Loss: -0.5259189605712891 Generator Loss: -0.3256712555885315\nEpoch [94/240] Step [1200] Discriminator Loss: -0.6119962930679321 Generator Loss: -0.2212287038564682\nEpoch [94/240] Step [1800] Discriminator Loss: -0.09112326800823212 Generator Loss: -0.3582511246204376\nEpoch [94/240] Step [2400] Discriminator Loss: -0.6950554847717285 Generator Loss: -0.18445567786693573\nEpoch [94/240] Step [3000] Discriminator Loss: 0.004916727542877197 Generator Loss: -0.3797377943992615\nEpoch [94/240] Step [3600] Discriminator Loss: 0.33454349637031555 Generator Loss: -0.6062992215156555\nEpoch [94/240] Step [4200] Discriminator Loss: -0.4460674226284027 Generator Loss: -0.28338927030563354\nEpoch [94/240] Step [4800] Discriminator Loss: 0.8196050524711609 Generator Loss: -0.35400140285491943\nEpoch [94/240] Step [5400] Discriminator Loss: -0.5540298819541931 Generator Loss: -0.20878872275352478\nEpoch [94/240] Step [6000] Discriminator Loss: -0.19590365886688232 Generator Loss: -0.26810237765312195\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  40%|███▉      | 95/240 [1:00:59<1:34:24, 39.07s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [94/240] Avg Discriminator Loss: -0.0949341984322438 Avg Generator Loss: -0.27966950828339154\nEpoch [95/240] Step [0] Discriminator Loss: -0.6321904063224792 Generator Loss: -0.18085388839244843\nEpoch [95/240] Step [600] Discriminator Loss: -0.7230519652366638 Generator Loss: -0.2750330865383148\nEpoch [95/240] Step [1200] Discriminator Loss: -0.15675543248653412 Generator Loss: -0.2634812295436859\nEpoch [95/240] Step [1800] Discriminator Loss: -0.11450797319412231 Generator Loss: -0.47042912244796753\nEpoch [95/240] Step [2400] Discriminator Loss: -0.006606876850128174 Generator Loss: -0.06745927780866623\nEpoch [95/240] Step [3000] Discriminator Loss: -0.7395941615104675 Generator Loss: -0.18238253891468048\nEpoch [95/240] Step [3600] Discriminator Loss: -0.3892149329185486 Generator Loss: -0.249711275100708\nEpoch [95/240] Step [4200] Discriminator Loss: -0.6889076828956604 Generator Loss: -0.15257593989372253\nEpoch [95/240] Step [4800] Discriminator Loss: -0.16705447435379028 Generator Loss: -0.22456787526607513\nEpoch [95/240] Step [5400] Discriminator Loss: -0.5266501307487488 Generator Loss: -0.2576918601989746\nEpoch [95/240] Step [6000] Discriminator Loss: -0.1389000117778778 Generator Loss: -0.5875550508499146\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  40%|████      | 96/240 [1:01:38<1:33:34, 38.99s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [95/240] Avg Discriminator Loss: -0.3915276748738883 Avg Generator Loss: -0.23652638241839716\nEpoch [96/240] Step [0] Discriminator Loss: -0.6658291816711426 Generator Loss: -0.23202136158943176\nEpoch [96/240] Step [600] Discriminator Loss: -0.5792953968048096 Generator Loss: -0.04888056591153145\nEpoch [96/240] Step [1200] Discriminator Loss: 0.18924912810325623 Generator Loss: -0.5210150480270386\nEpoch [96/240] Step [1800] Discriminator Loss: -0.6874812841415405 Generator Loss: -0.21115443110466003\nEpoch [96/240] Step [2400] Discriminator Loss: -0.7135374546051025 Generator Loss: -0.13660110533237457\nEpoch [96/240] Step [3000] Discriminator Loss: -0.6355952024459839 Generator Loss: -0.1984739452600479\nEpoch [96/240] Step [3600] Discriminator Loss: -0.31566938757896423 Generator Loss: -0.22414933145046234\nEpoch [96/240] Step [4200] Discriminator Loss: -0.05916905403137207 Generator Loss: -0.4776594936847687\nEpoch [96/240] Step [4800] Discriminator Loss: 0.1863216757774353 Generator Loss: -0.23319964110851288\nEpoch [96/240] Step [5400] Discriminator Loss: -0.43163782358169556 Generator Loss: -0.26922163367271423\nEpoch [96/240] Step [6000] Discriminator Loss: -0.6098840236663818 Generator Loss: -0.13422997295856476\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  40%|████      | 97/240 [1:02:17<1:32:57, 39.00s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [96/240] Avg Discriminator Loss: -0.40095222836885697 Avg Generator Loss: -0.2501580690412403\nEpoch [97/240] Step [0] Discriminator Loss: -0.2716972827911377 Generator Loss: -0.06742233037948608\nEpoch [97/240] Step [600] Discriminator Loss: -0.6412753462791443 Generator Loss: -0.11869721114635468\nEpoch [97/240] Step [1200] Discriminator Loss: -0.431633859872818 Generator Loss: -0.24003401398658752\nEpoch [97/240] Step [1800] Discriminator Loss: -0.6404299139976501 Generator Loss: -0.3067421019077301\nEpoch [97/240] Step [2400] Discriminator Loss: -0.655953049659729 Generator Loss: -0.3005481958389282\nEpoch [97/240] Step [3000] Discriminator Loss: 0.20294088125228882 Generator Loss: -0.2874450087547302\nEpoch [97/240] Step [3600] Discriminator Loss: 0.3221815824508667 Generator Loss: -0.3482629954814911\nEpoch [97/240] Step [4200] Discriminator Loss: -0.61262047290802 Generator Loss: -0.0586380735039711\nEpoch [97/240] Step [4800] Discriminator Loss: -0.07374277710914612 Generator Loss: -0.26791200041770935\nEpoch [97/240] Step [5400] Discriminator Loss: -0.577216625213623 Generator Loss: -0.14960545301437378\nEpoch [97/240] Step [6000] Discriminator Loss: -0.35254988074302673 Generator Loss: -0.1308307945728302\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  41%|████      | 98/240 [1:02:56<1:32:15, 38.98s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [97/240] Avg Discriminator Loss: -0.48738447055493517 Avg Generator Loss: -0.22401915629131672\nEpoch [98/240] Step [0] Discriminator Loss: -0.7211695909500122 Generator Loss: -0.18285369873046875\nEpoch [98/240] Step [600] Discriminator Loss: -0.5742161273956299 Generator Loss: -0.17286472022533417\nEpoch [98/240] Step [1200] Discriminator Loss: -0.4795864224433899 Generator Loss: -0.14753568172454834\nEpoch [98/240] Step [1800] Discriminator Loss: -0.7584801316261292 Generator Loss: -0.13976328074932098\nEpoch [98/240] Step [2400] Discriminator Loss: -0.6580994129180908 Generator Loss: -0.18947842717170715\nEpoch [98/240] Step [3000] Discriminator Loss: 0.513636589050293 Generator Loss: -0.18834292888641357\nEpoch [98/240] Step [3600] Discriminator Loss: -0.3245384991168976 Generator Loss: -0.26027417182922363\nEpoch [98/240] Step [4200] Discriminator Loss: -0.3129231929779053 Generator Loss: -0.17162638902664185\nEpoch [98/240] Step [4800] Discriminator Loss: -0.6391998529434204 Generator Loss: -0.11306976526975632\nEpoch [98/240] Step [5400] Discriminator Loss: -0.5654963254928589 Generator Loss: -0.17162629961967468\nEpoch [98/240] Step [6000] Discriminator Loss: -0.4936659634113312 Generator Loss: -0.14006607234477997\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  41%|████▏     | 99/240 [1:03:35<1:31:34, 38.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [98/240] Avg Discriminator Loss: -0.4293576054848157 Avg Generator Loss: -0.230370206478642\nEpoch [99/240] Step [0] Discriminator Loss: -0.7834140062332153 Generator Loss: -0.08088567852973938\nEpoch [99/240] Step [600] Discriminator Loss: -0.6765406727790833 Generator Loss: -0.14617274701595306\nEpoch [99/240] Step [1200] Discriminator Loss: -0.47945815324783325 Generator Loss: -0.2666567862033844\nEpoch [99/240] Step [1800] Discriminator Loss: -0.7050361633300781 Generator Loss: -0.19412820041179657\nEpoch [99/240] Step [2400] Discriminator Loss: -0.6774484515190125 Generator Loss: -0.20552101731300354\nEpoch [99/240] Step [3000] Discriminator Loss: -0.5855293273925781 Generator Loss: -0.16435666382312775\nEpoch [99/240] Step [3600] Discriminator Loss: -0.7486216425895691 Generator Loss: -0.09630365669727325\nEpoch [99/240] Step [4200] Discriminator Loss: -0.37179604172706604 Generator Loss: -0.1357739269733429\nEpoch [99/240] Step [4800] Discriminator Loss: -0.07335913181304932 Generator Loss: -0.22271186113357544\nEpoch [99/240] Step [5400] Discriminator Loss: -0.5877931714057922 Generator Loss: -0.2778782248497009\nEpoch [99/240] Step [6000] Discriminator Loss: -0.5090417861938477 Generator Loss: -0.10990537703037262\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  42%|████▏     | 100/240 [1:04:13<1:30:45, 38.90s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [99/240] Avg Discriminator Loss: -0.5054103017617495 Avg Generator Loss: -0.20943926859838077\nEpoch [100/240] Step [0] Discriminator Loss: -0.6517587900161743 Generator Loss: -0.28049954771995544\nEpoch [100/240] Step [600] Discriminator Loss: -0.6712318062782288 Generator Loss: -0.11706039309501648\nEpoch [100/240] Step [1200] Discriminator Loss: -0.2755490243434906 Generator Loss: -0.43519583344459534\nEpoch [100/240] Step [1800] Discriminator Loss: -0.35710057616233826 Generator Loss: -0.07483454048633575\nEpoch [100/240] Step [2400] Discriminator Loss: -0.5429409742355347 Generator Loss: -0.30269142985343933\nEpoch [100/240] Step [3000] Discriminator Loss: -0.53888338804245 Generator Loss: -0.2093777358531952\nEpoch [100/240] Step [3600] Discriminator Loss: 0.13604013621807098 Generator Loss: -0.34942230582237244\nEpoch [100/240] Step [4200] Discriminator Loss: 0.3699638247489929 Generator Loss: -0.624168336391449\nEpoch [100/240] Step [4800] Discriminator Loss: -0.7534846663475037 Generator Loss: -0.16159558296203613\nEpoch [100/240] Step [5400] Discriminator Loss: -0.44555768370628357 Generator Loss: -0.453138530254364\nEpoch [100/240] Step [6000] Discriminator Loss: -0.35291779041290283 Generator Loss: -0.1513330489397049\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  42%|████▏     | 101/240 [1:04:52<1:30:08, 38.91s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [100/240] Avg Discriminator Loss: -0.3395786729706076 Avg Generator Loss: -0.2877458976956951\nEpoch [101/240] Step [0] Discriminator Loss: -0.5773378014564514 Generator Loss: -0.2232978343963623\nEpoch [101/240] Step [600] Discriminator Loss: -0.4144035577774048 Generator Loss: -0.3433895409107208\nEpoch [101/240] Step [1200] Discriminator Loss: -0.4733438491821289 Generator Loss: -0.2854762077331543\nEpoch [101/240] Step [1800] Discriminator Loss: -0.7231106162071228 Generator Loss: -0.0699579268693924\nEpoch [101/240] Step [2400] Discriminator Loss: 0.20570111274719238 Generator Loss: -0.3803403377532959\nEpoch [101/240] Step [3000] Discriminator Loss: -0.1890537440776825 Generator Loss: -0.43443793058395386\nEpoch [101/240] Step [3600] Discriminator Loss: -0.412455677986145 Generator Loss: -0.19083639979362488\nEpoch [101/240] Step [4200] Discriminator Loss: -0.6021803617477417 Generator Loss: -0.27258190512657166\nEpoch [101/240] Step [4800] Discriminator Loss: -0.28295251727104187 Generator Loss: -0.27474990487098694\nEpoch [101/240] Step [5400] Discriminator Loss: -0.3797261714935303 Generator Loss: -0.36652639508247375\nEpoch [101/240] Step [6000] Discriminator Loss: -0.6898050308227539 Generator Loss: -0.19317305088043213\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  42%|████▎     | 102/240 [1:05:31<1:29:14, 38.80s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [101/240] Avg Discriminator Loss: -0.3406262437884624 Avg Generator Loss: -0.2680780673774826\nEpoch [102/240] Step [0] Discriminator Loss: -0.5925331711769104 Generator Loss: -0.20840638875961304\nEpoch [102/240] Step [600] Discriminator Loss: -0.62010657787323 Generator Loss: -0.07180314511060715\nEpoch [102/240] Step [1200] Discriminator Loss: -0.0009329468011856079 Generator Loss: -0.26901882886886597\nEpoch [102/240] Step [1800] Discriminator Loss: -0.5635516047477722 Generator Loss: -0.18252919614315033\nEpoch [102/240] Step [2400] Discriminator Loss: -0.4979791045188904 Generator Loss: -0.07905422151088715\nEpoch [102/240] Step [3000] Discriminator Loss: -0.7481755018234253 Generator Loss: -0.14600959420204163\nEpoch [102/240] Step [3600] Discriminator Loss: -0.7198569774627686 Generator Loss: -0.17889834940433502\nEpoch [102/240] Step [4200] Discriminator Loss: -0.687895655632019 Generator Loss: -0.15466372668743134\nEpoch [102/240] Step [4800] Discriminator Loss: -0.6324841380119324 Generator Loss: -0.18877169489860535\nEpoch [102/240] Step [5400] Discriminator Loss: -0.6286793947219849 Generator Loss: -0.19647595286369324\nEpoch [102/240] Step [6000] Discriminator Loss: -0.6408979296684265 Generator Loss: -0.21281437575817108\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  43%|████▎     | 103/240 [1:06:09<1:28:25, 38.73s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [102/240] Avg Discriminator Loss: -0.4519946049257513 Avg Generator Loss: -0.24726346727365103\nEpoch [103/240] Step [0] Discriminator Loss: -0.5622822046279907 Generator Loss: -0.22371608018875122\nEpoch [103/240] Step [600] Discriminator Loss: -0.6956084370613098 Generator Loss: -0.15154853463172913\nEpoch [103/240] Step [1200] Discriminator Loss: -0.44254398345947266 Generator Loss: -0.39500099420547485\nEpoch [103/240] Step [1800] Discriminator Loss: -0.5836687088012695 Generator Loss: -0.3207888901233673\nEpoch [103/240] Step [2400] Discriminator Loss: -0.653734028339386 Generator Loss: -0.16785967350006104\nEpoch [103/240] Step [3000] Discriminator Loss: -0.6457258462905884 Generator Loss: -0.14914898574352264\nEpoch [103/240] Step [3600] Discriminator Loss: -0.7606959342956543 Generator Loss: -0.12582002580165863\nEpoch [103/240] Step [4200] Discriminator Loss: -0.558355450630188 Generator Loss: -0.1577652543783188\nEpoch [103/240] Step [4800] Discriminator Loss: -0.023250937461853027 Generator Loss: -0.2967415750026703\nEpoch [103/240] Step [5400] Discriminator Loss: -0.6036913990974426 Generator Loss: -0.2569463849067688\nEpoch [103/240] Step [6000] Discriminator Loss: -0.5416565537452698 Generator Loss: -0.0856132060289383\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  43%|████▎     | 104/240 [1:06:48<1:27:30, 38.61s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [103/240] Avg Discriminator Loss: -0.48469361324450033 Avg Generator Loss: -0.23876184529382669\nEpoch [104/240] Step [0] Discriminator Loss: 0.5218662619590759 Generator Loss: -0.5185661315917969\nEpoch [104/240] Step [600] Discriminator Loss: -0.21093976497650146 Generator Loss: -0.24681730568408966\nEpoch [104/240] Step [1200] Discriminator Loss: -0.11876623332500458 Generator Loss: -0.34088125824928284\nEpoch [104/240] Step [1800] Discriminator Loss: -0.6338974237442017 Generator Loss: -0.03207597881555557\nEpoch [104/240] Step [2400] Discriminator Loss: -0.02545166015625 Generator Loss: -0.5899571180343628\nEpoch [104/240] Step [3000] Discriminator Loss: -0.41254574060440063 Generator Loss: -0.21116183698177338\nEpoch [104/240] Step [3600] Discriminator Loss: -0.5625436305999756 Generator Loss: -0.24603065848350525\nEpoch [104/240] Step [4200] Discriminator Loss: -0.45338553190231323 Generator Loss: -0.12218533456325531\nEpoch [104/240] Step [4800] Discriminator Loss: 0.33185267448425293 Generator Loss: -0.48458966612815857\nEpoch [104/240] Step [5400] Discriminator Loss: -0.23987692594528198 Generator Loss: -0.2699764370918274\nEpoch [104/240] Step [6000] Discriminator Loss: -0.6773760914802551 Generator Loss: -0.12755146622657776\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  44%|████▍     | 105/240 [1:07:26<1:26:54, 38.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [104/240] Avg Discriminator Loss: -0.3055507441361745 Avg Generator Loss: -0.2352359948386421\nEpoch [105/240] Step [0] Discriminator Loss: -0.6551774740219116 Generator Loss: -0.1797095537185669\nEpoch [105/240] Step [600] Discriminator Loss: -0.5882366299629211 Generator Loss: -0.12262933701276779\nEpoch [105/240] Step [1200] Discriminator Loss: -0.5643486976623535 Generator Loss: -0.13389864563941956\nEpoch [105/240] Step [1800] Discriminator Loss: -0.7874211072921753 Generator Loss: -0.1167818158864975\nEpoch [105/240] Step [2400] Discriminator Loss: -0.7985248565673828 Generator Loss: -0.12626846134662628\nEpoch [105/240] Step [3000] Discriminator Loss: -0.616245687007904 Generator Loss: -0.28114330768585205\nEpoch [105/240] Step [3600] Discriminator Loss: -0.7612542510032654 Generator Loss: -0.14144399762153625\nEpoch [105/240] Step [4200] Discriminator Loss: -0.38351064920425415 Generator Loss: -0.4037321209907532\nEpoch [105/240] Step [4800] Discriminator Loss: -0.5184967517852783 Generator Loss: -0.24191321432590485\nEpoch [105/240] Step [5400] Discriminator Loss: -0.6991724371910095 Generator Loss: -0.20637711882591248\nEpoch [105/240] Step [6000] Discriminator Loss: -0.5040026903152466 Generator Loss: -0.38700786232948303\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  44%|████▍     | 106/240 [1:08:05<1:26:17, 38.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [105/240] Avg Discriminator Loss: -0.5586641073881925 Avg Generator Loss: -0.21719660993065043\nEpoch [106/240] Step [0] Discriminator Loss: -0.7076727151870728 Generator Loss: -0.1153467521071434\nEpoch [106/240] Step [600] Discriminator Loss: -0.5607689023017883 Generator Loss: -0.18705719709396362\nEpoch [106/240] Step [1200] Discriminator Loss: -0.5984783172607422 Generator Loss: -0.30306094884872437\nEpoch [106/240] Step [1800] Discriminator Loss: -0.7287566661834717 Generator Loss: -0.15757666528224945\nEpoch [106/240] Step [2400] Discriminator Loss: -0.6693729162216187 Generator Loss: -0.238716721534729\nEpoch [106/240] Step [3000] Discriminator Loss: -0.6199924945831299 Generator Loss: -0.20242345333099365\nEpoch [106/240] Step [3600] Discriminator Loss: -0.7150171399116516 Generator Loss: -0.1864546537399292\nEpoch [106/240] Step [4200] Discriminator Loss: -0.14308619499206543 Generator Loss: -0.433942049741745\nEpoch [106/240] Step [4800] Discriminator Loss: -0.6315685510635376 Generator Loss: -0.25677090883255005\nEpoch [106/240] Step [5400] Discriminator Loss: 0.13509473204612732 Generator Loss: -0.5142463445663452\nEpoch [106/240] Step [6000] Discriminator Loss: -0.07536529004573822 Generator Loss: -0.2258097529411316\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  45%|████▍     | 107/240 [1:08:44<1:25:42, 38.67s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [106/240] Avg Discriminator Loss: -0.43613975698421725 Avg Generator Loss: -0.2565206838805815\nEpoch [107/240] Step [0] Discriminator Loss: -0.761116087436676 Generator Loss: -0.0781741663813591\nEpoch [107/240] Step [600] Discriminator Loss: -0.5548155903816223 Generator Loss: -0.22074952721595764\nEpoch [107/240] Step [1200] Discriminator Loss: -0.4299055337905884 Generator Loss: -0.07582832872867584\nEpoch [107/240] Step [1800] Discriminator Loss: -0.7101955413818359 Generator Loss: -0.10703778266906738\nEpoch [107/240] Step [2400] Discriminator Loss: -0.1758306622505188 Generator Loss: -0.20258226990699768\nEpoch [107/240] Step [3000] Discriminator Loss: -0.48399657011032104 Generator Loss: -0.48738977313041687\nEpoch [107/240] Step [3600] Discriminator Loss: -0.7492931485176086 Generator Loss: -0.17422959208488464\nEpoch [107/240] Step [4200] Discriminator Loss: -0.6595388054847717 Generator Loss: -0.1905718296766281\nEpoch [107/240] Step [4800] Discriminator Loss: -0.45436951518058777 Generator Loss: -0.20930416882038116\nEpoch [107/240] Step [5400] Discriminator Loss: -0.16983267664909363 Generator Loss: -0.2754662334918976\nEpoch [107/240] Step [6000] Discriminator Loss: -0.32828184962272644 Generator Loss: -0.2799113094806671\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  45%|████▌     | 108/240 [1:09:22<1:24:55, 38.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [107/240] Avg Discriminator Loss: -0.5135389498192748 Avg Generator Loss: -0.2057535145807015\nEpoch [108/240] Step [0] Discriminator Loss: -0.6417934894561768 Generator Loss: -0.2186071127653122\nEpoch [108/240] Step [600] Discriminator Loss: -0.6618857383728027 Generator Loss: -0.11082641035318375\nEpoch [108/240] Step [1200] Discriminator Loss: -0.7077671885490417 Generator Loss: -0.1855235993862152\nEpoch [108/240] Step [1800] Discriminator Loss: -0.787933886051178 Generator Loss: -0.10672655701637268\nEpoch [108/240] Step [2400] Discriminator Loss: -0.7148813009262085 Generator Loss: -0.15037302672863007\nEpoch [108/240] Step [3000] Discriminator Loss: -0.7182955741882324 Generator Loss: -0.20704928040504456\nEpoch [108/240] Step [3600] Discriminator Loss: -0.6591565012931824 Generator Loss: -0.21003445982933044\nEpoch [108/240] Step [4200] Discriminator Loss: -0.3994022309780121 Generator Loss: -0.28339990973472595\nEpoch [108/240] Step [4800] Discriminator Loss: -0.7635204792022705 Generator Loss: -0.09351151436567307\nEpoch [108/240] Step [5400] Discriminator Loss: -0.6357569694519043 Generator Loss: -0.05879776552319527\nEpoch [108/240] Step [6000] Discriminator Loss: -0.704073429107666 Generator Loss: -0.13561512529850006\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  45%|████▌     | 109/240 [1:10:01<1:24:16, 38.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [108/240] Avg Discriminator Loss: -0.5550267388532449 Avg Generator Loss: -0.22411841485690284\nEpoch [109/240] Step [0] Discriminator Loss: -0.6317746639251709 Generator Loss: -0.25522539019584656\nEpoch [109/240] Step [600] Discriminator Loss: -0.6960323452949524 Generator Loss: -0.08557261526584625\nEpoch [109/240] Step [1200] Discriminator Loss: -0.6091824173927307 Generator Loss: -0.24569305777549744\nEpoch [109/240] Step [1800] Discriminator Loss: -0.7321997880935669 Generator Loss: -0.056952204555273056\nEpoch [109/240] Step [2400] Discriminator Loss: -0.35160398483276367 Generator Loss: -0.15278658270835876\nEpoch [109/240] Step [3000] Discriminator Loss: -0.7088918685913086 Generator Loss: -0.1429813653230667\nEpoch [109/240] Step [3600] Discriminator Loss: -0.18863415718078613 Generator Loss: -0.2722437381744385\nEpoch [109/240] Step [4200] Discriminator Loss: -0.6780154705047607 Generator Loss: -0.1615346521139145\nEpoch [109/240] Step [4800] Discriminator Loss: -0.7542529106140137 Generator Loss: -0.035911280661821365\nEpoch [109/240] Step [5400] Discriminator Loss: -0.6678889989852905 Generator Loss: -0.19613417983055115\nEpoch [109/240] Step [6000] Discriminator Loss: -0.6676976680755615 Generator Loss: -0.17261762917041779\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  46%|████▌     | 110/240 [1:10:39<1:23:31, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [109/240] Avg Discriminator Loss: -0.5367077823196139 Avg Generator Loss: -0.20172103905142882\nEpoch [110/240] Step [0] Discriminator Loss: -0.782994270324707 Generator Loss: -0.058057382702827454\nEpoch [110/240] Step [600] Discriminator Loss: -0.5981841683387756 Generator Loss: -0.1784643977880478\nEpoch [110/240] Step [1200] Discriminator Loss: -0.6212079524993896 Generator Loss: -0.08919515460729599\nEpoch [110/240] Step [1800] Discriminator Loss: -0.587702214717865 Generator Loss: -0.1408304125070572\nEpoch [110/240] Step [2400] Discriminator Loss: -0.26683998107910156 Generator Loss: -0.4526205062866211\nEpoch [110/240] Step [3000] Discriminator Loss: -0.5291210412979126 Generator Loss: -0.2699817419052124\nEpoch [110/240] Step [3600] Discriminator Loss: -0.5538303852081299 Generator Loss: -0.1418895721435547\nEpoch [110/240] Step [4200] Discriminator Loss: -0.5034555196762085 Generator Loss: -0.1281513273715973\nEpoch [110/240] Step [4800] Discriminator Loss: -0.5748389959335327 Generator Loss: -0.05440455302596092\nEpoch [110/240] Step [5400] Discriminator Loss: -0.43685683608055115 Generator Loss: -0.2398628294467926\nEpoch [110/240] Step [6000] Discriminator Loss: -0.751934289932251 Generator Loss: -0.11865881085395813\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  46%|████▋     | 111/240 [1:11:18<1:22:51, 38.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [110/240] Avg Discriminator Loss: -0.5070989962680873 Avg Generator Loss: -0.20755691729117554\nEpoch [111/240] Step [0] Discriminator Loss: -0.5325384736061096 Generator Loss: -0.23308569192886353\nEpoch [111/240] Step [600] Discriminator Loss: -0.6431088447570801 Generator Loss: -0.14705319702625275\nEpoch [111/240] Step [1200] Discriminator Loss: -0.4610942304134369 Generator Loss: -0.38103440403938293\nEpoch [111/240] Step [1800] Discriminator Loss: 0.235351100564003 Generator Loss: -0.45155927538871765\nEpoch [111/240] Step [2400] Discriminator Loss: 0.14713306725025177 Generator Loss: -0.1405825912952423\nEpoch [111/240] Step [3000] Discriminator Loss: -0.3206688165664673 Generator Loss: -0.33503615856170654\nEpoch [111/240] Step [3600] Discriminator Loss: -0.3781622648239136 Generator Loss: -0.36970847845077515\nEpoch [111/240] Step [4200] Discriminator Loss: -0.37084102630615234 Generator Loss: -0.24397319555282593\nEpoch [111/240] Step [4800] Discriminator Loss: -0.5882314443588257 Generator Loss: -0.2350064069032669\nEpoch [111/240] Step [5400] Discriminator Loss: -0.3314765691757202 Generator Loss: -0.3937963545322418\nEpoch [111/240] Step [6000] Discriminator Loss: -0.4529060125350952 Generator Loss: -0.08943212777376175\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  47%|████▋     | 112/240 [1:11:56<1:22:11, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [111/240] Avg Discriminator Loss: -0.29143057272329437 Avg Generator Loss: -0.26904977412532755\nEpoch [112/240] Step [0] Discriminator Loss: -0.6463799476623535 Generator Loss: -0.07172538340091705\nEpoch [112/240] Step [600] Discriminator Loss: 0.09620624780654907 Generator Loss: -0.3528033494949341\nEpoch [112/240] Step [1200] Discriminator Loss: -0.49283066391944885 Generator Loss: -0.08488591760396957\nEpoch [112/240] Step [1800] Discriminator Loss: -0.4029918313026428 Generator Loss: -0.34862974286079407\nEpoch [112/240] Step [2400] Discriminator Loss: -0.693249523639679 Generator Loss: -0.18078920245170593\nEpoch [112/240] Step [3000] Discriminator Loss: -0.7049363255500793 Generator Loss: -0.2484438568353653\nEpoch [112/240] Step [3600] Discriminator Loss: -0.5020209550857544 Generator Loss: -0.3003652095794678\nEpoch [112/240] Step [4200] Discriminator Loss: -0.4382392466068268 Generator Loss: -0.1731935739517212\nEpoch [112/240] Step [4800] Discriminator Loss: -0.6973737478256226 Generator Loss: -0.16729606688022614\nEpoch [112/240] Step [5400] Discriminator Loss: -0.708564043045044 Generator Loss: -0.15871597826480865\nEpoch [112/240] Step [6000] Discriminator Loss: -0.37878021597862244 Generator Loss: -0.12393999099731445\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  47%|████▋     | 113/240 [1:12:35<1:21:33, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [112/240] Avg Discriminator Loss: -0.5012997671579703 Avg Generator Loss: -0.2379990042197508\nEpoch [113/240] Step [0] Discriminator Loss: -0.5141558647155762 Generator Loss: -0.3291168510913849\nEpoch [113/240] Step [600] Discriminator Loss: -0.712468147277832 Generator Loss: -0.17226165533065796\nEpoch [113/240] Step [1200] Discriminator Loss: -0.5988409519195557 Generator Loss: -0.30775508284568787\nEpoch [113/240] Step [1800] Discriminator Loss: -0.7175416946411133 Generator Loss: -0.12702390551567078\nEpoch [113/240] Step [2400] Discriminator Loss: -0.6428203582763672 Generator Loss: -0.1935264617204666\nEpoch [113/240] Step [3000] Discriminator Loss: -0.1403294801712036 Generator Loss: -0.21678340435028076\nEpoch [113/240] Step [3600] Discriminator Loss: -0.4502100348472595 Generator Loss: -0.42747005820274353\nEpoch [113/240] Step [4200] Discriminator Loss: -0.365281879901886 Generator Loss: -0.37650778889656067\nEpoch [113/240] Step [4800] Discriminator Loss: -0.741412341594696 Generator Loss: -0.062261708080768585\nEpoch [113/240] Step [5400] Discriminator Loss: -0.559594988822937 Generator Loss: -0.2154267579317093\nEpoch [113/240] Step [6000] Discriminator Loss: -0.5787158608436584 Generator Loss: -0.13685649633407593\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  48%|████▊     | 114/240 [1:13:13<1:20:43, 38.44s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [113/240] Avg Discriminator Loss: -0.5363111888150592 Avg Generator Loss: -0.2223291924707728\nEpoch [114/240] Step [0] Discriminator Loss: -0.5961642265319824 Generator Loss: -0.14079312980175018\nEpoch [114/240] Step [600] Discriminator Loss: -0.7166436910629272 Generator Loss: -0.1428365707397461\nEpoch [114/240] Step [1200] Discriminator Loss: -0.5607917308807373 Generator Loss: -0.18250489234924316\nEpoch [114/240] Step [1800] Discriminator Loss: -0.6697914600372314 Generator Loss: -0.1906995177268982\nEpoch [114/240] Step [2400] Discriminator Loss: -0.7250180840492249 Generator Loss: -0.06965874880552292\nEpoch [114/240] Step [3000] Discriminator Loss: -0.4774428606033325 Generator Loss: -0.1813509464263916\nEpoch [114/240] Step [3600] Discriminator Loss: 1.1281251907348633 Generator Loss: -0.6425330638885498\nEpoch [114/240] Step [4200] Discriminator Loss: -0.6722603440284729 Generator Loss: -0.19840377569198608\nEpoch [114/240] Step [4800] Discriminator Loss: -0.7464484572410583 Generator Loss: -0.09633602946996689\nEpoch [114/240] Step [5400] Discriminator Loss: -0.6057993173599243 Generator Loss: -0.21892058849334717\nEpoch [114/240] Step [6000] Discriminator Loss: -0.318172812461853 Generator Loss: -0.30600303411483765\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  48%|████▊     | 115/240 [1:13:51<1:20:00, 38.40s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [114/240] Avg Discriminator Loss: -0.5419405705326206 Avg Generator Loss: -0.21496557221225984\nEpoch [115/240] Step [0] Discriminator Loss: -0.6322349905967712 Generator Loss: -0.1267329305410385\nEpoch [115/240] Step [600] Discriminator Loss: -0.6863663792610168 Generator Loss: -0.1357676088809967\nEpoch [115/240] Step [1200] Discriminator Loss: -0.07802644371986389 Generator Loss: -0.46884146332740784\nEpoch [115/240] Step [1800] Discriminator Loss: -0.5319544672966003 Generator Loss: -0.19195948541164398\nEpoch [115/240] Step [2400] Discriminator Loss: -0.3363170623779297 Generator Loss: -0.24209874868392944\nEpoch [115/240] Step [3000] Discriminator Loss: -0.6470814943313599 Generator Loss: -0.060153305530548096\nEpoch [115/240] Step [3600] Discriminator Loss: -0.7577985525131226 Generator Loss: -0.07958343625068665\nEpoch [115/240] Step [4200] Discriminator Loss: -0.47302335500717163 Generator Loss: -0.12268448621034622\nEpoch [115/240] Step [4800] Discriminator Loss: -0.6407018303871155 Generator Loss: -0.24292506277561188\nEpoch [115/240] Step [5400] Discriminator Loss: -0.12660828232765198 Generator Loss: -0.45373299717903137\nEpoch [115/240] Step [6000] Discriminator Loss: -0.12582552433013916 Generator Loss: -0.3047325909137726\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  48%|████▊     | 116/240 [1:14:31<1:20:17, 38.85s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [115/240] Avg Discriminator Loss: -0.41601654494201745 Avg Generator Loss: -0.21403590038473352\nEpoch [116/240] Step [0] Discriminator Loss: -0.4186573326587677 Generator Loss: -0.23074334859848022\nEpoch [116/240] Step [600] Discriminator Loss: -0.5992393493652344 Generator Loss: -0.21937429904937744\nEpoch [116/240] Step [1200] Discriminator Loss: -0.445930540561676 Generator Loss: -0.2762513756752014\nEpoch [116/240] Step [1800] Discriminator Loss: -0.5732836127281189 Generator Loss: -0.2962237000465393\nEpoch [116/240] Step [2400] Discriminator Loss: 0.025539517402648926 Generator Loss: -0.28388115763664246\nEpoch [116/240] Step [3000] Discriminator Loss: -0.4756602942943573 Generator Loss: -0.3226676285266876\nEpoch [116/240] Step [3600] Discriminator Loss: -0.5001481771469116 Generator Loss: -0.14692741632461548\nEpoch [116/240] Step [4200] Discriminator Loss: 0.278749942779541 Generator Loss: -0.4424688220024109\nEpoch [116/240] Step [4800] Discriminator Loss: -0.7577598690986633 Generator Loss: -0.09225662052631378\nEpoch [116/240] Step [5400] Discriminator Loss: -0.5682052969932556 Generator Loss: -0.1748822033405304\nEpoch [116/240] Step [6000] Discriminator Loss: -0.18036052584648132 Generator Loss: -0.27260908484458923\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  49%|████▉     | 117/240 [1:15:10<1:19:19, 38.69s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [116/240] Avg Discriminator Loss: -0.31892015282815195 Avg Generator Loss: -0.25655559933959293\nEpoch [117/240] Step [0] Discriminator Loss: -0.27361270785331726 Generator Loss: -0.6488282680511475\nEpoch [117/240] Step [600] Discriminator Loss: 0.392017662525177 Generator Loss: -0.26640602946281433\nEpoch [117/240] Step [1200] Discriminator Loss: -0.10633091628551483 Generator Loss: -0.15908826887607574\nEpoch [117/240] Step [1800] Discriminator Loss: -0.6167639493942261 Generator Loss: -0.023634672164916992\nEpoch [117/240] Step [2400] Discriminator Loss: -0.4596876800060272 Generator Loss: -0.18411748111248016\nEpoch [117/240] Step [3000] Discriminator Loss: -0.10047179460525513 Generator Loss: -0.06508765369653702\nEpoch [117/240] Step [3600] Discriminator Loss: -0.6213517189025879 Generator Loss: -0.24792326986789703\nEpoch [117/240] Step [4200] Discriminator Loss: -0.6105564832687378 Generator Loss: -0.13239507377147675\nEpoch [117/240] Step [4800] Discriminator Loss: -0.6814121007919312 Generator Loss: -0.2241736501455307\nEpoch [117/240] Step [5400] Discriminator Loss: -0.6557316780090332 Generator Loss: -0.27099716663360596\nEpoch [117/240] Step [6000] Discriminator Loss: -0.36962956190109253 Generator Loss: -0.3090985417366028\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  49%|████▉     | 118/240 [1:15:48<1:18:34, 38.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [117/240] Avg Discriminator Loss: -0.489046554766841 Avg Generator Loss: -0.21130218554881738\nEpoch [118/240] Step [0] Discriminator Loss: -0.7628195881843567 Generator Loss: -0.18052397668361664\nEpoch [118/240] Step [600] Discriminator Loss: -0.6178323030471802 Generator Loss: -0.257090300321579\nEpoch [118/240] Step [1200] Discriminator Loss: -0.5592206716537476 Generator Loss: -0.16079489886760712\nEpoch [118/240] Step [1800] Discriminator Loss: -0.6532307863235474 Generator Loss: -0.1775740385055542\nEpoch [118/240] Step [2400] Discriminator Loss: -0.6090235710144043 Generator Loss: -0.12346123903989792\nEpoch [118/240] Step [3000] Discriminator Loss: -0.7531160712242126 Generator Loss: -0.18343250453472137\nEpoch [118/240] Step [3600] Discriminator Loss: -0.5938672423362732 Generator Loss: -0.24931327998638153\nEpoch [118/240] Step [4200] Discriminator Loss: -0.7356171607971191 Generator Loss: -0.16991542279720306\nEpoch [118/240] Step [4800] Discriminator Loss: -0.41646701097488403 Generator Loss: -0.3901055157184601\nEpoch [118/240] Step [5400] Discriminator Loss: -0.24263155460357666 Generator Loss: -0.43633466958999634\nEpoch [118/240] Step [6000] Discriminator Loss: -0.41245388984680176 Generator Loss: -0.4801786541938782\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  50%|████▉     | 119/240 [1:16:27<1:17:50, 38.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [118/240] Avg Discriminator Loss: -0.5657490943814372 Avg Generator Loss: -0.22106563909859447\nEpoch [119/240] Step [0] Discriminator Loss: -0.30505746603012085 Generator Loss: -0.2611956298351288\nEpoch [119/240] Step [600] Discriminator Loss: -0.6608604192733765 Generator Loss: -0.15400293469429016\nEpoch [119/240] Step [1200] Discriminator Loss: -0.3149503171443939 Generator Loss: -0.2714954614639282\nEpoch [119/240] Step [1800] Discriminator Loss: -0.6731424331665039 Generator Loss: -0.23161575198173523\nEpoch [119/240] Step [2400] Discriminator Loss: -0.007970690727233887 Generator Loss: -0.26831868290901184\nEpoch [119/240] Step [3000] Discriminator Loss: -0.5990284085273743 Generator Loss: -0.2995010316371918\nEpoch [119/240] Step [3600] Discriminator Loss: -0.6970518231391907 Generator Loss: -0.13086409866809845\nEpoch [119/240] Step [4200] Discriminator Loss: -0.4808740019798279 Generator Loss: -0.2901938259601593\nEpoch [119/240] Step [4800] Discriminator Loss: -0.5139211416244507 Generator Loss: -0.3920626938343048\nEpoch [119/240] Step [5400] Discriminator Loss: -0.8075578808784485 Generator Loss: -0.10441230237483978\nEpoch [119/240] Step [6000] Discriminator Loss: -0.602508544921875 Generator Loss: -0.22229304909706116\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  50%|█████     | 120/240 [1:17:05<1:17:05, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [119/240] Avg Discriminator Loss: -0.5278572467302446 Avg Generator Loss: -0.22639086610559142\nEpoch [120/240] Step [0] Discriminator Loss: -0.5680058002471924 Generator Loss: -0.2873082756996155\nEpoch [120/240] Step [600] Discriminator Loss: -0.7892531752586365 Generator Loss: -0.09648820012807846\nEpoch [120/240] Step [1200] Discriminator Loss: -0.6232898831367493 Generator Loss: -0.26918020844459534\nEpoch [120/240] Step [1800] Discriminator Loss: -0.7465640306472778 Generator Loss: -0.15625213086605072\nEpoch [120/240] Step [2400] Discriminator Loss: -0.5749826431274414 Generator Loss: -0.12287403643131256\nEpoch [120/240] Step [3000] Discriminator Loss: -0.526813805103302 Generator Loss: -0.3120729923248291\nEpoch [120/240] Step [3600] Discriminator Loss: -0.5869825482368469 Generator Loss: -0.23042556643486023\nEpoch [120/240] Step [4200] Discriminator Loss: -0.6494631767272949 Generator Loss: -0.2744811475276947\nEpoch [120/240] Step [4800] Discriminator Loss: -0.5101984143257141 Generator Loss: -0.4927847683429718\nEpoch [120/240] Step [5400] Discriminator Loss: -0.6794137954711914 Generator Loss: -0.21454212069511414\nEpoch [120/240] Step [6000] Discriminator Loss: -0.7551043629646301 Generator Loss: -0.13775493204593658\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  50%|█████     | 121/240 [1:17:44<1:16:28, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [120/240] Avg Discriminator Loss: -0.5001657236462984 Avg Generator Loss: -0.236782020619719\nEpoch [121/240] Step [0] Discriminator Loss: -0.11995798349380493 Generator Loss: -0.15398311614990234\nEpoch [121/240] Step [600] Discriminator Loss: -0.1448356807231903 Generator Loss: -0.30663830041885376\nEpoch [121/240] Step [1200] Discriminator Loss: -0.5520002841949463 Generator Loss: -0.39504456520080566\nEpoch [121/240] Step [1800] Discriminator Loss: -0.8438902497291565 Generator Loss: -0.0070837149396538734\nEpoch [121/240] Step [2400] Discriminator Loss: -0.681064248085022 Generator Loss: -0.18506157398223877\nEpoch [121/240] Step [3000] Discriminator Loss: -0.4245235025882721 Generator Loss: -0.23368512094020844\nEpoch [121/240] Step [3600] Discriminator Loss: -0.15209169685840607 Generator Loss: -0.2420593798160553\nEpoch [121/240] Step [4200] Discriminator Loss: -0.19573341310024261 Generator Loss: -0.45968976616859436\nEpoch [121/240] Step [4800] Discriminator Loss: -0.04445080831646919 Generator Loss: -0.38942793011665344\nEpoch [121/240] Step [5400] Discriminator Loss: 0.166139617562294 Generator Loss: -0.39250925183296204\nEpoch [121/240] Step [6000] Discriminator Loss: 0.07025602459907532 Generator Loss: -0.39955374598503113\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  51%|█████     | 122/240 [1:18:22<1:15:48, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [121/240] Avg Discriminator Loss: -0.15391823810426306 Avg Generator Loss: -0.29318265928358056\nEpoch [122/240] Step [0] Discriminator Loss: 0.07296205312013626 Generator Loss: -0.4023144245147705\nEpoch [122/240] Step [600] Discriminator Loss: -0.08184492588043213 Generator Loss: -0.3548593521118164\nEpoch [122/240] Step [1200] Discriminator Loss: -0.04961010068655014 Generator Loss: -0.37646031379699707\nEpoch [122/240] Step [1800] Discriminator Loss: -0.206138014793396 Generator Loss: -0.32173001766204834\nEpoch [122/240] Step [2400] Discriminator Loss: -0.0877251923084259 Generator Loss: -0.5060136318206787\nEpoch [122/240] Step [3000] Discriminator Loss: -0.3384384512901306 Generator Loss: -0.48137083649635315\nEpoch [122/240] Step [3600] Discriminator Loss: 0.09488451480865479 Generator Loss: -0.3306852877140045\nEpoch [122/240] Step [4200] Discriminator Loss: -0.5645617842674255 Generator Loss: -0.23769205808639526\nEpoch [122/240] Step [4800] Discriminator Loss: -0.5710227489471436 Generator Loss: -0.2220485955476761\nEpoch [122/240] Step [5400] Discriminator Loss: -0.42405736446380615 Generator Loss: -0.22177210450172424\nEpoch [122/240] Step [6000] Discriminator Loss: -0.654212474822998 Generator Loss: -0.22350740432739258\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  51%|█████▏    | 123/240 [1:19:01<1:15:11, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [122/240] Avg Discriminator Loss: -0.2733975914426339 Avg Generator Loss: -0.3038369587080164\nEpoch [123/240] Step [0] Discriminator Loss: -0.44952356815338135 Generator Loss: -0.28431206941604614\nEpoch [123/240] Step [600] Discriminator Loss: -0.6684293746948242 Generator Loss: -0.1731574833393097\nEpoch [123/240] Step [1200] Discriminator Loss: -0.7567152380943298 Generator Loss: -0.15624402463436127\nEpoch [123/240] Step [1800] Discriminator Loss: -0.7364339828491211 Generator Loss: -0.19128979742527008\nEpoch [123/240] Step [2400] Discriminator Loss: -0.7052428722381592 Generator Loss: -0.23519933223724365\nEpoch [123/240] Step [3000] Discriminator Loss: -0.5053145289421082 Generator Loss: -0.32202357053756714\nEpoch [123/240] Step [3600] Discriminator Loss: -0.21090443432331085 Generator Loss: -0.35003823041915894\nEpoch [123/240] Step [4200] Discriminator Loss: -0.44746339321136475 Generator Loss: -0.24057911336421967\nEpoch [123/240] Step [4800] Discriminator Loss: -0.6860825419425964 Generator Loss: -0.24076049029827118\nEpoch [123/240] Step [5400] Discriminator Loss: -0.5803079605102539 Generator Loss: -0.12797830998897552\nEpoch [123/240] Step [6000] Discriminator Loss: -0.3326009511947632 Generator Loss: -0.24905118346214294\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  52%|█████▏    | 124/240 [1:19:39<1:14:32, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [123/240] Avg Discriminator Loss: -0.43120801315093654 Avg Generator Loss: -0.2395376283197831\nEpoch [124/240] Step [0] Discriminator Loss: -0.7392224669456482 Generator Loss: -0.16801463067531586\nEpoch [124/240] Step [600] Discriminator Loss: -0.47220221161842346 Generator Loss: -0.1694183349609375\nEpoch [124/240] Step [1200] Discriminator Loss: 0.015474006533622742 Generator Loss: -0.40042340755462646\nEpoch [124/240] Step [1800] Discriminator Loss: -0.06820432841777802 Generator Loss: -0.3609902858734131\nEpoch [124/240] Step [2400] Discriminator Loss: -0.27280062437057495 Generator Loss: -0.2593385577201843\nEpoch [124/240] Step [3000] Discriminator Loss: -0.8007131218910217 Generator Loss: -0.06867009401321411\nEpoch [124/240] Step [3600] Discriminator Loss: -0.6977488994598389 Generator Loss: -0.125850647687912\nEpoch [124/240] Step [4200] Discriminator Loss: -0.4456784129142761 Generator Loss: -0.11297407746315002\nEpoch [124/240] Step [4800] Discriminator Loss: -0.3993133008480072 Generator Loss: -0.2716154158115387\nEpoch [124/240] Step [5400] Discriminator Loss: -0.5321459770202637 Generator Loss: -0.2528849244117737\nEpoch [124/240] Step [6000] Discriminator Loss: -0.21863046288490295 Generator Loss: -0.28468042612075806\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  52%|█████▏    | 125/240 [1:20:18<1:13:50, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [124/240] Avg Discriminator Loss: -0.3692198689795021 Avg Generator Loss: -0.2603992479904504\nEpoch [125/240] Step [0] Discriminator Loss: -0.48067352175712585 Generator Loss: -0.3441731035709381\nEpoch [125/240] Step [600] Discriminator Loss: -0.6462813019752502 Generator Loss: -0.20796820521354675\nEpoch [125/240] Step [1200] Discriminator Loss: -0.6754624247550964 Generator Loss: -0.12693141400814056\nEpoch [125/240] Step [1800] Discriminator Loss: -0.6088976263999939 Generator Loss: -0.2416021227836609\nEpoch [125/240] Step [2400] Discriminator Loss: -0.5365503430366516 Generator Loss: -0.22179965674877167\nEpoch [125/240] Step [3000] Discriminator Loss: -0.318261981010437 Generator Loss: -0.48259541392326355\nEpoch [125/240] Step [3600] Discriminator Loss: -0.15624715387821198 Generator Loss: -0.5164116621017456\nEpoch [125/240] Step [4200] Discriminator Loss: -0.26823481917381287 Generator Loss: -0.2888118624687195\nEpoch [125/240] Step [4800] Discriminator Loss: -0.741477906703949 Generator Loss: -0.13667353987693787\nEpoch [125/240] Step [5400] Discriminator Loss: -0.7792110443115234 Generator Loss: -0.1012406125664711\nEpoch [125/240] Step [6000] Discriminator Loss: -0.24808813631534576 Generator Loss: -0.13627713918685913\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  52%|█████▎    | 126/240 [1:20:56<1:13:07, 38.49s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [125/240] Avg Discriminator Loss: -0.42763334466315017 Avg Generator Loss: -0.21590581866520228\nEpoch [126/240] Step [0] Discriminator Loss: -0.5792385935783386 Generator Loss: -0.0884292796254158\nEpoch [126/240] Step [600] Discriminator Loss: -0.19089055061340332 Generator Loss: -0.3179475963115692\nEpoch [126/240] Step [1200] Discriminator Loss: -0.2591380476951599 Generator Loss: -0.2348959743976593\nEpoch [126/240] Step [1800] Discriminator Loss: -0.45242685079574585 Generator Loss: -0.3481677770614624\nEpoch [126/240] Step [2400] Discriminator Loss: -0.6603947281837463 Generator Loss: -0.22525851428508759\nEpoch [126/240] Step [3000] Discriminator Loss: -0.7089159488677979 Generator Loss: -0.13729920983314514\nEpoch [126/240] Step [3600] Discriminator Loss: -0.30663684010505676 Generator Loss: -0.1521618664264679\nEpoch [126/240] Step [4200] Discriminator Loss: -0.5599560737609863 Generator Loss: -0.39789628982543945\nEpoch [126/240] Step [4800] Discriminator Loss: -0.5274245738983154 Generator Loss: -0.21138159930706024\nEpoch [126/240] Step [5400] Discriminator Loss: -0.5698204040527344 Generator Loss: -0.09864401817321777\nEpoch [126/240] Step [6000] Discriminator Loss: -0.7308138012886047 Generator Loss: -0.17471039295196533\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  53%|█████▎    | 127/240 [1:21:35<1:12:30, 38.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [126/240] Avg Discriminator Loss: -0.4964383737944858 Avg Generator Loss: -0.23569267008439962\nEpoch [127/240] Step [0] Discriminator Loss: -0.5762143135070801 Generator Loss: -0.31063368916511536\nEpoch [127/240] Step [600] Discriminator Loss: -0.7213351726531982 Generator Loss: -0.15587995946407318\nEpoch [127/240] Step [1200] Discriminator Loss: -0.5670290589332581 Generator Loss: -0.2797534465789795\nEpoch [127/240] Step [1800] Discriminator Loss: -0.7655351161956787 Generator Loss: -0.10372398048639297\nEpoch [127/240] Step [2400] Discriminator Loss: -0.5279539227485657 Generator Loss: -0.21989454329013824\nEpoch [127/240] Step [3000] Discriminator Loss: 0.7181494235992432 Generator Loss: -0.10152849555015564\nEpoch [127/240] Step [3600] Discriminator Loss: -0.5564324855804443 Generator Loss: -0.27849245071411133\nEpoch [127/240] Step [4200] Discriminator Loss: -0.6739116907119751 Generator Loss: -0.2190876454114914\nEpoch [127/240] Step [4800] Discriminator Loss: -0.6907920837402344 Generator Loss: -0.22191904485225677\nEpoch [127/240] Step [5400] Discriminator Loss: -0.5390653610229492 Generator Loss: -0.19916552305221558\nEpoch [127/240] Step [6000] Discriminator Loss: 1.1394708156585693 Generator Loss: -0.9521067142486572\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  53%|█████▎    | 128/240 [1:22:13<1:11:49, 38.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [127/240] Avg Discriminator Loss: -0.5010106740417061 Avg Generator Loss: -0.2565777147113731\nEpoch [128/240] Step [0] Discriminator Loss: -0.764442503452301 Generator Loss: -0.031884171068668365\nEpoch [128/240] Step [600] Discriminator Loss: -0.5288810133934021 Generator Loss: -0.24134089052677155\nEpoch [128/240] Step [1200] Discriminator Loss: 0.07271359860897064 Generator Loss: -0.3815094828605652\nEpoch [128/240] Step [1800] Discriminator Loss: -0.436118483543396 Generator Loss: -0.15492193400859833\nEpoch [128/240] Step [2400] Discriminator Loss: -0.07731792330741882 Generator Loss: -0.3884790539741516\nEpoch [128/240] Step [3000] Discriminator Loss: -0.35477080941200256 Generator Loss: -0.24142363667488098\nEpoch [128/240] Step [3600] Discriminator Loss: -0.3292853534221649 Generator Loss: -0.312872976064682\nEpoch [128/240] Step [4200] Discriminator Loss: -0.3730924129486084 Generator Loss: -0.357194185256958\nEpoch [128/240] Step [4800] Discriminator Loss: -0.7653231620788574 Generator Loss: -0.0702156275510788\nEpoch [128/240] Step [5400] Discriminator Loss: -0.5245363712310791 Generator Loss: -0.18457317352294922\nEpoch [128/240] Step [6000] Discriminator Loss: -0.5201685428619385 Generator Loss: -0.238811194896698\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  54%|█████▍    | 129/240 [1:22:51<1:11:04, 38.42s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [128/240] Avg Discriminator Loss: -0.2850635280430099 Avg Generator Loss: -0.263047234056306\nEpoch [129/240] Step [0] Discriminator Loss: -0.7374923825263977 Generator Loss: -0.15059484541416168\nEpoch [129/240] Step [600] Discriminator Loss: -0.6578672528266907 Generator Loss: -0.25173962116241455\nEpoch [129/240] Step [1200] Discriminator Loss: -0.6634528040885925 Generator Loss: -0.1820485144853592\nEpoch [129/240] Step [1800] Discriminator Loss: -0.6313300132751465 Generator Loss: -0.19574740529060364\nEpoch [129/240] Step [2400] Discriminator Loss: -0.6166590452194214 Generator Loss: -0.12303100526332855\nEpoch [129/240] Step [3000] Discriminator Loss: -0.788642168045044 Generator Loss: -0.12333603948354721\nEpoch [129/240] Step [3600] Discriminator Loss: -0.6884819269180298 Generator Loss: -0.23122867941856384\nEpoch [129/240] Step [4200] Discriminator Loss: 0.3412055969238281 Generator Loss: -0.005436290986835957\nEpoch [129/240] Step [4800] Discriminator Loss: -0.35955002903938293 Generator Loss: -0.23738285899162292\nEpoch [129/240] Step [5400] Discriminator Loss: -0.6572908759117126 Generator Loss: -0.23961712419986725\nEpoch [129/240] Step [6000] Discriminator Loss: -0.6720063090324402 Generator Loss: -0.24246110022068024\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  54%|█████▍    | 130/240 [1:23:30<1:10:25, 38.42s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [129/240] Avg Discriminator Loss: -0.5323338181653738 Avg Generator Loss: -0.2210581940070013\nEpoch [130/240] Step [0] Discriminator Loss: -0.7395432591438293 Generator Loss: -0.19426888227462769\nEpoch [130/240] Step [600] Discriminator Loss: -0.5180877447128296 Generator Loss: -0.22707587480545044\nEpoch [130/240] Step [1200] Discriminator Loss: -0.6417611241340637 Generator Loss: -0.1719900220632553\nEpoch [130/240] Step [1800] Discriminator Loss: -0.7419083714485168 Generator Loss: -0.08635907620191574\nEpoch [130/240] Step [2400] Discriminator Loss: 0.11515133082866669 Generator Loss: -0.3921634554862976\nEpoch [130/240] Step [3000] Discriminator Loss: -0.66379714012146 Generator Loss: -0.06349682807922363\nEpoch [130/240] Step [3600] Discriminator Loss: -0.6246063709259033 Generator Loss: -0.1443977802991867\nEpoch [130/240] Step [4200] Discriminator Loss: -0.5414780378341675 Generator Loss: -0.19082093238830566\nEpoch [130/240] Step [4800] Discriminator Loss: -0.7955869436264038 Generator Loss: -0.0803593248128891\nEpoch [130/240] Step [5400] Discriminator Loss: -0.12786094844341278 Generator Loss: -0.26278799772262573\nEpoch [130/240] Step [6000] Discriminator Loss: -0.39907190203666687 Generator Loss: -0.28300145268440247\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  55%|█████▍    | 131/240 [1:24:08<1:09:51, 38.45s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [130/240] Avg Discriminator Loss: -0.3731921726749057 Avg Generator Loss: -0.2481301553076604\nEpoch [131/240] Step [0] Discriminator Loss: -0.33303648233413696 Generator Loss: -0.24129422008991241\nEpoch [131/240] Step [600] Discriminator Loss: -0.06035681813955307 Generator Loss: -0.5469964146614075\nEpoch [131/240] Step [1200] Discriminator Loss: -0.2642231285572052 Generator Loss: -0.4203890860080719\nEpoch [131/240] Step [1800] Discriminator Loss: -0.43496716022491455 Generator Loss: -0.19360843300819397\nEpoch [131/240] Step [2400] Discriminator Loss: -0.3881351053714752 Generator Loss: -0.12076562643051147\nEpoch [131/240] Step [3000] Discriminator Loss: -0.42098408937454224 Generator Loss: -0.031053323298692703\nEpoch [131/240] Step [3600] Discriminator Loss: -0.17652606964111328 Generator Loss: -0.40290921926498413\nEpoch [131/240] Step [4200] Discriminator Loss: -0.42698708176612854 Generator Loss: -0.30144068598747253\nEpoch [131/240] Step [4800] Discriminator Loss: -0.7102712392807007 Generator Loss: -0.16903749108314514\nEpoch [131/240] Step [5400] Discriminator Loss: -0.649366557598114 Generator Loss: -0.150588259100914\nEpoch [131/240] Step [6000] Discriminator Loss: -0.5354278683662415 Generator Loss: -0.19014336168766022\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  55%|█████▌    | 132/240 [1:24:47<1:09:13, 38.46s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [131/240] Avg Discriminator Loss: -0.4515464570059444 Avg Generator Loss: -0.20983776538854554\nEpoch [132/240] Step [0] Discriminator Loss: -0.7706663608551025 Generator Loss: -0.11585190892219543\nEpoch [132/240] Step [600] Discriminator Loss: -0.7206697463989258 Generator Loss: -0.15389078855514526\nEpoch [132/240] Step [1200] Discriminator Loss: -0.732071042060852 Generator Loss: -0.2663819491863251\nEpoch [132/240] Step [1800] Discriminator Loss: -0.569053053855896 Generator Loss: -0.18612924218177795\nEpoch [132/240] Step [2400] Discriminator Loss: -0.7517794966697693 Generator Loss: -0.10391296446323395\nEpoch [132/240] Step [3000] Discriminator Loss: -0.8139342069625854 Generator Loss: -0.15262554585933685\nEpoch [132/240] Step [3600] Discriminator Loss: -0.763062059879303 Generator Loss: -0.24068446457386017\nEpoch [132/240] Step [4200] Discriminator Loss: -0.5666906237602234 Generator Loss: -0.18693293631076813\nEpoch [132/240] Step [4800] Discriminator Loss: 0.0031784772872924805 Generator Loss: -0.18922880291938782\nEpoch [132/240] Step [5400] Discriminator Loss: 0.05676046013832092 Generator Loss: -0.4590493440628052\nEpoch [132/240] Step [6000] Discriminator Loss: -0.1850290149450302 Generator Loss: -0.15925952792167664\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  55%|█████▌    | 133/240 [1:25:25<1:08:39, 38.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [132/240] Avg Discriminator Loss: -0.5073425850861675 Avg Generator Loss: -0.22347371003781566\nEpoch [133/240] Step [0] Discriminator Loss: -0.5506928563117981 Generator Loss: -0.2000616043806076\nEpoch [133/240] Step [600] Discriminator Loss: -0.537693977355957 Generator Loss: -0.23659074306488037\nEpoch [133/240] Step [1200] Discriminator Loss: -0.49863624572753906 Generator Loss: -0.2590923011302948\nEpoch [133/240] Step [1800] Discriminator Loss: -0.7651642560958862 Generator Loss: -0.062259379774332047\nEpoch [133/240] Step [2400] Discriminator Loss: -0.6476697325706482 Generator Loss: -0.24398651719093323\nEpoch [133/240] Step [3000] Discriminator Loss: -0.7132667303085327 Generator Loss: -0.1691361665725708\nEpoch [133/240] Step [3600] Discriminator Loss: -0.7077538371086121 Generator Loss: -0.16067376732826233\nEpoch [133/240] Step [4200] Discriminator Loss: -0.3789026141166687 Generator Loss: -0.3720617890357971\nEpoch [133/240] Step [4800] Discriminator Loss: -0.44798609614372253 Generator Loss: -0.18036913871765137\nEpoch [133/240] Step [5400] Discriminator Loss: -0.7661551833152771 Generator Loss: -0.10578811913728714\nEpoch [133/240] Step [6000] Discriminator Loss: -0.3838801681995392 Generator Loss: -0.29360026121139526\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  56%|█████▌    | 134/240 [1:26:04<1:07:59, 38.49s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [133/240] Avg Discriminator Loss: -0.555352892330933 Avg Generator Loss: -0.21196921825436227\nEpoch [134/240] Step [0] Discriminator Loss: -0.652557373046875 Generator Loss: -0.2407078593969345\nEpoch [134/240] Step [600] Discriminator Loss: -0.7227378487586975 Generator Loss: -0.17089778184890747\nEpoch [134/240] Step [1200] Discriminator Loss: -0.47594839334487915 Generator Loss: -0.2905217707157135\nEpoch [134/240] Step [1800] Discriminator Loss: -0.7664055228233337 Generator Loss: -0.21011364459991455\nEpoch [134/240] Step [2400] Discriminator Loss: 0.326907753944397 Generator Loss: -0.399641215801239\nEpoch [134/240] Step [3000] Discriminator Loss: 0.7257248163223267 Generator Loss: -0.4344639182090759\nEpoch [134/240] Step [3600] Discriminator Loss: -0.15943212807178497 Generator Loss: -0.6998558044433594\nEpoch [134/240] Step [4200] Discriminator Loss: -0.39837977290153503 Generator Loss: -0.2963131368160248\nEpoch [134/240] Step [4800] Discriminator Loss: -0.6605014204978943 Generator Loss: -0.21554219722747803\nEpoch [134/240] Step [5400] Discriminator Loss: -0.5990091562271118 Generator Loss: -0.15706266462802887\nEpoch [134/240] Step [6000] Discriminator Loss: -0.49850642681121826 Generator Loss: -0.04561248794198036\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  56%|█████▋    | 135/240 [1:26:42<1:07:26, 38.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [134/240] Avg Discriminator Loss: -0.43563550123910766 Avg Generator Loss: -0.23161110844149257\nEpoch [135/240] Step [0] Discriminator Loss: -0.5218807458877563 Generator Loss: -0.2759080231189728\nEpoch [135/240] Step [600] Discriminator Loss: -0.5342018604278564 Generator Loss: -0.08891736716032028\nEpoch [135/240] Step [1200] Discriminator Loss: -0.738978922367096 Generator Loss: -0.14190687239170074\nEpoch [135/240] Step [1800] Discriminator Loss: -0.7325607538223267 Generator Loss: -0.19856834411621094\nEpoch [135/240] Step [2400] Discriminator Loss: -0.6399905681610107 Generator Loss: -0.1193888783454895\nEpoch [135/240] Step [3000] Discriminator Loss: -0.8427693843841553 Generator Loss: -0.10112452507019043\nEpoch [135/240] Step [3600] Discriminator Loss: -0.6406095027923584 Generator Loss: -0.14710170030593872\nEpoch [135/240] Step [4200] Discriminator Loss: -0.7915507555007935 Generator Loss: -0.18087223172187805\nEpoch [135/240] Step [4800] Discriminator Loss: -0.6703833937644958 Generator Loss: -0.245741069316864\nEpoch [135/240] Step [5400] Discriminator Loss: -0.4765935242176056 Generator Loss: -0.2137400209903717\nEpoch [135/240] Step [6000] Discriminator Loss: 9.999143600463867 Generator Loss: -0.9932056069374084\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  57%|█████▋    | 136/240 [1:27:21<1:06:43, 38.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [135/240] Avg Discriminator Loss: 0.8166925084569079 Avg Generator Loss: -0.2932203589774832\nEpoch [136/240] Step [0] Discriminator Loss: 9.996779441833496 Generator Loss: -0.9941809177398682\nEpoch [136/240] Step [600] Discriminator Loss: 9.995575904846191 Generator Loss: -0.9951546788215637\nEpoch [136/240] Step [1200] Discriminator Loss: 0.4061052203178406 Generator Loss: -0.6992014646530151\nEpoch [136/240] Step [1800] Discriminator Loss: 0.35342055559158325 Generator Loss: -0.5182501077651978\nEpoch [136/240] Step [2400] Discriminator Loss: -0.05996908247470856 Generator Loss: -0.22358644008636475\nEpoch [136/240] Step [3000] Discriminator Loss: 0.3255733549594879 Generator Loss: -0.7763333916664124\nEpoch [136/240] Step [3600] Discriminator Loss: 0.23487648367881775 Generator Loss: -0.4567033350467682\nEpoch [136/240] Step [4200] Discriminator Loss: -0.30503877997398376 Generator Loss: -0.16011184453964233\nEpoch [136/240] Step [4800] Discriminator Loss: -0.5546808838844299 Generator Loss: -0.10269950330257416\nEpoch [136/240] Step [5400] Discriminator Loss: -0.5858515501022339 Generator Loss: -0.0701446682214737\nEpoch [136/240] Step [6000] Discriminator Loss: -0.5294115543365479 Generator Loss: -0.28811952471733093\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  57%|█████▋    | 137/240 [1:27:59<1:06:09, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [136/240] Avg Discriminator Loss: 1.0509709346316236 Avg Generator Loss: -0.38944097653188275\nEpoch [137/240] Step [0] Discriminator Loss: -0.5613404512405396 Generator Loss: -0.09259796142578125\nEpoch [137/240] Step [600] Discriminator Loss: -0.6013816595077515 Generator Loss: -0.19748397171497345\nEpoch [137/240] Step [1200] Discriminator Loss: -0.5000672936439514 Generator Loss: -0.25253137946128845\nEpoch [137/240] Step [1800] Discriminator Loss: -0.4787192940711975 Generator Loss: -0.23806485533714294\nEpoch [137/240] Step [2400] Discriminator Loss: -0.35942041873931885 Generator Loss: -0.4265446364879608\nEpoch [137/240] Step [3000] Discriminator Loss: -0.8107103705406189 Generator Loss: -0.11115366220474243\nEpoch [137/240] Step [3600] Discriminator Loss: -0.7393878102302551 Generator Loss: -0.17411208152770996\nEpoch [137/240] Step [4200] Discriminator Loss: -0.3707320988178253 Generator Loss: -0.3738083243370056\nEpoch [137/240] Step [4800] Discriminator Loss: -0.7338757514953613 Generator Loss: -0.12924493849277496\nEpoch [137/240] Step [5400] Discriminator Loss: 0.9063541889190674 Generator Loss: -0.9029709696769714\nEpoch [137/240] Step [6000] Discriminator Loss: -0.28129538893699646 Generator Loss: -0.35310569405555725\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  57%|█████▊    | 138/240 [1:28:38<1:05:27, 38.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [137/240] Avg Discriminator Loss: -0.44784253524554957 Avg Generator Loss: -0.23002958555634206\nEpoch [138/240] Step [0] Discriminator Loss: -0.588112473487854 Generator Loss: -0.04395793750882149\nEpoch [138/240] Step [600] Discriminator Loss: -0.2949730157852173 Generator Loss: -0.3137204647064209\nEpoch [138/240] Step [1200] Discriminator Loss: -0.6174466013908386 Generator Loss: -0.10133714973926544\nEpoch [138/240] Step [1800] Discriminator Loss: -0.3153669536113739 Generator Loss: -0.2844017744064331\nEpoch [138/240] Step [2400] Discriminator Loss: -0.6007669568061829 Generator Loss: -0.1332377791404724\nEpoch [138/240] Step [3000] Discriminator Loss: -0.5817415714263916 Generator Loss: -0.3893554210662842\nEpoch [138/240] Step [3600] Discriminator Loss: -0.5752838253974915 Generator Loss: -0.272560179233551\nEpoch [138/240] Step [4200] Discriminator Loss: -0.6144840717315674 Generator Loss: -0.2553206980228424\nEpoch [138/240] Step [4800] Discriminator Loss: -0.7000846862792969 Generator Loss: -0.2019849717617035\nEpoch [138/240] Step [5400] Discriminator Loss: -0.24596978724002838 Generator Loss: -0.3931038975715637\nEpoch [138/240] Step [6000] Discriminator Loss: -0.586121141910553 Generator Loss: -0.21383580565452576\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  58%|█████▊    | 139/240 [1:29:16<1:04:45, 38.47s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [138/240] Avg Discriminator Loss: -0.44774544064378563 Avg Generator Loss: -0.24542957981843705\nEpoch [139/240] Step [0] Discriminator Loss: -0.6991528868675232 Generator Loss: -0.2264411747455597\nEpoch [139/240] Step [600] Discriminator Loss: -0.48406338691711426 Generator Loss: -0.1960257589817047\nEpoch [139/240] Step [1200] Discriminator Loss: -0.4006474018096924 Generator Loss: -0.21533502638339996\nEpoch [139/240] Step [1800] Discriminator Loss: -0.470023512840271 Generator Loss: -0.1767272651195526\nEpoch [139/240] Step [2400] Discriminator Loss: -0.7252631783485413 Generator Loss: -0.20064270496368408\nEpoch [139/240] Step [3000] Discriminator Loss: -0.5904272794723511 Generator Loss: -0.17263314127922058\nEpoch [139/240] Step [3600] Discriminator Loss: -0.6922698020935059 Generator Loss: -0.16700758039951324\nEpoch [139/240] Step [4200] Discriminator Loss: -0.622370719909668 Generator Loss: -0.34844377636909485\nEpoch [139/240] Step [4800] Discriminator Loss: -0.6794270873069763 Generator Loss: -0.1740405410528183\nEpoch [139/240] Step [5400] Discriminator Loss: -0.3720085918903351 Generator Loss: -0.3839930593967438\nEpoch [139/240] Step [6000] Discriminator Loss: -0.3454611897468567 Generator Loss: -0.3084843158721924\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  58%|█████▊    | 140/240 [1:29:55<1:04:08, 38.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [139/240] Avg Discriminator Loss: -0.5315606477278056 Avg Generator Loss: -0.22293799857680613\nEpoch [140/240] Step [0] Discriminator Loss: -0.4504087567329407 Generator Loss: -0.47068455815315247\nEpoch [140/240] Step [600] Discriminator Loss: -0.2248571515083313 Generator Loss: -0.3651256263256073\nEpoch [140/240] Step [1200] Discriminator Loss: -0.42088842391967773 Generator Loss: -0.1551082581281662\nEpoch [140/240] Step [1800] Discriminator Loss: 4.047940254211426 Generator Loss: -0.32889482378959656\nEpoch [140/240] Step [2400] Discriminator Loss: 0.17290322482585907 Generator Loss: -0.5373623967170715\nEpoch [140/240] Step [3000] Discriminator Loss: 0.009242773056030273 Generator Loss: -0.36670148372650146\nEpoch [140/240] Step [3600] Discriminator Loss: -0.17812295258045197 Generator Loss: -0.34917116165161133\nEpoch [140/240] Step [4200] Discriminator Loss: -0.1453462839126587 Generator Loss: -0.23651432991027832\nEpoch [140/240] Step [4800] Discriminator Loss: -0.69013911485672 Generator Loss: -0.08598548173904419\nEpoch [140/240] Step [5400] Discriminator Loss: -0.4461521506309509 Generator Loss: -0.3916952311992645\nEpoch [140/240] Step [6000] Discriminator Loss: -0.13375359773635864 Generator Loss: -0.16268390417099\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  59%|█████▉    | 141/240 [1:30:34<1:03:36, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [140/240] Avg Discriminator Loss: 0.04446776617905159 Avg Generator Loss: -0.302768320043063\nEpoch [141/240] Step [0] Discriminator Loss: -0.5702012777328491 Generator Loss: -0.0394095741212368\nEpoch [141/240] Step [600] Discriminator Loss: -0.5422499179840088 Generator Loss: -0.17869721353054047\nEpoch [141/240] Step [1200] Discriminator Loss: -0.6987688541412354 Generator Loss: -0.09646733850240707\nEpoch [141/240] Step [1800] Discriminator Loss: -0.48159968852996826 Generator Loss: -0.16928423941135406\nEpoch [141/240] Step [2400] Discriminator Loss: -0.7255175113677979 Generator Loss: -0.1152927428483963\nEpoch [141/240] Step [3000] Discriminator Loss: -0.6455793380737305 Generator Loss: -0.24844974279403687\nEpoch [141/240] Step [3600] Discriminator Loss: -0.21363329887390137 Generator Loss: -0.43926069140434265\nEpoch [141/240] Step [4200] Discriminator Loss: -0.5372470617294312 Generator Loss: -0.27173328399658203\nEpoch [141/240] Step [4800] Discriminator Loss: -0.27837616205215454 Generator Loss: -0.1521441638469696\nEpoch [141/240] Step [5400] Discriminator Loss: -0.5656105279922485 Generator Loss: -0.17052413523197174\nEpoch [141/240] Step [6000] Discriminator Loss: -0.6767085790634155 Generator Loss: -0.14607621729373932\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  59%|█████▉    | 142/240 [1:31:12<1:03:00, 38.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [141/240] Avg Discriminator Loss: -0.4937165379251316 Avg Generator Loss: -0.2118466690680756\nEpoch [142/240] Step [0] Discriminator Loss: -0.5491920709609985 Generator Loss: -0.35232290625572205\nEpoch [142/240] Step [600] Discriminator Loss: -0.7097211480140686 Generator Loss: -0.17677804827690125\nEpoch [142/240] Step [1200] Discriminator Loss: 0.046481356024742126 Generator Loss: -0.4538850784301758\nEpoch [142/240] Step [1800] Discriminator Loss: -0.6352120041847229 Generator Loss: -0.13138888776302338\nEpoch [142/240] Step [2400] Discriminator Loss: -0.7010862827301025 Generator Loss: -0.1300792694091797\nEpoch [142/240] Step [3000] Discriminator Loss: -0.545407772064209 Generator Loss: -0.1545354276895523\nEpoch [142/240] Step [3600] Discriminator Loss: -0.7508620023727417 Generator Loss: -0.16893085837364197\nEpoch [142/240] Step [4200] Discriminator Loss: -0.660939633846283 Generator Loss: -0.22738532721996307\nEpoch [142/240] Step [4800] Discriminator Loss: -0.6893216967582703 Generator Loss: -0.1626155823469162\nEpoch [142/240] Step [5400] Discriminator Loss: -0.7396723628044128 Generator Loss: -0.2034531831741333\nEpoch [142/240] Step [6000] Discriminator Loss: -0.6812454462051392 Generator Loss: -0.2069636732339859\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  60%|█████▉    | 143/240 [1:31:51<1:02:19, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [142/240] Avg Discriminator Loss: -0.5330414187176761 Avg Generator Loss: -0.2277977210657173\nEpoch [143/240] Step [0] Discriminator Loss: -0.7037607431411743 Generator Loss: -0.2320394068956375\nEpoch [143/240] Step [600] Discriminator Loss: -0.6336627006530762 Generator Loss: -0.16833922266960144\nEpoch [143/240] Step [1200] Discriminator Loss: -0.5088686943054199 Generator Loss: -0.2548600137233734\nEpoch [143/240] Step [1800] Discriminator Loss: -0.7528224587440491 Generator Loss: -0.10588657855987549\nEpoch [143/240] Step [2400] Discriminator Loss: -0.7341247797012329 Generator Loss: -0.13438597321510315\nEpoch [143/240] Step [3000] Discriminator Loss: -0.7652274370193481 Generator Loss: -0.0935220792889595\nEpoch [143/240] Step [3600] Discriminator Loss: -0.7154468894004822 Generator Loss: -0.20703773200511932\nEpoch [143/240] Step [4200] Discriminator Loss: -0.7495917677879333 Generator Loss: -0.08232218027114868\nEpoch [143/240] Step [4800] Discriminator Loss: -0.3508545160293579 Generator Loss: -0.21171198785305023\nEpoch [143/240] Step [5400] Discriminator Loss: -0.45726579427719116 Generator Loss: -0.1147518903017044\nEpoch [143/240] Step [6000] Discriminator Loss: -0.6841050386428833 Generator Loss: -0.15902327001094818\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  60%|██████    | 144/240 [1:32:29<1:01:41, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [143/240] Avg Discriminator Loss: -0.5860611492897565 Avg Generator Loss: -0.21850593681464264\nEpoch [144/240] Step [0] Discriminator Loss: -0.7606627345085144 Generator Loss: -0.13922490179538727\nEpoch [144/240] Step [600] Discriminator Loss: -0.7809789180755615 Generator Loss: -0.14158955216407776\nEpoch [144/240] Step [1200] Discriminator Loss: -0.6436051726341248 Generator Loss: -0.23633688688278198\nEpoch [144/240] Step [1800] Discriminator Loss: -0.6858876943588257 Generator Loss: -0.22003468871116638\nEpoch [144/240] Step [2400] Discriminator Loss: 2.242765426635742 Generator Loss: -0.2779195010662079\nEpoch [144/240] Step [3000] Discriminator Loss: -0.335863322019577 Generator Loss: -0.1494709700345993\nEpoch [144/240] Step [3600] Discriminator Loss: 0.36086171865463257 Generator Loss: -0.29700878262519836\nEpoch [144/240] Step [4200] Discriminator Loss: -0.6746797561645508 Generator Loss: -0.07641379535198212\nEpoch [144/240] Step [4800] Discriminator Loss: -0.5728458762168884 Generator Loss: -0.12266109138727188\nEpoch [144/240] Step [5400] Discriminator Loss: -0.1879526972770691 Generator Loss: -0.18437093496322632\nEpoch [144/240] Step [6000] Discriminator Loss: -0.5653642416000366 Generator Loss: -0.128508061170578\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  60%|██████    | 145/240 [1:33:08<1:01:00, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [144/240] Avg Discriminator Loss: -0.504301168734119 Avg Generator Loss: -0.22534388701189242\nEpoch [145/240] Step [0] Discriminator Loss: -0.6515960693359375 Generator Loss: -0.272761732339859\nEpoch [145/240] Step [600] Discriminator Loss: 0.011521533131599426 Generator Loss: -0.4489806294441223\nEpoch [145/240] Step [1200] Discriminator Loss: -0.3808748722076416 Generator Loss: -0.3973372280597687\nEpoch [145/240] Step [1800] Discriminator Loss: -0.419375479221344 Generator Loss: -0.2543376684188843\nEpoch [145/240] Step [2400] Discriminator Loss: 0.2938145399093628 Generator Loss: -0.4782767593860626\nEpoch [145/240] Step [3000] Discriminator Loss: -0.33910253643989563 Generator Loss: -0.36613667011260986\nEpoch [145/240] Step [3600] Discriminator Loss: -0.34023696184158325 Generator Loss: -0.3230477273464203\nEpoch [145/240] Step [4200] Discriminator Loss: -0.5291972756385803 Generator Loss: -0.18407195806503296\nEpoch [145/240] Step [4800] Discriminator Loss: -0.46958062052726746 Generator Loss: -0.34671005606651306\nEpoch [145/240] Step [5400] Discriminator Loss: -0.5388705730438232 Generator Loss: -0.30637049674987793\nEpoch [145/240] Step [6000] Discriminator Loss: -0.5644676089286804 Generator Loss: -0.03791185840964317\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  61%|██████    | 146/240 [1:33:46<1:00:20, 38.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [145/240] Avg Discriminator Loss: -0.3879685130093124 Avg Generator Loss: -0.23804973205722077\nEpoch [146/240] Step [0] Discriminator Loss: -0.6303114295005798 Generator Loss: -0.11266874521970749\nEpoch [146/240] Step [600] Discriminator Loss: -0.6468860507011414 Generator Loss: -0.11340716481208801\nEpoch [146/240] Step [1200] Discriminator Loss: -0.6071383357048035 Generator Loss: -0.2656785547733307\nEpoch [146/240] Step [1800] Discriminator Loss: -0.6937459707260132 Generator Loss: -0.15773910284042358\nEpoch [146/240] Step [2400] Discriminator Loss: -0.7375497221946716 Generator Loss: -0.1487056165933609\nEpoch [146/240] Step [3000] Discriminator Loss: -0.7675597071647644 Generator Loss: -0.18075568974018097\nEpoch [146/240] Step [3600] Discriminator Loss: -0.7947022914886475 Generator Loss: -0.16500894725322723\nEpoch [146/240] Step [4200] Discriminator Loss: -0.6971149444580078 Generator Loss: -0.23086872696876526\nEpoch [146/240] Step [4800] Discriminator Loss: -0.6605364084243774 Generator Loss: -0.11509144306182861\nEpoch [146/240] Step [5400] Discriminator Loss: -0.4213571548461914 Generator Loss: -0.3383827209472656\nEpoch [146/240] Step [6000] Discriminator Loss: -0.3602958619594574 Generator Loss: -0.21204549074172974\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  61%|██████▏   | 147/240 [1:34:25<59:43, 38.53s/it]  ","output_type":"stream"},{"name":"stdout","text":"Epoch [146/240] Avg Discriminator Loss: -0.6161851890576191 Avg Generator Loss: -0.1963756597147156\nEpoch [147/240] Step [0] Discriminator Loss: -0.6098206639289856 Generator Loss: -0.23341232538223267\nEpoch [147/240] Step [600] Discriminator Loss: -0.7225914001464844 Generator Loss: -0.09817871451377869\nEpoch [147/240] Step [1200] Discriminator Loss: -0.5453174114227295 Generator Loss: -0.32337653636932373\nEpoch [147/240] Step [1800] Discriminator Loss: -0.4299973249435425 Generator Loss: -0.17268726229667664\nEpoch [147/240] Step [2400] Discriminator Loss: -0.08993452787399292 Generator Loss: -0.1531001627445221\nEpoch [147/240] Step [3000] Discriminator Loss: -0.6392819285392761 Generator Loss: -0.10506296157836914\nEpoch [147/240] Step [3600] Discriminator Loss: -0.6956965327262878 Generator Loss: -0.23855087161064148\nEpoch [147/240] Step [4200] Discriminator Loss: -0.6554449200630188 Generator Loss: -0.20378652215003967\nEpoch [147/240] Step [4800] Discriminator Loss: -0.745826244354248 Generator Loss: -0.18919838964939117\nEpoch [147/240] Step [5400] Discriminator Loss: -0.1399746835231781 Generator Loss: -0.40437254309654236\nEpoch [147/240] Step [6000] Discriminator Loss: -0.5127292275428772 Generator Loss: -0.3400935232639313\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  62%|██████▏   | 148/240 [1:35:05<1:00:00, 39.14s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [147/240] Avg Discriminator Loss: -0.5493534853879786 Avg Generator Loss: -0.244257881432335\nEpoch [148/240] Step [0] Discriminator Loss: -0.6042389869689941 Generator Loss: -0.2717939615249634\nEpoch [148/240] Step [600] Discriminator Loss: -0.709526777267456 Generator Loss: -0.18037588894367218\nEpoch [148/240] Step [1200] Discriminator Loss: -0.7268078327178955 Generator Loss: -0.07279883325099945\nEpoch [148/240] Step [1800] Discriminator Loss: -0.3918376564979553 Generator Loss: -0.46799010038375854\nEpoch [148/240] Step [2400] Discriminator Loss: -0.2752341032028198 Generator Loss: -0.2589447796344757\nEpoch [148/240] Step [3000] Discriminator Loss: -0.631790280342102 Generator Loss: -0.0940307229757309\nEpoch [148/240] Step [3600] Discriminator Loss: -0.3659084439277649 Generator Loss: -0.18510447442531586\nEpoch [148/240] Step [4200] Discriminator Loss: -0.7114732265472412 Generator Loss: -0.16749759018421173\nEpoch [148/240] Step [4800] Discriminator Loss: -0.6092368960380554 Generator Loss: -0.2908296287059784\nEpoch [148/240] Step [5400] Discriminator Loss: -0.45781660079956055 Generator Loss: -0.32376953959465027\nEpoch [148/240] Step [6000] Discriminator Loss: -0.5153816342353821 Generator Loss: -0.41415929794311523\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  62%|██████▏   | 149/240 [1:35:44<59:09, 39.00s/it]  ","output_type":"stream"},{"name":"stdout","text":"Epoch [148/240] Avg Discriminator Loss: -0.4996363264900861 Avg Generator Loss: -0.24496095483583627\nEpoch [149/240] Step [0] Discriminator Loss: -0.5541749000549316 Generator Loss: -0.07807567715644836\nEpoch [149/240] Step [600] Discriminator Loss: -0.746616005897522 Generator Loss: -0.10793572664260864\nEpoch [149/240] Step [1200] Discriminator Loss: -0.5756274461746216 Generator Loss: -0.2202070951461792\nEpoch [149/240] Step [1800] Discriminator Loss: -0.7537795305252075 Generator Loss: -0.10629469901323318\nEpoch [149/240] Step [2400] Discriminator Loss: -0.4318998456001282 Generator Loss: -0.29584598541259766\nEpoch [149/240] Step [3000] Discriminator Loss: -0.7933262586593628 Generator Loss: -0.1281045377254486\nEpoch [149/240] Step [3600] Discriminator Loss: -0.7292261123657227 Generator Loss: -0.08995027095079422\nEpoch [149/240] Step [4200] Discriminator Loss: -0.7975649833679199 Generator Loss: -0.09264729917049408\nEpoch [149/240] Step [4800] Discriminator Loss: -0.49211400747299194 Generator Loss: -0.25859490036964417\nEpoch [149/240] Step [5400] Discriminator Loss: -0.7255972623825073 Generator Loss: -0.07704030722379684\nEpoch [149/240] Step [6000] Discriminator Loss: 0.7411866188049316 Generator Loss: -0.4087717831134796\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  62%|██████▎   | 150/240 [1:36:23<58:19, 38.88s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [149/240] Avg Discriminator Loss: -0.606627535525259 Avg Generator Loss: -0.18027552926141918\nEpoch [150/240] Step [0] Discriminator Loss: -0.6931524276733398 Generator Loss: -0.2494092434644699\nEpoch [150/240] Step [600] Discriminator Loss: 0.2359980344772339 Generator Loss: -0.37323009967803955\nEpoch [150/240] Step [1200] Discriminator Loss: 0.23078446090221405 Generator Loss: -0.404778391122818\nEpoch [150/240] Step [1800] Discriminator Loss: -0.6658295392990112 Generator Loss: -0.1136377602815628\nEpoch [150/240] Step [2400] Discriminator Loss: -0.025310441851615906 Generator Loss: -0.35867974162101746\nEpoch [150/240] Step [3000] Discriminator Loss: -0.7480601668357849 Generator Loss: -0.1728881150484085\nEpoch [150/240] Step [3600] Discriminator Loss: -0.7258691191673279 Generator Loss: -0.16695451736450195\nEpoch [150/240] Step [4200] Discriminator Loss: -0.5812022686004639 Generator Loss: -0.08326751738786697\nEpoch [150/240] Step [4800] Discriminator Loss: -0.7045363187789917 Generator Loss: -0.14511823654174805\nEpoch [150/240] Step [5400] Discriminator Loss: -0.6856234669685364 Generator Loss: -0.12392871081829071\nEpoch [150/240] Step [6000] Discriminator Loss: -0.5652879476547241 Generator Loss: -0.19144052267074585\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  63%|██████▎   | 151/240 [1:37:01<57:26, 38.72s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [150/240] Avg Discriminator Loss: -0.39518887590576 Avg Generator Loss: -0.22727897492042937\nEpoch [151/240] Step [0] Discriminator Loss: -0.4221078157424927 Generator Loss: -0.28022831678390503\nEpoch [151/240] Step [600] Discriminator Loss: -0.7769312858581543 Generator Loss: -0.12825989723205566\nEpoch [151/240] Step [1200] Discriminator Loss: -0.6023461222648621 Generator Loss: -0.26516175270080566\nEpoch [151/240] Step [1800] Discriminator Loss: 9.683384895324707 Generator Loss: -0.9437474608421326\nEpoch [151/240] Step [2400] Discriminator Loss: 1.501326084136963 Generator Loss: -0.9588561654090881\nEpoch [151/240] Step [3000] Discriminator Loss: -0.15825696289539337 Generator Loss: -0.3463008403778076\nEpoch [151/240] Step [3600] Discriminator Loss: -0.6859908699989319 Generator Loss: -0.17860551178455353\nEpoch [151/240] Step [4200] Discriminator Loss: -0.4184528887271881 Generator Loss: -0.35797643661499023\nEpoch [151/240] Step [4800] Discriminator Loss: -0.3482329249382019 Generator Loss: -0.24521270394325256\nEpoch [151/240] Step [5400] Discriminator Loss: -0.0038923025131225586 Generator Loss: -0.41702374815940857\nEpoch [151/240] Step [6000] Discriminator Loss: -0.132516548037529 Generator Loss: -0.4494333863258362\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  63%|██████▎   | 152/240 [1:37:40<56:46, 38.70s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [151/240] Avg Discriminator Loss: -0.175542813067362 Avg Generator Loss: -0.3256850880417195\nEpoch [152/240] Step [0] Discriminator Loss: -0.47442004084587097 Generator Loss: -0.2255486249923706\nEpoch [152/240] Step [600] Discriminator Loss: -0.7435705661773682 Generator Loss: -0.06696481257677078\nEpoch [152/240] Step [1200] Discriminator Loss: -0.03139415383338928 Generator Loss: -0.5170525312423706\nEpoch [152/240] Step [1800] Discriminator Loss: -0.44853585958480835 Generator Loss: -0.1217363178730011\nEpoch [152/240] Step [2400] Discriminator Loss: -0.7233033180236816 Generator Loss: -0.13848493993282318\nEpoch [152/240] Step [3000] Discriminator Loss: -0.7363649010658264 Generator Loss: -0.1894102245569229\nEpoch [152/240] Step [3600] Discriminator Loss: -0.5315905809402466 Generator Loss: -0.21936184167861938\nEpoch [152/240] Step [4200] Discriminator Loss: -0.7486121654510498 Generator Loss: -0.22965878248214722\nEpoch [152/240] Step [4800] Discriminator Loss: -0.7609012722969055 Generator Loss: -0.14831891655921936\nEpoch [152/240] Step [5400] Discriminator Loss: -0.6744145750999451 Generator Loss: -0.16792327165603638\nEpoch [152/240] Step [6000] Discriminator Loss: -0.653121829032898 Generator Loss: -0.22799941897392273\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  64%|██████▍   | 153/240 [1:38:18<56:02, 38.65s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [152/240] Avg Discriminator Loss: -0.5877173366673264 Avg Generator Loss: -0.20337460866887055\nEpoch [153/240] Step [0] Discriminator Loss: -0.5743987560272217 Generator Loss: -0.25671184062957764\nEpoch [153/240] Step [600] Discriminator Loss: -0.5107910633087158 Generator Loss: -0.2225898802280426\nEpoch [153/240] Step [1200] Discriminator Loss: -0.6653092503547668 Generator Loss: -0.1986406147480011\nEpoch [153/240] Step [1800] Discriminator Loss: -0.6393942832946777 Generator Loss: -0.1965324431657791\nEpoch [153/240] Step [2400] Discriminator Loss: 0.11212015151977539 Generator Loss: -0.09427644312381744\nEpoch [153/240] Step [3000] Discriminator Loss: -0.4817405343055725 Generator Loss: -0.17323288321495056\nEpoch [153/240] Step [3600] Discriminator Loss: -0.6868407130241394 Generator Loss: -0.180490642786026\nEpoch [153/240] Step [4200] Discriminator Loss: -0.6595343351364136 Generator Loss: -0.25281739234924316\nEpoch [153/240] Step [4800] Discriminator Loss: -0.8129316568374634 Generator Loss: -0.13986656069755554\nEpoch [153/240] Step [5400] Discriminator Loss: -0.7642346024513245 Generator Loss: -0.1393677443265915\nEpoch [153/240] Step [6000] Discriminator Loss: -0.6029925346374512 Generator Loss: -0.22821667790412903\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  64%|██████▍   | 154/240 [1:38:57<55:23, 38.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [153/240] Avg Discriminator Loss: -0.5922023216228345 Avg Generator Loss: -0.21573364852685414\nEpoch [154/240] Step [0] Discriminator Loss: -0.7642366290092468 Generator Loss: -0.13109438121318817\nEpoch [154/240] Step [600] Discriminator Loss: -0.6721034049987793 Generator Loss: -0.18563124537467957\nEpoch [154/240] Step [1200] Discriminator Loss: -0.6784208416938782 Generator Loss: -0.22968371212482452\nEpoch [154/240] Step [1800] Discriminator Loss: -0.5119020342826843 Generator Loss: -0.2535920739173889\nEpoch [154/240] Step [2400] Discriminator Loss: -0.1662536859512329 Generator Loss: -0.09735424071550369\nEpoch [154/240] Step [3000] Discriminator Loss: -0.4691309332847595 Generator Loss: -0.3525537848472595\nEpoch [154/240] Step [3600] Discriminator Loss: -0.582343578338623 Generator Loss: -0.17518837749958038\nEpoch [154/240] Step [4200] Discriminator Loss: -0.676727831363678 Generator Loss: -0.2393426150083542\nEpoch [154/240] Step [4800] Discriminator Loss: -0.36664897203445435 Generator Loss: -0.677905797958374\nEpoch [154/240] Step [5400] Discriminator Loss: -0.23382556438446045 Generator Loss: -0.4603728652000427\nEpoch [154/240] Step [6000] Discriminator Loss: -0.014276355504989624 Generator Loss: -0.24172866344451904\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  65%|██████▍   | 155/240 [1:39:35<54:41, 38.61s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [154/240] Avg Discriminator Loss: -0.5226851365505121 Avg Generator Loss: -0.21136322071700742\nEpoch [155/240] Step [0] Discriminator Loss: -0.5040132999420166 Generator Loss: -0.18559710681438446\nEpoch [155/240] Step [600] Discriminator Loss: -0.22138744592666626 Generator Loss: -0.13653147220611572\nEpoch [155/240] Step [1200] Discriminator Loss: -0.45996904373168945 Generator Loss: -0.5327602624893188\nEpoch [155/240] Step [1800] Discriminator Loss: -0.5352077484130859 Generator Loss: -0.1719825267791748\nEpoch [155/240] Step [2400] Discriminator Loss: -0.4331687390804291 Generator Loss: -0.21455027163028717\nEpoch [155/240] Step [3000] Discriminator Loss: -0.6459685564041138 Generator Loss: -0.1319616734981537\nEpoch [155/240] Step [3600] Discriminator Loss: -0.42968496680259705 Generator Loss: -0.2383602261543274\nEpoch [155/240] Step [4200] Discriminator Loss: -0.6469710469245911 Generator Loss: -0.2509510815143585\nEpoch [155/240] Step [4800] Discriminator Loss: 0.004622258245944977 Generator Loss: -0.6486125588417053\nEpoch [155/240] Step [5400] Discriminator Loss: -0.328856885433197 Generator Loss: -0.24901796877384186\nEpoch [155/240] Step [6000] Discriminator Loss: -0.3475687503814697 Generator Loss: -0.17946216464042664\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  65%|██████▌   | 156/240 [1:40:14<54:01, 38.59s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [155/240] Avg Discriminator Loss: -0.308322895522956 Avg Generator Loss: -0.2425412150345497\nEpoch [156/240] Step [0] Discriminator Loss: -0.5820418000221252 Generator Loss: -0.12074625492095947\nEpoch [156/240] Step [600] Discriminator Loss: -0.41612911224365234 Generator Loss: -0.32860833406448364\nEpoch [156/240] Step [1200] Discriminator Loss: -0.45700427889823914 Generator Loss: -0.29746201634407043\nEpoch [156/240] Step [1800] Discriminator Loss: 0.16166049242019653 Generator Loss: -0.5064902901649475\nEpoch [156/240] Step [2400] Discriminator Loss: -0.4635844826698303 Generator Loss: -0.07877592742443085\nEpoch [156/240] Step [3000] Discriminator Loss: -0.7938260436058044 Generator Loss: -0.1424742341041565\nEpoch [156/240] Step [3600] Discriminator Loss: -0.397066593170166 Generator Loss: -0.2274225950241089\nEpoch [156/240] Step [4200] Discriminator Loss: -0.4258181154727936 Generator Loss: -0.2791103720664978\nEpoch [156/240] Step [4800] Discriminator Loss: -0.6298658847808838 Generator Loss: -0.34027379751205444\nEpoch [156/240] Step [5400] Discriminator Loss: -0.36736512184143066 Generator Loss: -0.04252028465270996\nEpoch [156/240] Step [6000] Discriminator Loss: -0.6144974827766418 Generator Loss: -0.2733761668205261\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  65%|██████▌   | 157/240 [1:40:52<53:22, 38.59s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [156/240] Avg Discriminator Loss: -0.4186533405121429 Avg Generator Loss: -0.22883113104706773\nEpoch [157/240] Step [0] Discriminator Loss: -0.5881143808364868 Generator Loss: -0.15338601171970367\nEpoch [157/240] Step [600] Discriminator Loss: -0.7509686946868896 Generator Loss: -0.15136116743087769\nEpoch [157/240] Step [1200] Discriminator Loss: -0.8085729479789734 Generator Loss: -0.11627821624279022\nEpoch [157/240] Step [1800] Discriminator Loss: -0.8020225167274475 Generator Loss: -0.16456085443496704\nEpoch [157/240] Step [2400] Discriminator Loss: -0.6333190202713013 Generator Loss: -0.1618242710828781\nEpoch [157/240] Step [3000] Discriminator Loss: -0.713666558265686 Generator Loss: -0.11643379181623459\nEpoch [157/240] Step [3600] Discriminator Loss: -0.7099777460098267 Generator Loss: -0.08309061825275421\nEpoch [157/240] Step [4200] Discriminator Loss: -0.7652795314788818 Generator Loss: -0.20335279405117035\nEpoch [157/240] Step [4800] Discriminator Loss: -0.46900853514671326 Generator Loss: -0.22387096285820007\nEpoch [157/240] Step [5400] Discriminator Loss: -0.570798933506012 Generator Loss: -0.27546682953834534\nEpoch [157/240] Step [6000] Discriminator Loss: -0.6964255571365356 Generator Loss: -0.08262939751148224\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  66%|██████▌   | 158/240 [1:41:31<52:36, 38.49s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [157/240] Avg Discriminator Loss: -0.6388957248284266 Avg Generator Loss: -0.19366111360735946\nEpoch [158/240] Step [0] Discriminator Loss: -0.6428174376487732 Generator Loss: -0.15698255598545074\nEpoch [158/240] Step [600] Discriminator Loss: -0.7465513944625854 Generator Loss: -0.15202879905700684\nEpoch [158/240] Step [1200] Discriminator Loss: -0.6272223591804504 Generator Loss: -0.25511640310287476\nEpoch [158/240] Step [1800] Discriminator Loss: -0.3499321937561035 Generator Loss: -0.2746039927005768\nEpoch [158/240] Step [2400] Discriminator Loss: -0.2806044816970825 Generator Loss: -0.4250442087650299\nEpoch [158/240] Step [3000] Discriminator Loss: -0.37274956703186035 Generator Loss: -0.41857609152793884\nEpoch [158/240] Step [3600] Discriminator Loss: 1.0192973613739014 Generator Loss: -0.556516170501709\nEpoch [158/240] Step [4200] Discriminator Loss: 0.15225699543952942 Generator Loss: -0.3649439811706543\nEpoch [158/240] Step [4800] Discriminator Loss: -0.4564949572086334 Generator Loss: -0.24192474782466888\nEpoch [158/240] Step [5400] Discriminator Loss: -0.043900489807128906 Generator Loss: -0.2765679955482483\nEpoch [158/240] Step [6000] Discriminator Loss: -0.460507869720459 Generator Loss: -0.1912485957145691\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  66%|██████▋   | 159/240 [1:42:10<52:09, 38.63s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [158/240] Avg Discriminator Loss: -0.4283814867719626 Avg Generator Loss: -0.228236214875247\nEpoch [159/240] Step [0] Discriminator Loss: -0.5561466813087463 Generator Loss: -0.14892946183681488\nEpoch [159/240] Step [600] Discriminator Loss: -0.3779853582382202 Generator Loss: -0.3473808169364929\nEpoch [159/240] Step [1200] Discriminator Loss: -0.2686355710029602 Generator Loss: -0.2413737028837204\nEpoch [159/240] Step [1800] Discriminator Loss: -0.8266024589538574 Generator Loss: -0.0743352547287941\nEpoch [159/240] Step [2400] Discriminator Loss: -0.8091386556625366 Generator Loss: -0.0924731194972992\nEpoch [159/240] Step [3000] Discriminator Loss: -0.8214827179908752 Generator Loss: -0.1445041447877884\nEpoch [159/240] Step [3600] Discriminator Loss: -0.6814744472503662 Generator Loss: -0.1510578840970993\nEpoch [159/240] Step [4200] Discriminator Loss: -0.6775813698768616 Generator Loss: -0.21415632963180542\nEpoch [159/240] Step [4800] Discriminator Loss: -0.6383076310157776 Generator Loss: -0.2513265013694763\nEpoch [159/240] Step [5400] Discriminator Loss: -0.7631892561912537 Generator Loss: -0.12542395293712616\nEpoch [159/240] Step [6000] Discriminator Loss: -0.6798567771911621 Generator Loss: -0.18008695542812347\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  67%|██████▋   | 160/240 [1:42:49<51:38, 38.74s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [159/240] Avg Discriminator Loss: -0.6175501234692968 Avg Generator Loss: -0.1923222013172649\nEpoch [160/240] Step [0] Discriminator Loss: -0.4442438781261444 Generator Loss: -0.3205587565898895\nEpoch [160/240] Step [600] Discriminator Loss: -0.6756961941719055 Generator Loss: -0.1580839902162552\nEpoch [160/240] Step [1200] Discriminator Loss: -0.5478447675704956 Generator Loss: -0.22010855376720428\nEpoch [160/240] Step [1800] Discriminator Loss: -0.37624552845954895 Generator Loss: -0.319372296333313\nEpoch [160/240] Step [2400] Discriminator Loss: 0.4613187611103058 Generator Loss: -0.3860565423965454\nEpoch [160/240] Step [3000] Discriminator Loss: -0.8521891832351685 Generator Loss: -0.042531002312898636\nEpoch [160/240] Step [3600] Discriminator Loss: -0.5320470333099365 Generator Loss: -0.20278368890285492\nEpoch [160/240] Step [4200] Discriminator Loss: -0.7557753324508667 Generator Loss: -0.17654240131378174\nEpoch [160/240] Step [4800] Discriminator Loss: -0.7544369101524353 Generator Loss: -0.1270478516817093\nEpoch [160/240] Step [5400] Discriminator Loss: -0.7535455226898193 Generator Loss: -0.09529273211956024\nEpoch [160/240] Step [6000] Discriminator Loss: -0.7935845255851746 Generator Loss: -0.09729103744029999\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  67%|██████▋   | 161/240 [1:43:28<51:08, 38.84s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [160/240] Avg Discriminator Loss: -0.5346774386835622 Avg Generator Loss: -0.20103761520843966\nEpoch [161/240] Step [0] Discriminator Loss: -0.6059093475341797 Generator Loss: -0.2686005234718323\nEpoch [161/240] Step [600] Discriminator Loss: -0.7146487832069397 Generator Loss: -0.21484650671482086\nEpoch [161/240] Step [1200] Discriminator Loss: -0.6477700471878052 Generator Loss: -0.26803481578826904\nEpoch [161/240] Step [1800] Discriminator Loss: -0.7120890021324158 Generator Loss: -0.18579788506031036\nEpoch [161/240] Step [2400] Discriminator Loss: -0.7729941010475159 Generator Loss: -0.23821529746055603\nEpoch [161/240] Step [3000] Discriminator Loss: -0.3493848443031311 Generator Loss: -0.22239816188812256\nEpoch [161/240] Step [3600] Discriminator Loss: -0.7523790001869202 Generator Loss: -0.08427103608846664\nEpoch [161/240] Step [4200] Discriminator Loss: -0.7557162046432495 Generator Loss: -0.07430233806371689\nEpoch [161/240] Step [4800] Discriminator Loss: -0.7812512516975403 Generator Loss: -0.09536370635032654\nEpoch [161/240] Step [5400] Discriminator Loss: -0.17144697904586792 Generator Loss: -0.3477703630924225\nEpoch [161/240] Step [6000] Discriminator Loss: -0.6176490783691406 Generator Loss: -0.13798445463180542\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  68%|██████▊   | 162/240 [1:44:07<50:34, 38.90s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [161/240] Avg Discriminator Loss: -0.5114996534509536 Avg Generator Loss: -0.21164098017654576\nEpoch [162/240] Step [0] Discriminator Loss: -0.6969695687294006 Generator Loss: -0.16113942861557007\nEpoch [162/240] Step [600] Discriminator Loss: -0.6802489161491394 Generator Loss: -0.23178119957447052\nEpoch [162/240] Step [1200] Discriminator Loss: -0.6619651317596436 Generator Loss: -0.19555537402629852\nEpoch [162/240] Step [1800] Discriminator Loss: -0.6380892992019653 Generator Loss: -0.1427810788154602\nEpoch [162/240] Step [2400] Discriminator Loss: -0.749967634677887 Generator Loss: -0.20187459886074066\nEpoch [162/240] Step [3000] Discriminator Loss: -0.7861671447753906 Generator Loss: -0.11467104405164719\nEpoch [162/240] Step [3600] Discriminator Loss: -0.7160913348197937 Generator Loss: -0.1980108618736267\nEpoch [162/240] Step [4200] Discriminator Loss: -0.3700845241546631 Generator Loss: -0.5223298072814941\nEpoch [162/240] Step [4800] Discriminator Loss: -0.6568502187728882 Generator Loss: -0.21774187684059143\nEpoch [162/240] Step [5400] Discriminator Loss: -0.43945759534835815 Generator Loss: -0.16569796204566956\nEpoch [162/240] Step [6000] Discriminator Loss: -0.4605347514152527 Generator Loss: -0.04104391485452652\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  68%|██████▊   | 163/240 [1:44:45<49:51, 38.85s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [162/240] Avg Discriminator Loss: -0.5259624498012738 Avg Generator Loss: -0.20849350202255523\nEpoch [163/240] Step [0] Discriminator Loss: -0.6434552669525146 Generator Loss: -0.19282391667366028\nEpoch [163/240] Step [600] Discriminator Loss: -0.7858341932296753 Generator Loss: -0.09752260148525238\nEpoch [163/240] Step [1200] Discriminator Loss: -0.6585985422134399 Generator Loss: -0.15887130796909332\nEpoch [163/240] Step [1800] Discriminator Loss: -0.6817948818206787 Generator Loss: -0.127711683511734\nEpoch [163/240] Step [2400] Discriminator Loss: -0.8185555934906006 Generator Loss: -0.12387081235647202\nEpoch [163/240] Step [3000] Discriminator Loss: -0.7502449154853821 Generator Loss: -0.13061195611953735\nEpoch [163/240] Step [3600] Discriminator Loss: -0.6472358703613281 Generator Loss: -0.22125166654586792\nEpoch [163/240] Step [4200] Discriminator Loss: -0.15226459503173828 Generator Loss: -0.3507247269153595\nEpoch [163/240] Step [4800] Discriminator Loss: -0.5489592552185059 Generator Loss: -0.2148003727197647\nEpoch [163/240] Step [5400] Discriminator Loss: -0.7101617455482483 Generator Loss: -0.19303758442401886\nEpoch [163/240] Step [6000] Discriminator Loss: 0.09140822291374207 Generator Loss: -0.6751052141189575\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  68%|██████▊   | 164/240 [1:45:24<49:11, 38.84s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [163/240] Avg Discriminator Loss: -0.44746373621098723 Avg Generator Loss: -0.254474915905204\nEpoch [164/240] Step [0] Discriminator Loss: 0.40180420875549316 Generator Loss: -0.9847174882888794\nEpoch [164/240] Step [600] Discriminator Loss: 0.41687992215156555 Generator Loss: -0.9223833680152893\nEpoch [164/240] Step [1200] Discriminator Loss: -0.051045261323451996 Generator Loss: -0.31422850489616394\nEpoch [164/240] Step [1800] Discriminator Loss: -0.2844909727573395 Generator Loss: -0.16089406609535217\nEpoch [164/240] Step [2400] Discriminator Loss: -0.515636682510376 Generator Loss: -0.18515995144844055\nEpoch [164/240] Step [3000] Discriminator Loss: -0.7734556794166565 Generator Loss: -0.20429405570030212\nEpoch [164/240] Step [3600] Discriminator Loss: -0.6870003342628479 Generator Loss: -0.21042729914188385\nEpoch [164/240] Step [4200] Discriminator Loss: -0.5880115032196045 Generator Loss: -0.21677382290363312\nEpoch [164/240] Step [4800] Discriminator Loss: -0.5590122938156128 Generator Loss: -0.16078364849090576\nEpoch [164/240] Step [5400] Discriminator Loss: -0.7461369633674622 Generator Loss: -0.1762743443250656\nEpoch [164/240] Step [6000] Discriminator Loss: -0.7076730132102966 Generator Loss: -0.20090502500534058\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  69%|██████▉   | 165/240 [1:46:03<48:35, 38.87s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [164/240] Avg Discriminator Loss: -0.3104911038563365 Avg Generator Loss: -0.3150555155898407\nEpoch [165/240] Step [0] Discriminator Loss: -0.7763715386390686 Generator Loss: -0.09855344891548157\nEpoch [165/240] Step [600] Discriminator Loss: 0.15479715168476105 Generator Loss: -0.19293315708637238\nEpoch [165/240] Step [1200] Discriminator Loss: 0.11581755429506302 Generator Loss: -0.39376401901245117\nEpoch [165/240] Step [1800] Discriminator Loss: -0.325072318315506 Generator Loss: -0.32421860098838806\nEpoch [165/240] Step [2400] Discriminator Loss: -0.40404587984085083 Generator Loss: -0.16086062788963318\nEpoch [165/240] Step [3000] Discriminator Loss: -0.6646968722343445 Generator Loss: -0.15807396173477173\nEpoch [165/240] Step [3600] Discriminator Loss: -0.1842505782842636 Generator Loss: -0.25994378328323364\nEpoch [165/240] Step [4200] Discriminator Loss: -0.42041754722595215 Generator Loss: -0.1537552773952484\nEpoch [165/240] Step [4800] Discriminator Loss: -0.4640628695487976 Generator Loss: -0.2853507995605469\nEpoch [165/240] Step [5400] Discriminator Loss: -0.6084945797920227 Generator Loss: -0.17072288691997528\nEpoch [165/240] Step [6000] Discriminator Loss: -0.2798321545124054 Generator Loss: -0.10848726332187653\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  69%|██████▉   | 166/240 [1:46:42<48:00, 38.93s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [165/240] Avg Discriminator Loss: -0.2205296649355373 Avg Generator Loss: -0.2658935733405607\nEpoch [166/240] Step [0] Discriminator Loss: 0.02457539737224579 Generator Loss: -0.5884222984313965\nEpoch [166/240] Step [600] Discriminator Loss: -0.777982771396637 Generator Loss: -0.043107517063617706\nEpoch [166/240] Step [1200] Discriminator Loss: -0.11735464632511139 Generator Loss: -0.2637360990047455\nEpoch [166/240] Step [1800] Discriminator Loss: -0.1744694709777832 Generator Loss: -0.32236552238464355\nEpoch [166/240] Step [2400] Discriminator Loss: -0.3146008849143982 Generator Loss: -0.5294392108917236\nEpoch [166/240] Step [3000] Discriminator Loss: -0.5679834485054016 Generator Loss: -0.15720735490322113\nEpoch [166/240] Step [3600] Discriminator Loss: -0.15173619985580444 Generator Loss: -0.22195720672607422\nEpoch [166/240] Step [4200] Discriminator Loss: -0.3225640654563904 Generator Loss: -0.3114316761493683\nEpoch [166/240] Step [4800] Discriminator Loss: -0.8105223178863525 Generator Loss: -0.09288797527551651\nEpoch [166/240] Step [5400] Discriminator Loss: -0.7486681938171387 Generator Loss: -0.17841924726963043\nEpoch [166/240] Step [6000] Discriminator Loss: -0.5705904960632324 Generator Loss: -0.25494277477264404\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  70%|██████▉   | 167/240 [1:47:21<47:18, 38.88s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [166/240] Avg Discriminator Loss: -0.45655685492651366 Avg Generator Loss: -0.21618178603921645\nEpoch [167/240] Step [0] Discriminator Loss: -0.7458631992340088 Generator Loss: -0.1746646761894226\nEpoch [167/240] Step [600] Discriminator Loss: -0.6192947030067444 Generator Loss: -0.2437220811843872\nEpoch [167/240] Step [1200] Discriminator Loss: -0.732411801815033 Generator Loss: -0.16798174381256104\nEpoch [167/240] Step [1800] Discriminator Loss: -0.6663441061973572 Generator Loss: -0.1819629967212677\nEpoch [167/240] Step [2400] Discriminator Loss: -0.0026288628578186035 Generator Loss: -0.21490488946437836\nEpoch [167/240] Step [3000] Discriminator Loss: -0.7997049689292908 Generator Loss: -0.05224547162652016\nEpoch [167/240] Step [3600] Discriminator Loss: -0.6522492170333862 Generator Loss: -0.10802831500768661\nEpoch [167/240] Step [4200] Discriminator Loss: -0.6366153955459595 Generator Loss: -0.19957318902015686\nEpoch [167/240] Step [4800] Discriminator Loss: -0.640182614326477 Generator Loss: -0.25086483359336853\nEpoch [167/240] Step [5400] Discriminator Loss: -0.40907102823257446 Generator Loss: -0.12250988185405731\nEpoch [167/240] Step [6000] Discriminator Loss: -0.25228846073150635 Generator Loss: -0.34762340784072876\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  70%|███████   | 168/240 [1:48:00<46:39, 38.88s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [167/240] Avg Discriminator Loss: -0.5244996168347069 Avg Generator Loss: -0.24448952283505554\nEpoch [168/240] Step [0] Discriminator Loss: 0.21212410926818848 Generator Loss: -0.9229046702384949\nEpoch [168/240] Step [600] Discriminator Loss: -0.3568563759326935 Generator Loss: -0.1640341579914093\nEpoch [168/240] Step [1200] Discriminator Loss: -0.0873481035232544 Generator Loss: -0.5476473569869995\nEpoch [168/240] Step [1800] Discriminator Loss: -0.6695851683616638 Generator Loss: -0.0017452379688620567\nEpoch [168/240] Step [2400] Discriminator Loss: -0.624126672744751 Generator Loss: -0.2477666288614273\nEpoch [168/240] Step [3000] Discriminator Loss: -0.7334911227226257 Generator Loss: -0.16549818217754364\nEpoch [168/240] Step [3600] Discriminator Loss: -0.5993102192878723 Generator Loss: -0.29263365268707275\nEpoch [168/240] Step [4200] Discriminator Loss: -0.6507649421691895 Generator Loss: -0.07121087610721588\nEpoch [168/240] Step [4800] Discriminator Loss: -0.5943998098373413 Generator Loss: -0.2630072236061096\nEpoch [168/240] Step [5400] Discriminator Loss: -0.724900484085083 Generator Loss: -0.17224499583244324\nEpoch [168/240] Step [6000] Discriminator Loss: -0.6579745411872864 Generator Loss: -0.20375032722949982\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  70%|███████   | 169/240 [1:48:39<46:01, 38.90s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [168/240] Avg Discriminator Loss: -0.5618763574477517 Avg Generator Loss: -0.21129129583787024\nEpoch [169/240] Step [0] Discriminator Loss: -0.2899869680404663 Generator Loss: -0.2989693284034729\nEpoch [169/240] Step [600] Discriminator Loss: -0.5741035342216492 Generator Loss: -0.23794203996658325\nEpoch [169/240] Step [1200] Discriminator Loss: -0.6175597310066223 Generator Loss: -0.22282826900482178\nEpoch [169/240] Step [1800] Discriminator Loss: -0.7007395625114441 Generator Loss: -0.22472624480724335\nEpoch [169/240] Step [2400] Discriminator Loss: -0.671992838382721 Generator Loss: -0.2661115229129791\nEpoch [169/240] Step [3000] Discriminator Loss: -0.6757211685180664 Generator Loss: -0.20051603019237518\nEpoch [169/240] Step [3600] Discriminator Loss: -0.5818995833396912 Generator Loss: -0.18970759212970734\nEpoch [169/240] Step [4200] Discriminator Loss: -0.7101920247077942 Generator Loss: -0.13723266124725342\nEpoch [169/240] Step [4800] Discriminator Loss: -0.5861765146255493 Generator Loss: -0.2720524072647095\nEpoch [169/240] Step [5400] Discriminator Loss: -0.5459625720977783 Generator Loss: -0.2535388171672821\nEpoch [169/240] Step [6000] Discriminator Loss: -0.3998706042766571 Generator Loss: -0.33433541655540466\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  71%|███████   | 170/240 [1:49:18<45:25, 38.93s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [169/240] Avg Discriminator Loss: -0.5585949269188193 Avg Generator Loss: -0.23354244599248464\nEpoch [170/240] Step [0] Discriminator Loss: -0.6075511574745178 Generator Loss: -0.17682605981826782\nEpoch [170/240] Step [600] Discriminator Loss: -0.6067132949829102 Generator Loss: -0.14254270493984222\nEpoch [170/240] Step [1200] Discriminator Loss: -0.547097384929657 Generator Loss: -0.2071320116519928\nEpoch [170/240] Step [1800] Discriminator Loss: -0.14198458194732666 Generator Loss: -0.2394433468580246\nEpoch [170/240] Step [2400] Discriminator Loss: -0.7506768107414246 Generator Loss: -0.09532295167446136\nEpoch [170/240] Step [3000] Discriminator Loss: -0.6718977093696594 Generator Loss: -0.09646650403738022\nEpoch [170/240] Step [3600] Discriminator Loss: -0.6409346461296082 Generator Loss: -0.1669105440378189\nEpoch [170/240] Step [4200] Discriminator Loss: -0.5792620182037354 Generator Loss: -0.15904831886291504\nEpoch [170/240] Step [4800] Discriminator Loss: -0.5349231958389282 Generator Loss: -0.29752519726753235\nEpoch [170/240] Step [5400] Discriminator Loss: -0.5272291898727417 Generator Loss: -0.27256080508232117\nEpoch [170/240] Step [6000] Discriminator Loss: -0.4249727725982666 Generator Loss: -0.28345537185668945\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  71%|███████▏  | 171/240 [1:49:57<44:50, 38.99s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [170/240] Avg Discriminator Loss: -0.5295973727991293 Avg Generator Loss: -0.20980956154319394\nEpoch [171/240] Step [0] Discriminator Loss: -0.4626948833465576 Generator Loss: -0.2956121265888214\nEpoch [171/240] Step [600] Discriminator Loss: -0.6700483560562134 Generator Loss: -0.022727929055690765\nEpoch [171/240] Step [1200] Discriminator Loss: -0.638985276222229 Generator Loss: -0.1926533579826355\nEpoch [171/240] Step [1800] Discriminator Loss: -0.6120911836624146 Generator Loss: -0.11930526793003082\nEpoch [171/240] Step [2400] Discriminator Loss: -0.21197324991226196 Generator Loss: -0.20791500806808472\nEpoch [171/240] Step [3000] Discriminator Loss: 0.22028344869613647 Generator Loss: -0.40592798590660095\nEpoch [171/240] Step [3600] Discriminator Loss: -0.7532956600189209 Generator Loss: -0.0825708657503128\nEpoch [171/240] Step [4200] Discriminator Loss: -0.5460397005081177 Generator Loss: -0.06564939022064209\nEpoch [171/240] Step [4800] Discriminator Loss: -0.07042032480239868 Generator Loss: -0.10280223190784454\nEpoch [171/240] Step [5400] Discriminator Loss: -0.6013543009757996 Generator Loss: -0.2484831064939499\nEpoch [171/240] Step [6000] Discriminator Loss: -0.6139872670173645 Generator Loss: -0.20710578560829163\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  72%|███████▏  | 172/240 [1:50:36<44:09, 38.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [171/240] Avg Discriminator Loss: -0.5262261517209448 Avg Generator Loss: -0.1685158959538727\nEpoch [172/240] Step [0] Discriminator Loss: -0.3921750783920288 Generator Loss: -0.18484073877334595\nEpoch [172/240] Step [600] Discriminator Loss: -0.7539905309677124 Generator Loss: -0.014702826738357544\nEpoch [172/240] Step [1200] Discriminator Loss: -0.773726224899292 Generator Loss: -0.0602346770465374\nEpoch [172/240] Step [1800] Discriminator Loss: -0.7808736562728882 Generator Loss: -0.023253843188285828\nEpoch [172/240] Step [2400] Discriminator Loss: -0.46285927295684814 Generator Loss: 0.008688723668456078\nEpoch [172/240] Step [3000] Discriminator Loss: -0.7547768950462341 Generator Loss: -0.10893797874450684\nEpoch [172/240] Step [3600] Discriminator Loss: -0.5711057186126709 Generator Loss: -0.14156141877174377\nEpoch [172/240] Step [4200] Discriminator Loss: -0.41721171140670776 Generator Loss: -0.14816637337207794\nEpoch [172/240] Step [4800] Discriminator Loss: -0.6473028659820557 Generator Loss: -0.2041977196931839\nEpoch [172/240] Step [5400] Discriminator Loss: -0.6156134009361267 Generator Loss: -0.21336999535560608\nEpoch [172/240] Step [6000] Discriminator Loss: -0.6908040046691895 Generator Loss: -0.1947651505470276\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  72%|███████▏  | 173/240 [1:51:15<43:29, 38.94s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [172/240] Avg Discriminator Loss: -0.5691650487455256 Avg Generator Loss: -0.15749910840894277\nEpoch [173/240] Step [0] Discriminator Loss: -0.7060745358467102 Generator Loss: -0.17734374105930328\nEpoch [173/240] Step [600] Discriminator Loss: -0.7621463537216187 Generator Loss: -0.09088226407766342\nEpoch [173/240] Step [1200] Discriminator Loss: -0.6747003793716431 Generator Loss: -0.07484883069992065\nEpoch [173/240] Step [1800] Discriminator Loss: -0.7084258794784546 Generator Loss: -0.11569352447986603\nEpoch [173/240] Step [2400] Discriminator Loss: -0.6050202250480652 Generator Loss: -0.121919646859169\nEpoch [173/240] Step [3000] Discriminator Loss: -0.5946796536445618 Generator Loss: -0.20534899830818176\nEpoch [173/240] Step [3600] Discriminator Loss: -0.03546521067619324 Generator Loss: -0.5517160296440125\nEpoch [173/240] Step [4200] Discriminator Loss: -0.5353765487670898 Generator Loss: -0.17127777636051178\nEpoch [173/240] Step [4800] Discriminator Loss: -0.5559313297271729 Generator Loss: -0.22935467958450317\nEpoch [173/240] Step [5400] Discriminator Loss: -0.5541545748710632 Generator Loss: -0.21226106584072113\nEpoch [173/240] Step [6000] Discriminator Loss: -0.7442598342895508 Generator Loss: -0.09238214790821075\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  72%|███████▎  | 174/240 [1:51:54<42:49, 38.93s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [173/240] Avg Discriminator Loss: -0.5148548238770866 Avg Generator Loss: -0.21611136049305127\nEpoch [174/240] Step [0] Discriminator Loss: -0.5935770273208618 Generator Loss: -0.14996616542339325\nEpoch [174/240] Step [600] Discriminator Loss: -0.702355146408081 Generator Loss: -0.09370210766792297\nEpoch [174/240] Step [1200] Discriminator Loss: -0.6764870882034302 Generator Loss: -0.06522838026285172\nEpoch [174/240] Step [1800] Discriminator Loss: -0.04872739315032959 Generator Loss: -0.28727659583091736\nEpoch [174/240] Step [2400] Discriminator Loss: -0.5065104961395264 Generator Loss: -0.12389346957206726\nEpoch [174/240] Step [3000] Discriminator Loss: -0.3801274597644806 Generator Loss: -0.3671617805957794\nEpoch [174/240] Step [3600] Discriminator Loss: -0.6191362142562866 Generator Loss: -0.2076103836297989\nEpoch [174/240] Step [4200] Discriminator Loss: -0.46503400802612305 Generator Loss: -0.25713831186294556\nEpoch [174/240] Step [4800] Discriminator Loss: -0.6865984201431274 Generator Loss: -0.11467063426971436\nEpoch [174/240] Step [5400] Discriminator Loss: -0.68443763256073 Generator Loss: -0.08987195789813995\nEpoch [174/240] Step [6000] Discriminator Loss: -0.4266042709350586 Generator Loss: -0.18031752109527588\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  73%|███████▎  | 175/240 [1:52:33<42:08, 38.90s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [174/240] Avg Discriminator Loss: -0.5131643868900917 Avg Generator Loss: -0.20336280596671086\nEpoch [175/240] Step [0] Discriminator Loss: -0.3584888279438019 Generator Loss: -0.32639363408088684\nEpoch [175/240] Step [600] Discriminator Loss: -0.8034136891365051 Generator Loss: -0.09525130689144135\nEpoch [175/240] Step [1200] Discriminator Loss: -0.34876418113708496 Generator Loss: -0.280440092086792\nEpoch [175/240] Step [1800] Discriminator Loss: -0.7051262855529785 Generator Loss: -0.0471930056810379\nEpoch [175/240] Step [2400] Discriminator Loss: -0.4816048741340637 Generator Loss: -0.19464902579784393\nEpoch [175/240] Step [3000] Discriminator Loss: -0.7160655856132507 Generator Loss: -0.12435972690582275\nEpoch [175/240] Step [3600] Discriminator Loss: -0.06138718128204346 Generator Loss: -0.5249301791191101\nEpoch [175/240] Step [4200] Discriminator Loss: -0.6385402083396912 Generator Loss: -0.17098309099674225\nEpoch [175/240] Step [4800] Discriminator Loss: -0.7899287343025208 Generator Loss: -0.07888959348201752\nEpoch [175/240] Step [5400] Discriminator Loss: -0.4400913119316101 Generator Loss: -0.23698124289512634\nEpoch [175/240] Step [6000] Discriminator Loss: -0.6299426555633545 Generator Loss: -0.1350817084312439\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  73%|███████▎  | 176/240 [1:53:11<41:28, 38.88s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [175/240] Avg Discriminator Loss: -0.49514792409244474 Avg Generator Loss: -0.19091234964083184\nEpoch [176/240] Step [0] Discriminator Loss: -0.643072247505188 Generator Loss: -0.14119894802570343\nEpoch [176/240] Step [600] Discriminator Loss: -0.5440056324005127 Generator Loss: -0.19056853652000427\nEpoch [176/240] Step [1200] Discriminator Loss: -0.5791587829589844 Generator Loss: -0.22435003519058228\nEpoch [176/240] Step [1800] Discriminator Loss: -0.339816153049469 Generator Loss: -0.1663663387298584\nEpoch [176/240] Step [2400] Discriminator Loss: -0.7215566635131836 Generator Loss: -0.11917489767074585\nEpoch [176/240] Step [3000] Discriminator Loss: -0.6469776034355164 Generator Loss: -0.14072054624557495\nEpoch [176/240] Step [3600] Discriminator Loss: -0.4631633758544922 Generator Loss: -0.25496095418930054\nEpoch [176/240] Step [4200] Discriminator Loss: -0.6357895731925964 Generator Loss: -0.05433911085128784\nEpoch [176/240] Step [4800] Discriminator Loss: -0.6025187373161316 Generator Loss: -0.08867725729942322\nEpoch [176/240] Step [5400] Discriminator Loss: -0.0765487551689148 Generator Loss: -0.39674046635627747\nEpoch [176/240] Step [6000] Discriminator Loss: -0.5510275363922119 Generator Loss: -0.18181806802749634\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  74%|███████▍  | 177/240 [1:53:50<40:52, 38.93s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [176/240] Avg Discriminator Loss: -0.39680232521105596 Avg Generator Loss: -0.2041435364988588\nEpoch [177/240] Step [0] Discriminator Loss: -0.7729876637458801 Generator Loss: 0.0133013054728508\nEpoch [177/240] Step [600] Discriminator Loss: -0.7524975538253784 Generator Loss: -0.005037412047386169\nEpoch [177/240] Step [1200] Discriminator Loss: -0.7441846132278442 Generator Loss: -0.15668918192386627\nEpoch [177/240] Step [1800] Discriminator Loss: -0.584392249584198 Generator Loss: -0.3288702368736267\nEpoch [177/240] Step [2400] Discriminator Loss: -0.6863718032836914 Generator Loss: -0.04314383119344711\nEpoch [177/240] Step [3000] Discriminator Loss: -0.7006635069847107 Generator Loss: -0.10198827087879181\nEpoch [177/240] Step [3600] Discriminator Loss: 0.8873833417892456 Generator Loss: -0.504408061504364\nEpoch [177/240] Step [4200] Discriminator Loss: -0.45308566093444824 Generator Loss: -0.010251209139823914\nEpoch [177/240] Step [4800] Discriminator Loss: -0.6258800625801086 Generator Loss: -0.009299322962760925\nEpoch [177/240] Step [5400] Discriminator Loss: -0.6086879968643188 Generator Loss: -0.16408023238182068\nEpoch [177/240] Step [6000] Discriminator Loss: -0.540937066078186 Generator Loss: -0.180633082985878\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  74%|███████▍  | 178/240 [1:54:29<40:14, 38.94s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [177/240] Avg Discriminator Loss: -0.4892122208417117 Avg Generator Loss: -0.16487840270357473\nEpoch [178/240] Step [0] Discriminator Loss: 1.5989961624145508 Generator Loss: -0.49652233719825745\nEpoch [178/240] Step [600] Discriminator Loss: -0.6655193567276001 Generator Loss: -0.13473127782344818\nEpoch [178/240] Step [1200] Discriminator Loss: -0.7398917078971863 Generator Loss: -0.05988398566842079\nEpoch [178/240] Step [1800] Discriminator Loss: -0.5584438443183899 Generator Loss: -0.24190561473369598\nEpoch [178/240] Step [2400] Discriminator Loss: -0.7024502754211426 Generator Loss: -0.18149609863758087\nEpoch [178/240] Step [3000] Discriminator Loss: -0.800855278968811 Generator Loss: -0.06663300842046738\nEpoch [178/240] Step [3600] Discriminator Loss: -0.41032975912094116 Generator Loss: -0.15276122093200684\nEpoch [178/240] Step [4200] Discriminator Loss: -0.5171571969985962 Generator Loss: 0.024594658985733986\nEpoch [178/240] Step [4800] Discriminator Loss: 0.5192084312438965 Generator Loss: -0.6432880163192749\nEpoch [178/240] Step [5400] Discriminator Loss: 0.42777377367019653 Generator Loss: -0.8655737638473511\nEpoch [178/240] Step [6000] Discriminator Loss: -0.5980899333953857 Generator Loss: 0.030222121626138687\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  75%|███████▍  | 179/240 [1:55:08<39:36, 38.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [178/240] Avg Discriminator Loss: -0.3874514402050675 Avg Generator Loss: -0.2372987244018923\nEpoch [179/240] Step [0] Discriminator Loss: -0.0034500956535339355 Generator Loss: 0.024745967239141464\nEpoch [179/240] Step [600] Discriminator Loss: -0.7369953393936157 Generator Loss: -0.05609540641307831\nEpoch [179/240] Step [1200] Discriminator Loss: -0.8367810845375061 Generator Loss: -0.026818454265594482\nEpoch [179/240] Step [1800] Discriminator Loss: -0.7006919980049133 Generator Loss: -0.040357887744903564\nEpoch [179/240] Step [2400] Discriminator Loss: -0.8661807775497437 Generator Loss: -0.03443419188261032\nEpoch [179/240] Step [3000] Discriminator Loss: -0.7925910353660583 Generator Loss: 0.000260399654507637\nEpoch [179/240] Step [3600] Discriminator Loss: -0.7339536547660828 Generator Loss: -0.12581242620944977\nEpoch [179/240] Step [4200] Discriminator Loss: -0.7297238707542419 Generator Loss: -0.038819022476673126\nEpoch [179/240] Step [4800] Discriminator Loss: -0.7027337551116943 Generator Loss: -0.1362506002187729\nEpoch [179/240] Step [5400] Discriminator Loss: -0.651150643825531 Generator Loss: -0.270534873008728\nEpoch [179/240] Step [6000] Discriminator Loss: -0.4686749577522278 Generator Loss: -0.13184621930122375\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  75%|███████▌  | 180/240 [1:55:48<39:01, 39.03s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [179/240] Avg Discriminator Loss: -0.5966918967909866 Avg Generator Loss: -0.13305538836116101\nEpoch [180/240] Step [0] Discriminator Loss: -0.7581177949905396 Generator Loss: -0.09737803041934967\nEpoch [180/240] Step [600] Discriminator Loss: -0.5198525190353394 Generator Loss: -0.13837891817092896\nEpoch [180/240] Step [1200] Discriminator Loss: -0.6821499466896057 Generator Loss: -0.12241244316101074\nEpoch [180/240] Step [1800] Discriminator Loss: -0.7685312032699585 Generator Loss: -0.08551318943500519\nEpoch [180/240] Step [2400] Discriminator Loss: -0.740794837474823 Generator Loss: -0.09660237282514572\nEpoch [180/240] Step [3000] Discriminator Loss: -0.4777545630931854 Generator Loss: -0.1543160378932953\nEpoch [180/240] Step [3600] Discriminator Loss: -0.6907010674476624 Generator Loss: -0.05340531840920448\nEpoch [180/240] Step [4200] Discriminator Loss: -0.7277569770812988 Generator Loss: -0.13027605414390564\nEpoch [180/240] Step [4800] Discriminator Loss: -0.7118503451347351 Generator Loss: -0.12365000694990158\nEpoch [180/240] Step [5400] Discriminator Loss: -0.47356870770454407 Generator Loss: -0.33425241708755493\nEpoch [180/240] Step [6000] Discriminator Loss: -0.4057239890098572 Generator Loss: -0.24156975746154785\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  75%|███████▌  | 181/240 [1:56:27<38:24, 39.06s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [180/240] Avg Discriminator Loss: -0.5486227443694195 Avg Generator Loss: -0.17305740217367807\nEpoch [181/240] Step [0] Discriminator Loss: -0.7014449238777161 Generator Loss: -0.13380306959152222\nEpoch [181/240] Step [600] Discriminator Loss: 0.18370550870895386 Generator Loss: -0.7260538935661316\nEpoch [181/240] Step [1200] Discriminator Loss: -0.6062626242637634 Generator Loss: -0.00812026858329773\nEpoch [181/240] Step [1800] Discriminator Loss: -0.7208147644996643 Generator Loss: -0.06586097180843353\nEpoch [181/240] Step [2400] Discriminator Loss: 0.0039459168910980225 Generator Loss: -0.08415979146957397\nEpoch [181/240] Step [3000] Discriminator Loss: -0.7357302904129028 Generator Loss: -0.05256964638829231\nEpoch [181/240] Step [3600] Discriminator Loss: -0.16886252164840698 Generator Loss: -0.3877595365047455\nEpoch [181/240] Step [4200] Discriminator Loss: 0.7357063293457031 Generator Loss: -0.019821636378765106\nEpoch [181/240] Step [4800] Discriminator Loss: -0.5289497375488281 Generator Loss: -0.20073910057544708\nEpoch [181/240] Step [5400] Discriminator Loss: 0.030994892120361328 Generator Loss: -0.3592433035373688\nEpoch [181/240] Step [6000] Discriminator Loss: -0.501408040523529 Generator Loss: -0.18338130414485931\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  76%|███████▌  | 182/240 [1:57:06<37:44, 39.04s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [181/240] Avg Discriminator Loss: -0.40902527723283993 Avg Generator Loss: -0.21793383647834424\nEpoch [182/240] Step [0] Discriminator Loss: -0.6148147583007812 Generator Loss: -0.1740766167640686\nEpoch [182/240] Step [600] Discriminator Loss: -0.5601276159286499 Generator Loss: -0.19563820958137512\nEpoch [182/240] Step [1200] Discriminator Loss: -0.47496145963668823 Generator Loss: -0.1957109272480011\nEpoch [182/240] Step [1800] Discriminator Loss: -0.7700440287590027 Generator Loss: -0.08815119415521622\nEpoch [182/240] Step [2400] Discriminator Loss: -0.5069457292556763 Generator Loss: -0.15910422801971436\nEpoch [182/240] Step [3000] Discriminator Loss: -0.746697187423706 Generator Loss: -0.07126817852258682\nEpoch [182/240] Step [3600] Discriminator Loss: -0.6800491213798523 Generator Loss: -0.13607922196388245\nEpoch [182/240] Step [4200] Discriminator Loss: -0.7606135606765747 Generator Loss: -0.052230171859264374\nEpoch [182/240] Step [4800] Discriminator Loss: 0.5240448713302612 Generator Loss: -0.19459715485572815\nEpoch [182/240] Step [5400] Discriminator Loss: -0.34646421670913696 Generator Loss: -0.44103363156318665\nEpoch [182/240] Step [6000] Discriminator Loss: -0.4622957408428192 Generator Loss: -0.16558243334293365\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  76%|███████▋  | 183/240 [1:57:45<37:04, 39.02s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [182/240] Avg Discriminator Loss: -0.40203365506160826 Avg Generator Loss: -0.204763368836471\nEpoch [183/240] Step [0] Discriminator Loss: -0.7038552761077881 Generator Loss: -0.06850521266460419\nEpoch [183/240] Step [600] Discriminator Loss: -0.4082104563713074 Generator Loss: -0.1268230378627777\nEpoch [183/240] Step [1200] Discriminator Loss: 0.15661698579788208 Generator Loss: -0.5492358207702637\nEpoch [183/240] Step [1800] Discriminator Loss: -0.3587331473827362 Generator Loss: -0.2522130012512207\nEpoch [183/240] Step [2400] Discriminator Loss: -0.42990559339523315 Generator Loss: -0.21576008200645447\nEpoch [183/240] Step [3000] Discriminator Loss: -0.7467488050460815 Generator Loss: -0.20204678177833557\nEpoch [183/240] Step [3600] Discriminator Loss: 0.4840853214263916 Generator Loss: -0.6043397188186646\nEpoch [183/240] Step [4200] Discriminator Loss: -0.6991385817527771 Generator Loss: -0.0903518795967102\nEpoch [183/240] Step [4800] Discriminator Loss: -0.3211277723312378 Generator Loss: -0.22134771943092346\nEpoch [183/240] Step [5400] Discriminator Loss: -0.7236147522926331 Generator Loss: -0.14656201004981995\nEpoch [183/240] Step [6000] Discriminator Loss: -0.35422971844673157 Generator Loss: -0.10652761906385422\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  77%|███████▋  | 184/240 [1:58:24<36:24, 39.01s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [183/240] Avg Discriminator Loss: -0.4760929008215775 Avg Generator Loss: -0.19949534622740833\nEpoch [184/240] Step [0] Discriminator Loss: -0.7942356467247009 Generator Loss: -0.04513692110776901\nEpoch [184/240] Step [600] Discriminator Loss: -0.7455834746360779 Generator Loss: -0.1576663851737976\nEpoch [184/240] Step [1200] Discriminator Loss: -0.7596172094345093 Generator Loss: -0.07075368613004684\nEpoch [184/240] Step [1800] Discriminator Loss: -0.7473033666610718 Generator Loss: -0.10261138528585434\nEpoch [184/240] Step [2400] Discriminator Loss: -0.6221370697021484 Generator Loss: -0.16746221482753754\nEpoch [184/240] Step [3000] Discriminator Loss: -0.7749382853507996 Generator Loss: -0.013002213090658188\nEpoch [184/240] Step [3600] Discriminator Loss: -0.7554054260253906 Generator Loss: -0.06664679199457169\nEpoch [184/240] Step [4200] Discriminator Loss: -0.585762619972229 Generator Loss: -0.2614477276802063\nEpoch [184/240] Step [4800] Discriminator Loss: -0.8424615263938904 Generator Loss: 0.011503348127007484\nEpoch [184/240] Step [5400] Discriminator Loss: -0.46523553133010864 Generator Loss: -0.11635349690914154\nEpoch [184/240] Step [6000] Discriminator Loss: -0.7015842795372009 Generator Loss: -0.08892680704593658\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  77%|███████▋  | 185/240 [1:59:03<35:45, 39.00s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [184/240] Avg Discriminator Loss: -0.5816869387478182 Avg Generator Loss: -0.16076394208048508\nEpoch [185/240] Step [0] Discriminator Loss: -0.6282880306243896 Generator Loss: -0.1331469565629959\nEpoch [185/240] Step [600] Discriminator Loss: -0.7669286131858826 Generator Loss: -0.10914470255374908\nEpoch [185/240] Step [1200] Discriminator Loss: -0.4579973518848419 Generator Loss: -0.28291428089141846\nEpoch [185/240] Step [1800] Discriminator Loss: -0.5472704768180847 Generator Loss: -0.0734909176826477\nEpoch [185/240] Step [2400] Discriminator Loss: -0.07327556610107422 Generator Loss: -0.42018502950668335\nEpoch [185/240] Step [3000] Discriminator Loss: -0.10305222868919373 Generator Loss: -0.6578465700149536\nEpoch [185/240] Step [3600] Discriminator Loss: -0.7711406350135803 Generator Loss: -0.06270954757928848\nEpoch [185/240] Step [4200] Discriminator Loss: -0.6437421441078186 Generator Loss: -0.17654594779014587\nEpoch [185/240] Step [4800] Discriminator Loss: -0.7032527923583984 Generator Loss: -0.05039793998003006\nEpoch [185/240] Step [5400] Discriminator Loss: -0.5224279761314392 Generator Loss: -0.17080450057983398\nEpoch [185/240] Step [6000] Discriminator Loss: -0.6983295679092407 Generator Loss: -0.1598651111125946\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  78%|███████▊  | 186/240 [1:59:42<35:04, 38.98s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [185/240] Avg Discriminator Loss: -0.524066224858001 Avg Generator Loss: -0.19718404870903317\nEpoch [186/240] Step [0] Discriminator Loss: -0.48723170161247253 Generator Loss: -0.5147817134857178\nEpoch [186/240] Step [600] Discriminator Loss: -0.7462303042411804 Generator Loss: -0.12103582173585892\nEpoch [186/240] Step [1200] Discriminator Loss: -0.4867251515388489 Generator Loss: -0.3267157971858978\nEpoch [186/240] Step [1800] Discriminator Loss: -0.6705579161643982 Generator Loss: -0.1103328987956047\nEpoch [186/240] Step [2400] Discriminator Loss: -0.768815279006958 Generator Loss: -0.04582037776708603\nEpoch [186/240] Step [3000] Discriminator Loss: -0.7495754361152649 Generator Loss: -0.06432206928730011\nEpoch [186/240] Step [3600] Discriminator Loss: -0.6733997464179993 Generator Loss: -0.1410106122493744\nEpoch [186/240] Step [4200] Discriminator Loss: -0.6700626611709595 Generator Loss: -0.1715887188911438\nEpoch [186/240] Step [4800] Discriminator Loss: -0.561777651309967 Generator Loss: -0.15128783881664276\nEpoch [186/240] Step [5400] Discriminator Loss: -0.7045128345489502 Generator Loss: -0.07046432793140411\nEpoch [186/240] Step [6000] Discriminator Loss: -0.5963131785392761 Generator Loss: -0.23605689406394958\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  78%|███████▊  | 187/240 [2:00:21<34:29, 39.05s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [186/240] Avg Discriminator Loss: -0.44423125291263665 Avg Generator Loss: -0.20483806152101403\nEpoch [187/240] Step [0] Discriminator Loss: 0.37677818536758423 Generator Loss: -0.2069014608860016\nEpoch [187/240] Step [600] Discriminator Loss: -0.4418344497680664 Generator Loss: -0.20751067996025085\nEpoch [187/240] Step [1200] Discriminator Loss: -0.6479296088218689 Generator Loss: -0.13272789120674133\nEpoch [187/240] Step [1800] Discriminator Loss: -0.0717126727104187 Generator Loss: -0.6860224008560181\nEpoch [187/240] Step [2400] Discriminator Loss: -0.32912835478782654 Generator Loss: -0.10836027562618256\nEpoch [187/240] Step [3000] Discriminator Loss: -0.8392919301986694 Generator Loss: 0.019058600068092346\nEpoch [187/240] Step [3600] Discriminator Loss: -0.3891153037548065 Generator Loss: -0.36017677187919617\nEpoch [187/240] Step [4200] Discriminator Loss: -0.5321007370948792 Generator Loss: -0.17001357674598694\nEpoch [187/240] Step [4800] Discriminator Loss: -0.5122388601303101 Generator Loss: -0.08006454259157181\nEpoch [187/240] Step [5400] Discriminator Loss: -0.015251636505126953 Generator Loss: -0.5130396485328674\nEpoch [187/240] Step [6000] Discriminator Loss: -0.8428207635879517 Generator Loss: -0.0012685693800449371\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  78%|███████▊  | 188/240 [2:01:00<33:55, 39.14s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [187/240] Avg Discriminator Loss: -0.39471591209426465 Avg Generator Loss: -0.23984164229147273\nEpoch [188/240] Step [0] Discriminator Loss: -0.767896294593811 Generator Loss: -0.007723020389676094\nEpoch [188/240] Step [600] Discriminator Loss: -0.7903783321380615 Generator Loss: -0.02568589150905609\nEpoch [188/240] Step [1200] Discriminator Loss: -0.7094723582267761 Generator Loss: -0.16902559995651245\nEpoch [188/240] Step [1800] Discriminator Loss: -0.6466667652130127 Generator Loss: -0.2058069109916687\nEpoch [188/240] Step [2400] Discriminator Loss: 0.014281749725341797 Generator Loss: -0.5212427973747253\nEpoch [188/240] Step [3000] Discriminator Loss: -0.16176657378673553 Generator Loss: -0.2845781743526459\nEpoch [188/240] Step [3600] Discriminator Loss: 0.2229643613100052 Generator Loss: -0.28582870960235596\nEpoch [188/240] Step [4200] Discriminator Loss: -0.7281982898712158 Generator Loss: 0.02609127201139927\nEpoch [188/240] Step [4800] Discriminator Loss: -0.6226747632026672 Generator Loss: -0.06982488930225372\nEpoch [188/240] Step [5400] Discriminator Loss: -0.6795663237571716 Generator Loss: -0.09673997759819031\nEpoch [188/240] Step [6000] Discriminator Loss: -0.4832204580307007 Generator Loss: -0.05567185953259468\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  79%|███████▉  | 189/240 [2:01:41<33:50, 39.81s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [188/240] Avg Discriminator Loss: -0.3705506338140903 Avg Generator Loss: -0.17562603764235973\nEpoch [189/240] Step [0] Discriminator Loss: -0.7663363218307495 Generator Loss: -0.0756300836801529\nEpoch [189/240] Step [600] Discriminator Loss: -0.820183277130127 Generator Loss: -0.027372710406780243\nEpoch [189/240] Step [1200] Discriminator Loss: -0.7994300127029419 Generator Loss: -0.08232875913381577\nEpoch [189/240] Step [1800] Discriminator Loss: -0.2618873715400696 Generator Loss: -0.5566349625587463\nEpoch [189/240] Step [2400] Discriminator Loss: -0.2818557024002075 Generator Loss: -0.09211382269859314\nEpoch [189/240] Step [3000] Discriminator Loss: -0.6788437366485596 Generator Loss: -0.11012636125087738\nEpoch [189/240] Step [3600] Discriminator Loss: -0.7938549518585205 Generator Loss: -0.07312431931495667\nEpoch [189/240] Step [4200] Discriminator Loss: -0.8114218711853027 Generator Loss: -0.05474912375211716\nEpoch [189/240] Step [4800] Discriminator Loss: -0.47710078954696655 Generator Loss: -0.06610703468322754\nEpoch [189/240] Step [5400] Discriminator Loss: -0.7881322503089905 Generator Loss: -0.20536985993385315\nEpoch [189/240] Step [6000] Discriminator Loss: -0.6567580699920654 Generator Loss: -0.12896010279655457\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  79%|███████▉  | 190/240 [2:02:21<32:58, 39.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [189/240] Avg Discriminator Loss: -0.6334911033565744 Avg Generator Loss: -0.1471353834733749\nEpoch [190/240] Step [0] Discriminator Loss: -0.34346652030944824 Generator Loss: -0.15732750296592712\nEpoch [190/240] Step [600] Discriminator Loss: 0.9786304831504822 Generator Loss: -0.36036112904548645\nEpoch [190/240] Step [1200] Discriminator Loss: 0.22510536015033722 Generator Loss: -0.5540118217468262\nEpoch [190/240] Step [1800] Discriminator Loss: -0.03107428550720215 Generator Loss: -0.11340390890836716\nEpoch [190/240] Step [2400] Discriminator Loss: -0.5403635501861572 Generator Loss: 0.004034750163555145\nEpoch [190/240] Step [3000] Discriminator Loss: -0.29484623670578003 Generator Loss: -0.2721119523048401\nEpoch [190/240] Step [3600] Discriminator Loss: -0.19997578859329224 Generator Loss: -0.3317471444606781\nEpoch [190/240] Step [4200] Discriminator Loss: -0.6263567209243774 Generator Loss: -0.15234380960464478\nEpoch [190/240] Step [4800] Discriminator Loss: -0.6704566478729248 Generator Loss: -0.0775783583521843\nEpoch [190/240] Step [5400] Discriminator Loss: -0.8299335241317749 Generator Loss: -0.04631735756993294\nEpoch [190/240] Step [6000] Discriminator Loss: -0.6127285957336426 Generator Loss: -0.11858072876930237\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  80%|███████▉  | 191/240 [2:02:59<32:07, 39.34s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [190/240] Avg Discriminator Loss: -0.2966209078828494 Avg Generator Loss: -0.23624364733559527\nEpoch [191/240] Step [0] Discriminator Loss: -0.22382645308971405 Generator Loss: -0.5832257270812988\nEpoch [191/240] Step [600] Discriminator Loss: -0.6123988032341003 Generator Loss: -0.20115463435649872\nEpoch [191/240] Step [1200] Discriminator Loss: -0.6805097460746765 Generator Loss: -0.16668473184108734\nEpoch [191/240] Step [1800] Discriminator Loss: -0.6253864765167236 Generator Loss: -0.14571140706539154\nEpoch [191/240] Step [2400] Discriminator Loss: -0.6300365924835205 Generator Loss: -0.2690623104572296\nEpoch [191/240] Step [3000] Discriminator Loss: -0.5031847953796387 Generator Loss: -0.16374999284744263\nEpoch [191/240] Step [3600] Discriminator Loss: -0.3851551413536072 Generator Loss: -0.29406899213790894\nEpoch [191/240] Step [4200] Discriminator Loss: -0.5730493068695068 Generator Loss: -0.09563890844583511\nEpoch [191/240] Step [4800] Discriminator Loss: -0.784380316734314 Generator Loss: -0.12442520260810852\nEpoch [191/240] Step [5400] Discriminator Loss: -0.6756547689437866 Generator Loss: -0.26742368936538696\nEpoch [191/240] Step [6000] Discriminator Loss: -0.5229886770248413 Generator Loss: -0.10192424058914185\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  80%|████████  | 192/240 [2:03:38<31:20, 39.19s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [191/240] Avg Discriminator Loss: -0.5471364524993267 Avg Generator Loss: -0.18015999444538638\nEpoch [192/240] Step [0] Discriminator Loss: -0.7348655462265015 Generator Loss: -0.11537612229585648\nEpoch [192/240] Step [600] Discriminator Loss: -0.6235347986221313 Generator Loss: -0.17355571687221527\nEpoch [192/240] Step [1200] Discriminator Loss: -0.7338089942932129 Generator Loss: -0.1185348778963089\nEpoch [192/240] Step [1800] Discriminator Loss: -0.48745688796043396 Generator Loss: -0.12487161159515381\nEpoch [192/240] Step [2400] Discriminator Loss: -0.7985429763793945 Generator Loss: -0.0471479631960392\nEpoch [192/240] Step [3000] Discriminator Loss: -0.8265498280525208 Generator Loss: -0.05737963318824768\nEpoch [192/240] Step [3600] Discriminator Loss: -0.3415078818798065 Generator Loss: -0.2922983765602112\nEpoch [192/240] Step [4200] Discriminator Loss: -0.7550206184387207 Generator Loss: -0.07041241228580475\nEpoch [192/240] Step [4800] Discriminator Loss: -0.5788503289222717 Generator Loss: -0.15893778204917908\nEpoch [192/240] Step [5400] Discriminator Loss: 0.18703977763652802 Generator Loss: -0.8815640211105347\nEpoch [192/240] Step [6000] Discriminator Loss: -0.3603038191795349 Generator Loss: -0.14384770393371582\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  80%|████████  | 193/240 [2:04:17<30:35, 39.06s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [192/240] Avg Discriminator Loss: -0.3825993919710973 Avg Generator Loss: -0.24930147458918583\nEpoch [193/240] Step [0] Discriminator Loss: -0.5342950820922852 Generator Loss: -0.15099656581878662\nEpoch [193/240] Step [600] Discriminator Loss: -0.7182285189628601 Generator Loss: -0.1170489639043808\nEpoch [193/240] Step [1200] Discriminator Loss: -0.7065771818161011 Generator Loss: -0.1420842707157135\nEpoch [193/240] Step [1800] Discriminator Loss: -0.726167619228363 Generator Loss: -0.07283858954906464\nEpoch [193/240] Step [2400] Discriminator Loss: -0.8058615326881409 Generator Loss: -0.09871521592140198\nEpoch [193/240] Step [3000] Discriminator Loss: -0.7929785251617432 Generator Loss: -0.06637370586395264\nEpoch [193/240] Step [3600] Discriminator Loss: 0.27375462651252747 Generator Loss: -0.40800732374191284\nEpoch [193/240] Step [4200] Discriminator Loss: -0.4202289581298828 Generator Loss: -0.19603709876537323\nEpoch [193/240] Step [4800] Discriminator Loss: -0.6075766086578369 Generator Loss: -0.015205860137939453\nEpoch [193/240] Step [5400] Discriminator Loss: -0.6218916177749634 Generator Loss: -0.1117599830031395\nEpoch [193/240] Step [6000] Discriminator Loss: -0.7355968952178955 Generator Loss: -0.12263202667236328\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  81%|████████  | 194/240 [2:04:55<29:48, 38.89s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [193/240] Avg Discriminator Loss: -0.4197945911096129 Avg Generator Loss: -0.1780717506281513\nEpoch [194/240] Step [0] Discriminator Loss: -0.7753399610519409 Generator Loss: -0.021608661860227585\nEpoch [194/240] Step [600] Discriminator Loss: -0.23759180307388306 Generator Loss: -0.29059770703315735\nEpoch [194/240] Step [1200] Discriminator Loss: -0.7863479256629944 Generator Loss: -0.05347424000501633\nEpoch [194/240] Step [1800] Discriminator Loss: -0.5215263962745667 Generator Loss: -0.2069726586341858\nEpoch [194/240] Step [2400] Discriminator Loss: -0.7272933721542358 Generator Loss: -0.10853864997625351\nEpoch [194/240] Step [3000] Discriminator Loss: -0.7612276077270508 Generator Loss: -0.12538452446460724\nEpoch [194/240] Step [3600] Discriminator Loss: -0.5422183275222778 Generator Loss: -0.1282370686531067\nEpoch [194/240] Step [4200] Discriminator Loss: -0.43423837423324585 Generator Loss: -0.17913784086704254\nEpoch [194/240] Step [4800] Discriminator Loss: -0.6852346062660217 Generator Loss: -0.10333473235368729\nEpoch [194/240] Step [5400] Discriminator Loss: 1.5781044960021973 Generator Loss: -0.21193666756153107\nEpoch [194/240] Step [6000] Discriminator Loss: -0.7978763580322266 Generator Loss: -0.007363699376583099\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  81%|████████▏ | 195/240 [2:05:34<29:06, 38.80s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [194/240] Avg Discriminator Loss: -0.4742099386486378 Avg Generator Loss: -0.18729759887502198\nEpoch [195/240] Step [0] Discriminator Loss: -0.7868018746376038 Generator Loss: -0.04563470557332039\nEpoch [195/240] Step [600] Discriminator Loss: -0.42900538444519043 Generator Loss: -0.2957506775856018\nEpoch [195/240] Step [1200] Discriminator Loss: -0.6809074878692627 Generator Loss: -0.1403614580631256\nEpoch [195/240] Step [1800] Discriminator Loss: 0.035711780190467834 Generator Loss: -0.47588077187538147\nEpoch [195/240] Step [2400] Discriminator Loss: -0.5329328775405884 Generator Loss: -0.11452624201774597\nEpoch [195/240] Step [3000] Discriminator Loss: -0.5919142961502075 Generator Loss: -0.18434712290763855\nEpoch [195/240] Step [3600] Discriminator Loss: -0.6924382448196411 Generator Loss: -0.10705242305994034\nEpoch [195/240] Step [4200] Discriminator Loss: -0.7363131642341614 Generator Loss: -0.0928911417722702\nEpoch [195/240] Step [4800] Discriminator Loss: -0.6673086285591125 Generator Loss: -0.20437368750572205\nEpoch [195/240] Step [5400] Discriminator Loss: -0.11586587131023407 Generator Loss: -0.19261133670806885\nEpoch [195/240] Step [6000] Discriminator Loss: -0.6681472063064575 Generator Loss: -0.14378675818443298\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  82%|████████▏ | 196/240 [2:06:13<28:25, 38.77s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [195/240] Avg Discriminator Loss: -0.5163917928770348 Avg Generator Loss: -0.18251167525684003\nEpoch [196/240] Step [0] Discriminator Loss: -0.8254930973052979 Generator Loss: -0.023022685199975967\nEpoch [196/240] Step [600] Discriminator Loss: 0.07611751556396484 Generator Loss: -0.3302648067474365\nEpoch [196/240] Step [1200] Discriminator Loss: -0.2321833372116089 Generator Loss: -0.08721045404672623\nEpoch [196/240] Step [1800] Discriminator Loss: -0.7480283975601196 Generator Loss: -0.07787963002920151\nEpoch [196/240] Step [2400] Discriminator Loss: 0.0347476601600647 Generator Loss: -0.5713335275650024\nEpoch [196/240] Step [3000] Discriminator Loss: -0.01811528205871582 Generator Loss: -0.38884812593460083\nEpoch [196/240] Step [3600] Discriminator Loss: -0.5943987965583801 Generator Loss: -0.09968286752700806\nEpoch [196/240] Step [4200] Discriminator Loss: -0.7918916940689087 Generator Loss: -0.13541997969150543\nEpoch [196/240] Step [4800] Discriminator Loss: -0.822194516658783 Generator Loss: -0.057320233434438705\nEpoch [196/240] Step [5400] Discriminator Loss: -0.6719290018081665 Generator Loss: -0.11794522404670715\nEpoch [196/240] Step [6000] Discriminator Loss: -0.4331515431404114 Generator Loss: -0.34874823689460754\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  82%|████████▏ | 197/240 [2:06:51<27:46, 38.75s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [196/240] Avg Discriminator Loss: -0.4566947364217632 Avg Generator Loss: -0.21514745393679255\nEpoch [197/240] Step [0] Discriminator Loss: -0.6258272528648376 Generator Loss: -0.19770385324954987\nEpoch [197/240] Step [600] Discriminator Loss: -0.6907015442848206 Generator Loss: -0.08552511781454086\nEpoch [197/240] Step [1200] Discriminator Loss: -0.43713265657424927 Generator Loss: -0.3412565290927887\nEpoch [197/240] Step [1800] Discriminator Loss: -0.6237788796424866 Generator Loss: -0.11964808404445648\nEpoch [197/240] Step [2400] Discriminator Loss: -0.21504512429237366 Generator Loss: -0.09893326461315155\nEpoch [197/240] Step [3000] Discriminator Loss: -0.859691858291626 Generator Loss: 0.016014721244573593\nEpoch [197/240] Step [3600] Discriminator Loss: 0.8118645548820496 Generator Loss: -0.5893225073814392\nEpoch [197/240] Step [4200] Discriminator Loss: -0.8150226473808289 Generator Loss: -0.06899333000183105\nEpoch [197/240] Step [4800] Discriminator Loss: -0.7562350630760193 Generator Loss: -0.07361817359924316\nEpoch [197/240] Step [5400] Discriminator Loss: -0.6482482552528381 Generator Loss: -0.0716775432229042\nEpoch [197/240] Step [6000] Discriminator Loss: -0.6089674830436707 Generator Loss: -0.19557583332061768\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  82%|████████▎ | 198/240 [2:07:30<27:07, 38.76s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [197/240] Avg Discriminator Loss: -0.49255830426137526 Avg Generator Loss: -0.17777958665820923\nEpoch [198/240] Step [0] Discriminator Loss: -0.8489584922790527 Generator Loss: -0.008335642516613007\nEpoch [198/240] Step [600] Discriminator Loss: -0.7887957692146301 Generator Loss: -0.08351095020771027\nEpoch [198/240] Step [1200] Discriminator Loss: -0.6879618763923645 Generator Loss: -0.12160621583461761\nEpoch [198/240] Step [1800] Discriminator Loss: -0.6954940557479858 Generator Loss: -0.2167198359966278\nEpoch [198/240] Step [2400] Discriminator Loss: 0.022052422165870667 Generator Loss: -0.19625210762023926\nEpoch [198/240] Step [3000] Discriminator Loss: -0.6247241497039795 Generator Loss: -0.15685805678367615\nEpoch [198/240] Step [3600] Discriminator Loss: -0.5953717827796936 Generator Loss: -0.18072938919067383\nEpoch [198/240] Step [4200] Discriminator Loss: -0.6899219751358032 Generator Loss: -0.16386866569519043\nEpoch [198/240] Step [4800] Discriminator Loss: -0.6230372786521912 Generator Loss: -0.3056805431842804\nEpoch [198/240] Step [5400] Discriminator Loss: -0.6269518733024597 Generator Loss: -0.219448059797287\nEpoch [198/240] Step [6000] Discriminator Loss: -0.5797181129455566 Generator Loss: -0.11607513576745987\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  83%|████████▎ | 199/240 [2:08:09<26:24, 38.66s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [198/240] Avg Discriminator Loss: -0.5436330754787494 Avg Generator Loss: -0.18865153370186305\nEpoch [199/240] Step [0] Discriminator Loss: -0.6125038862228394 Generator Loss: -0.10185940563678741\nEpoch [199/240] Step [600] Discriminator Loss: -0.6107757687568665 Generator Loss: -0.12371058762073517\nEpoch [199/240] Step [1200] Discriminator Loss: 9.214125633239746 Generator Loss: -0.9581189751625061\nEpoch [199/240] Step [1800] Discriminator Loss: 0.1791592836380005 Generator Loss: -0.8224265575408936\nEpoch [199/240] Step [2400] Discriminator Loss: 0.04755818843841553 Generator Loss: -0.699232816696167\nEpoch [199/240] Step [3000] Discriminator Loss: -0.5908253192901611 Generator Loss: -0.095893993973732\nEpoch [199/240] Step [3600] Discriminator Loss: -0.2313079833984375 Generator Loss: -0.18941737711429596\nEpoch [199/240] Step [4200] Discriminator Loss: -0.7512916922569275 Generator Loss: -0.038341302424669266\nEpoch [199/240] Step [4800] Discriminator Loss: -0.8008584976196289 Generator Loss: -0.08104750514030457\nEpoch [199/240] Step [5400] Discriminator Loss: -0.8429216742515564 Generator Loss: -0.13597090542316437\nEpoch [199/240] Step [6000] Discriminator Loss: -0.8650839328765869 Generator Loss: -0.011764319613575935\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  83%|████████▎ | 200/240 [2:08:47<25:46, 38.65s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [199/240] Avg Discriminator Loss: -0.1254351528791281 Avg Generator Loss: -0.257791811627619\nEpoch [200/240] Step [0] Discriminator Loss: 1.0479846000671387 Generator Loss: -0.2946109473705292\nEpoch [200/240] Step [600] Discriminator Loss: -0.47306984663009644 Generator Loss: -0.18624167144298553\nEpoch [200/240] Step [1200] Discriminator Loss: -0.6969209909439087 Generator Loss: -0.14002668857574463\nEpoch [200/240] Step [1800] Discriminator Loss: -0.6458903551101685 Generator Loss: -0.4162047803401947\nEpoch [200/240] Step [2400] Discriminator Loss: 0.5116889476776123 Generator Loss: -0.39076629281044006\nEpoch [200/240] Step [3000] Discriminator Loss: -0.24796181917190552 Generator Loss: -0.11490842700004578\nEpoch [200/240] Step [3600] Discriminator Loss: -0.6539916396141052 Generator Loss: -0.12082558870315552\nEpoch [200/240] Step [4200] Discriminator Loss: -0.7629739046096802 Generator Loss: -0.10543672740459442\nEpoch [200/240] Step [4800] Discriminator Loss: -0.5784290432929993 Generator Loss: -0.2102612853050232\nEpoch [200/240] Step [5400] Discriminator Loss: -0.5871967077255249 Generator Loss: -0.0985502153635025\nEpoch [200/240] Step [6000] Discriminator Loss: -0.7957024574279785 Generator Loss: -0.03581845015287399\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  84%|████████▍ | 201/240 [2:09:26<25:08, 38.68s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [200/240] Avg Discriminator Loss: -0.49711739814980127 Avg Generator Loss: -0.17891882681338997\nEpoch [201/240] Step [0] Discriminator Loss: -0.6500224471092224 Generator Loss: -0.3276594877243042\nEpoch [201/240] Step [600] Discriminator Loss: 0.19303172826766968 Generator Loss: -0.6972708106040955\nEpoch [201/240] Step [1200] Discriminator Loss: 0.3272021412849426 Generator Loss: -0.8070634603500366\nEpoch [201/240] Step [1800] Discriminator Loss: -0.2813132703304291 Generator Loss: -0.12832647562026978\nEpoch [201/240] Step [2400] Discriminator Loss: -0.49210071563720703 Generator Loss: -0.04303307831287384\nEpoch [201/240] Step [3000] Discriminator Loss: -0.8152944445610046 Generator Loss: -0.019007474184036255\nEpoch [201/240] Step [3600] Discriminator Loss: -0.27401143312454224 Generator Loss: -0.29919686913490295\nEpoch [201/240] Step [4200] Discriminator Loss: -0.5991042852401733 Generator Loss: -0.2267998307943344\nEpoch [201/240] Step [4800] Discriminator Loss: -0.24753046035766602 Generator Loss: -0.49780088663101196\nEpoch [201/240] Step [5400] Discriminator Loss: -0.7008885145187378 Generator Loss: -0.1538795679807663\nEpoch [201/240] Step [6000] Discriminator Loss: -0.6920126080513 Generator Loss: -0.13563218712806702\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  84%|████████▍ | 202/240 [2:10:05<24:28, 38.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [201/240] Avg Discriminator Loss: -0.4665242621859351 Avg Generator Loss: -0.23493930511176586\nEpoch [202/240] Step [0] Discriminator Loss: -0.7543631792068481 Generator Loss: -0.09279248118400574\nEpoch [202/240] Step [600] Discriminator Loss: -0.8075213432312012 Generator Loss: -0.05744107812643051\nEpoch [202/240] Step [1200] Discriminator Loss: -0.7403384447097778 Generator Loss: -0.08220342546701431\nEpoch [202/240] Step [1800] Discriminator Loss: -0.6908164024353027 Generator Loss: -0.10183241963386536\nEpoch [202/240] Step [2400] Discriminator Loss: -0.3598782420158386 Generator Loss: -0.24864834547042847\nEpoch [202/240] Step [3000] Discriminator Loss: -0.6834969520568848 Generator Loss: -0.17128688097000122\nEpoch [202/240] Step [3600] Discriminator Loss: -0.6240921020507812 Generator Loss: -0.13753938674926758\nEpoch [202/240] Step [4200] Discriminator Loss: -0.7160168886184692 Generator Loss: -0.13541585206985474\nEpoch [202/240] Step [4800] Discriminator Loss: 0.6767645478248596 Generator Loss: -0.9567309617996216\nEpoch [202/240] Step [5400] Discriminator Loss: 0.08489523828029633 Generator Loss: -0.9621310234069824\nEpoch [202/240] Step [6000] Discriminator Loss: 0.16391146183013916 Generator Loss: -0.9549959301948547\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  85%|████████▍ | 203/240 [2:10:43<23:49, 38.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [202/240] Avg Discriminator Loss: -0.3473547103477048 Avg Generator Loss: -0.3943512055326949\nEpoch [203/240] Step [0] Discriminator Loss: 0.0822991132736206 Generator Loss: -0.9533659815788269\nEpoch [203/240] Step [600] Discriminator Loss: -0.8065706491470337 Generator Loss: 0.017774980515241623\nEpoch [203/240] Step [1200] Discriminator Loss: -0.6015353798866272 Generator Loss: -0.07363694161176682\nEpoch [203/240] Step [1800] Discriminator Loss: -0.05963009595870972 Generator Loss: -0.15356846153736115\nEpoch [203/240] Step [2400] Discriminator Loss: -0.5179581046104431 Generator Loss: -0.24734851717948914\nEpoch [203/240] Step [3000] Discriminator Loss: -0.6105027198791504 Generator Loss: -0.06046583876013756\nEpoch [203/240] Step [3600] Discriminator Loss: -0.5791181325912476 Generator Loss: -0.17196227610111237\nEpoch [203/240] Step [4200] Discriminator Loss: -0.041073158383369446 Generator Loss: -0.6299790740013123\nEpoch [203/240] Step [4800] Discriminator Loss: -0.8528172969818115 Generator Loss: -0.030229579657316208\nEpoch [203/240] Step [5400] Discriminator Loss: -0.17244736850261688 Generator Loss: -0.4234507083892822\nEpoch [203/240] Step [6000] Discriminator Loss: -0.6718845963478088 Generator Loss: -0.1368204802274704\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  85%|████████▌ | 204/240 [2:11:22<23:12, 38.67s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [203/240] Avg Discriminator Loss: -0.455819108738349 Avg Generator Loss: -0.19064752048311326\nEpoch [204/240] Step [0] Discriminator Loss: -0.639782190322876 Generator Loss: -0.161794513463974\nEpoch [204/240] Step [600] Discriminator Loss: 0.10185575485229492 Generator Loss: -0.5298393368721008\nEpoch [204/240] Step [1200] Discriminator Loss: -0.6751433610916138 Generator Loss: -0.11140981316566467\nEpoch [204/240] Step [1800] Discriminator Loss: -0.5884348154067993 Generator Loss: -0.14569352567195892\nEpoch [204/240] Step [2400] Discriminator Loss: -0.6705552339553833 Generator Loss: -0.07060498744249344\nEpoch [204/240] Step [3000] Discriminator Loss: -0.9158661961555481 Generator Loss: 0.015617660246789455\nEpoch [204/240] Step [3600] Discriminator Loss: -0.7305642366409302 Generator Loss: -0.08988231420516968\nEpoch [204/240] Step [4200] Discriminator Loss: -0.5927843451499939 Generator Loss: -0.20324690639972687\nEpoch [204/240] Step [4800] Discriminator Loss: -0.5177195072174072 Generator Loss: -0.12427692115306854\nEpoch [204/240] Step [5400] Discriminator Loss: -0.45224374532699585 Generator Loss: -0.4148077368736267\nEpoch [204/240] Step [6000] Discriminator Loss: -0.27240028977394104 Generator Loss: -0.27060380578041077\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  85%|████████▌ | 205/240 [2:12:00<22:31, 38.61s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [204/240] Avg Discriminator Loss: -0.5031264705426527 Avg Generator Loss: -0.2029733354321275\nEpoch [205/240] Step [0] Discriminator Loss: -0.5843380689620972 Generator Loss: -0.1566043496131897\nEpoch [205/240] Step [600] Discriminator Loss: -0.5887568593025208 Generator Loss: -0.15923210978507996\nEpoch [205/240] Step [1200] Discriminator Loss: -0.35772189497947693 Generator Loss: -0.1366393268108368\nEpoch [205/240] Step [1800] Discriminator Loss: -0.4606856107711792 Generator Loss: -0.23181240260601044\nEpoch [205/240] Step [2400] Discriminator Loss: -0.6619043350219727 Generator Loss: -0.15255054831504822\nEpoch [205/240] Step [3000] Discriminator Loss: -0.5804576873779297 Generator Loss: -0.2086171805858612\nEpoch [205/240] Step [3600] Discriminator Loss: -0.6415615081787109 Generator Loss: -0.1754063218832016\nEpoch [205/240] Step [4200] Discriminator Loss: -0.5434156656265259 Generator Loss: -0.23519039154052734\nEpoch [205/240] Step [4800] Discriminator Loss: -0.6387010216712952 Generator Loss: -0.1586974561214447\nEpoch [205/240] Step [5400] Discriminator Loss: 0.27314507961273193 Generator Loss: -0.3421992361545563\nEpoch [205/240] Step [6000] Discriminator Loss: -0.477497398853302 Generator Loss: -0.14946387708187103\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  86%|████████▌ | 206/240 [2:12:39<21:52, 38.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [205/240] Avg Discriminator Loss: -0.43454225473242364 Avg Generator Loss: -0.2249137953899446\nEpoch [206/240] Step [0] Discriminator Loss: -0.806164562702179 Generator Loss: -0.10026592016220093\nEpoch [206/240] Step [600] Discriminator Loss: -0.2638022005558014 Generator Loss: -0.39591795206069946\nEpoch [206/240] Step [1200] Discriminator Loss: -0.5178671479225159 Generator Loss: -0.24074818193912506\nEpoch [206/240] Step [1800] Discriminator Loss: -0.611388087272644 Generator Loss: -0.1357448250055313\nEpoch [206/240] Step [2400] Discriminator Loss: -0.5444657206535339 Generator Loss: -0.1850091964006424\nEpoch [206/240] Step [3000] Discriminator Loss: -0.722404956817627 Generator Loss: -0.1200806125998497\nEpoch [206/240] Step [3600] Discriminator Loss: -0.14231213927268982 Generator Loss: -0.18184040486812592\nEpoch [206/240] Step [4200] Discriminator Loss: 0.08915087580680847 Generator Loss: -0.23999139666557312\nEpoch [206/240] Step [4800] Discriminator Loss: -0.6574784517288208 Generator Loss: -0.03441647067666054\nEpoch [206/240] Step [5400] Discriminator Loss: -0.5522136092185974 Generator Loss: -0.02159915491938591\nEpoch [206/240] Step [6000] Discriminator Loss: -0.8663561344146729 Generator Loss: -0.020514460280537605\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  86%|████████▋ | 207/240 [2:13:17<21:12, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [206/240] Avg Discriminator Loss: -0.4462058861286212 Avg Generator Loss: -0.18521888175426604\nEpoch [207/240] Step [0] Discriminator Loss: -0.8045886754989624 Generator Loss: -0.08036083728075027\nEpoch [207/240] Step [600] Discriminator Loss: -0.8836749792098999 Generator Loss: -0.0075314585119485855\nEpoch [207/240] Step [1200] Discriminator Loss: -0.45730048418045044 Generator Loss: -0.21938082575798035\nEpoch [207/240] Step [1800] Discriminator Loss: -0.6405227184295654 Generator Loss: -0.23003998398780823\nEpoch [207/240] Step [2400] Discriminator Loss: -0.7154057621955872 Generator Loss: -0.09204220771789551\nEpoch [207/240] Step [3000] Discriminator Loss: -0.7722498774528503 Generator Loss: -0.026452064514160156\nEpoch [207/240] Step [3600] Discriminator Loss: -0.7322766780853271 Generator Loss: -0.00489402748644352\nEpoch [207/240] Step [4200] Discriminator Loss: -0.7639118432998657 Generator Loss: -0.014562899246811867\nEpoch [207/240] Step [4800] Discriminator Loss: -0.7893629670143127 Generator Loss: -0.0845533236861229\nEpoch [207/240] Step [5400] Discriminator Loss: -0.8296175599098206 Generator Loss: -0.0642113983631134\nEpoch [207/240] Step [6000] Discriminator Loss: -0.5218321084976196 Generator Loss: -0.30913954973220825\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  87%|████████▋ | 208/240 [2:13:56<20:32, 38.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [207/240] Avg Discriminator Loss: -0.6487713145576554 Avg Generator Loss: -0.14969459677544925\nEpoch [208/240] Step [0] Discriminator Loss: -0.6153343915939331 Generator Loss: -0.190623939037323\nEpoch [208/240] Step [600] Discriminator Loss: -0.69907146692276 Generator Loss: -0.12550321221351624\nEpoch [208/240] Step [1200] Discriminator Loss: -0.6143198013305664 Generator Loss: -0.22508686780929565\nEpoch [208/240] Step [1800] Discriminator Loss: -0.7080534100532532 Generator Loss: -0.17960581183433533\nEpoch [208/240] Step [2400] Discriminator Loss: -0.7719221115112305 Generator Loss: -0.0879654735326767\nEpoch [208/240] Step [3000] Discriminator Loss: -0.800162136554718 Generator Loss: -0.1135811060667038\nEpoch [208/240] Step [3600] Discriminator Loss: -0.7387394905090332 Generator Loss: -0.18636669218540192\nEpoch [208/240] Step [4200] Discriminator Loss: -0.311856210231781 Generator Loss: -0.3623841404914856\nEpoch [208/240] Step [4800] Discriminator Loss: -0.640398383140564 Generator Loss: -0.1624344438314438\nEpoch [208/240] Step [5400] Discriminator Loss: -0.4207347333431244 Generator Loss: -0.20608636736869812\nEpoch [208/240] Step [6000] Discriminator Loss: -0.5254013538360596 Generator Loss: -0.3481801748275757\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  87%|████████▋ | 209/240 [2:14:34<19:53, 38.49s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [208/240] Avg Discriminator Loss: -0.5244396971641007 Avg Generator Loss: -0.21439759958630952\nEpoch [209/240] Step [0] Discriminator Loss: -0.5445531606674194 Generator Loss: -0.17511652410030365\nEpoch [209/240] Step [600] Discriminator Loss: -0.8419563174247742 Generator Loss: -0.027262026444077492\nEpoch [209/240] Step [1200] Discriminator Loss: -0.7526410818099976 Generator Loss: -0.12054023146629333\nEpoch [209/240] Step [1800] Discriminator Loss: -0.18281984329223633 Generator Loss: -0.3018064796924591\nEpoch [209/240] Step [2400] Discriminator Loss: -0.2947613000869751 Generator Loss: -0.26197105646133423\nEpoch [209/240] Step [3000] Discriminator Loss: -0.4545784592628479 Generator Loss: -0.3356125056743622\nEpoch [209/240] Step [3600] Discriminator Loss: -0.5452287793159485 Generator Loss: -0.21248361468315125\nEpoch [209/240] Step [4200] Discriminator Loss: -0.47440123558044434 Generator Loss: -0.39587241411209106\nEpoch [209/240] Step [4800] Discriminator Loss: -0.42418229579925537 Generator Loss: -0.32084906101226807\nEpoch [209/240] Step [5400] Discriminator Loss: -0.8369858264923096 Generator Loss: -0.13180522620677948\nEpoch [209/240] Step [6000] Discriminator Loss: -0.6017811298370361 Generator Loss: -0.12319475412368774\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  88%|████████▊ | 210/240 [2:15:13<19:14, 38.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [209/240] Avg Discriminator Loss: -0.4966229645760505 Avg Generator Loss: -0.2011886636211431\nEpoch [210/240] Step [0] Discriminator Loss: -0.570331871509552 Generator Loss: 0.013257984071969986\nEpoch [210/240] Step [600] Discriminator Loss: -0.6801009178161621 Generator Loss: -0.013755058869719505\nEpoch [210/240] Step [1200] Discriminator Loss: -0.32060331106185913 Generator Loss: -0.27211618423461914\nEpoch [210/240] Step [1800] Discriminator Loss: -0.8250231742858887 Generator Loss: -0.05100438371300697\nEpoch [210/240] Step [2400] Discriminator Loss: -0.7484242916107178 Generator Loss: -0.09322739392518997\nEpoch [210/240] Step [3000] Discriminator Loss: -0.11084425449371338 Generator Loss: -0.3402439057826996\nEpoch [210/240] Step [3600] Discriminator Loss: -0.21405968070030212 Generator Loss: -0.6453832983970642\nEpoch [210/240] Step [4200] Discriminator Loss: -0.749748170375824 Generator Loss: -0.13270674645900726\nEpoch [210/240] Step [4800] Discriminator Loss: -0.7783272862434387 Generator Loss: -0.08859545737504959\nEpoch [210/240] Step [5400] Discriminator Loss: -0.4513035714626312 Generator Loss: -0.23949627578258514\nEpoch [210/240] Step [6000] Discriminator Loss: -0.696434736251831 Generator Loss: -0.06496225297451019\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  88%|████████▊ | 211/240 [2:15:51<18:37, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [210/240] Avg Discriminator Loss: -0.49507202232604497 Avg Generator Loss: -0.198057583062449\nEpoch [211/240] Step [0] Discriminator Loss: -0.6813845634460449 Generator Loss: -0.19339187443256378\nEpoch [211/240] Step [600] Discriminator Loss: 0.15505272150039673 Generator Loss: -0.6784626245498657\nEpoch [211/240] Step [1200] Discriminator Loss: -0.49632641673088074 Generator Loss: -0.2009720355272293\nEpoch [211/240] Step [1800] Discriminator Loss: -0.522521436214447 Generator Loss: -0.16301700472831726\nEpoch [211/240] Step [2400] Discriminator Loss: 0.249952495098114 Generator Loss: -0.19331865012645721\nEpoch [211/240] Step [3000] Discriminator Loss: -0.3661707043647766 Generator Loss: -0.1121930181980133\nEpoch [211/240] Step [3600] Discriminator Loss: -0.66126549243927 Generator Loss: -0.15220363438129425\nEpoch [211/240] Step [4200] Discriminator Loss: -0.5395950078964233 Generator Loss: -0.11956236511468887\nEpoch [211/240] Step [4800] Discriminator Loss: -0.11232167482376099 Generator Loss: -0.33036404848098755\nEpoch [211/240] Step [5400] Discriminator Loss: -0.7280935049057007 Generator Loss: -0.10551285743713379\nEpoch [211/240] Step [6000] Discriminator Loss: -0.5589743852615356 Generator Loss: -0.18229900300502777\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  88%|████████▊ | 212/240 [2:16:30<18:00, 38.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [211/240] Avg Discriminator Loss: -0.5438190302896849 Avg Generator Loss: -0.18080187368551234\nEpoch [212/240] Step [0] Discriminator Loss: -0.8325285911560059 Generator Loss: -0.10035951435565948\nEpoch [212/240] Step [600] Discriminator Loss: -0.7777930498123169 Generator Loss: -0.09564879536628723\nEpoch [212/240] Step [1200] Discriminator Loss: -0.7126209735870361 Generator Loss: -0.17285212874412537\nEpoch [212/240] Step [1800] Discriminator Loss: -0.6752859354019165 Generator Loss: -0.15939326584339142\nEpoch [212/240] Step [2400] Discriminator Loss: -0.06397837400436401 Generator Loss: -0.17255404591560364\nEpoch [212/240] Step [3000] Discriminator Loss: 0.14435261487960815 Generator Loss: -0.4021172523498535\nEpoch [212/240] Step [3600] Discriminator Loss: -0.5676851272583008 Generator Loss: -0.19303086400032043\nEpoch [212/240] Step [4200] Discriminator Loss: -0.7624543905258179 Generator Loss: -0.016115233302116394\nEpoch [212/240] Step [4800] Discriminator Loss: -0.798226535320282 Generator Loss: -0.06534682959318161\nEpoch [212/240] Step [5400] Discriminator Loss: 4.000514984130859 Generator Loss: -0.3241601288318634\nEpoch [212/240] Step [6000] Discriminator Loss: -0.5096276998519897 Generator Loss: -0.20748305320739746\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  89%|████████▉ | 213/240 [2:17:09<17:22, 38.61s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [212/240] Avg Discriminator Loss: -0.4918839378016336 Avg Generator Loss: -0.2032539158268071\nEpoch [213/240] Step [0] Discriminator Loss: -0.8513915538787842 Generator Loss: -0.002405203878879547\nEpoch [213/240] Step [600] Discriminator Loss: -0.31535443663597107 Generator Loss: -0.21413716673851013\nEpoch [213/240] Step [1200] Discriminator Loss: -0.5285760164260864 Generator Loss: -0.24154536426067352\nEpoch [213/240] Step [1800] Discriminator Loss: -0.5029730796813965 Generator Loss: -0.19807486236095428\nEpoch [213/240] Step [2400] Discriminator Loss: -0.37676671147346497 Generator Loss: -0.5305042862892151\nEpoch [213/240] Step [3000] Discriminator Loss: -0.7956598997116089 Generator Loss: -0.048517584800720215\nEpoch [213/240] Step [3600] Discriminator Loss: -0.695614218711853 Generator Loss: -0.07448775321245193\nEpoch [213/240] Step [4200] Discriminator Loss: -0.6292303204536438 Generator Loss: -0.03935455530881882\nEpoch [213/240] Step [4800] Discriminator Loss: -0.5916913747787476 Generator Loss: 0.011192411184310913\nEpoch [213/240] Step [5400] Discriminator Loss: -0.5686011910438538 Generator Loss: -0.23287566006183624\nEpoch [213/240] Step [6000] Discriminator Loss: -0.739505410194397 Generator Loss: -0.019972654059529305\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  89%|████████▉ | 214/240 [2:17:47<16:44, 38.62s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [213/240] Avg Discriminator Loss: -0.4180316340464812 Avg Generator Loss: -0.23013377163027013\nEpoch [214/240] Step [0] Discriminator Loss: -0.6893715858459473 Generator Loss: -0.04162299633026123\nEpoch [214/240] Step [600] Discriminator Loss: -0.7336680889129639 Generator Loss: -0.09213688969612122\nEpoch [214/240] Step [1200] Discriminator Loss: -0.038023412227630615 Generator Loss: -0.2878570854663849\nEpoch [214/240] Step [1800] Discriminator Loss: -0.7989863157272339 Generator Loss: -0.08990351110696793\nEpoch [214/240] Step [2400] Discriminator Loss: -0.4780585765838623 Generator Loss: -0.11817459017038345\nEpoch [214/240] Step [3000] Discriminator Loss: -0.7964001893997192 Generator Loss: -0.09452061355113983\nEpoch [214/240] Step [3600] Discriminator Loss: -0.5429588556289673 Generator Loss: -0.1315961629152298\nEpoch [214/240] Step [4200] Discriminator Loss: -0.7435084581375122 Generator Loss: -0.11631881445646286\nEpoch [214/240] Step [4800] Discriminator Loss: -0.8312143683433533 Generator Loss: -0.018375994637608528\nEpoch [214/240] Step [5400] Discriminator Loss: -0.4936278760433197 Generator Loss: -0.39809975028038025\nEpoch [214/240] Step [6000] Discriminator Loss: -0.6803758144378662 Generator Loss: -0.11535046994686127\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  90%|████████▉ | 215/240 [2:18:26<16:06, 38.66s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [214/240] Avg Discriminator Loss: -0.5595291627250312 Avg Generator Loss: -0.1780265342348661\nEpoch [215/240] Step [0] Discriminator Loss: -0.2813248634338379 Generator Loss: -0.2350585162639618\nEpoch [215/240] Step [600] Discriminator Loss: -0.7061166167259216 Generator Loss: -0.09467486292123795\nEpoch [215/240] Step [1200] Discriminator Loss: -0.5938605070114136 Generator Loss: -0.22086185216903687\nEpoch [215/240] Step [1800] Discriminator Loss: -0.2987559735774994 Generator Loss: -0.3889796733856201\nEpoch [215/240] Step [2400] Discriminator Loss: 0.11423230171203613 Generator Loss: -0.20615418255329132\nEpoch [215/240] Step [3000] Discriminator Loss: 2.324631690979004 Generator Loss: -0.7739783525466919\nEpoch [215/240] Step [3600] Discriminator Loss: -0.08462360501289368 Generator Loss: -0.3787458837032318\nEpoch [215/240] Step [4200] Discriminator Loss: -0.582805335521698 Generator Loss: -0.16444751620292664\nEpoch [215/240] Step [4800] Discriminator Loss: -0.33033114671707153 Generator Loss: -0.10244935005903244\nEpoch [215/240] Step [5400] Discriminator Loss: -0.3682214915752411 Generator Loss: -0.5082710981369019\nEpoch [215/240] Step [6000] Discriminator Loss: -0.204728901386261 Generator Loss: -0.1281193196773529\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  90%|█████████ | 216/240 [2:19:04<15:25, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [215/240] Avg Discriminator Loss: 0.06144672967902907 Avg Generator Loss: -0.2899667366370286\nEpoch [216/240] Step [0] Discriminator Loss: -0.6394039988517761 Generator Loss: -0.17243680357933044\nEpoch [216/240] Step [600] Discriminator Loss: -0.713386595249176 Generator Loss: -0.06855297088623047\nEpoch [216/240] Step [1200] Discriminator Loss: -0.6544345021247864 Generator Loss: -0.19867229461669922\nEpoch [216/240] Step [1800] Discriminator Loss: -0.6875388622283936 Generator Loss: -0.09271892160177231\nEpoch [216/240] Step [2400] Discriminator Loss: -0.49022266268730164 Generator Loss: -0.11052212864160538\nEpoch [216/240] Step [3000] Discriminator Loss: -0.7932002544403076 Generator Loss: -0.10076804459095001\nEpoch [216/240] Step [3600] Discriminator Loss: -0.7667192220687866 Generator Loss: -0.031767696142196655\nEpoch [216/240] Step [4200] Discriminator Loss: -0.7320644855499268 Generator Loss: -0.07071440666913986\nEpoch [216/240] Step [4800] Discriminator Loss: -0.6969203948974609 Generator Loss: -0.11591871827840805\nEpoch [216/240] Step [5400] Discriminator Loss: -0.6659706830978394 Generator Loss: -0.24641895294189453\nEpoch [216/240] Step [6000] Discriminator Loss: -0.5666841864585876 Generator Loss: -0.15645095705986023\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  90%|█████████ | 217/240 [2:19:43<14:46, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [216/240] Avg Discriminator Loss: -0.5767445646144531 Avg Generator Loss: -0.158390021320064\nEpoch [217/240] Step [0] Discriminator Loss: -0.5831905603408813 Generator Loss: -0.2258577197790146\nEpoch [217/240] Step [600] Discriminator Loss: -0.33487099409103394 Generator Loss: -0.38758379220962524\nEpoch [217/240] Step [1200] Discriminator Loss: -0.5038498044013977 Generator Loss: -0.20010599493980408\nEpoch [217/240] Step [1800] Discriminator Loss: -0.6873915791511536 Generator Loss: -0.06218419969081879\nEpoch [217/240] Step [2400] Discriminator Loss: -0.7265754342079163 Generator Loss: -0.13494382798671722\nEpoch [217/240] Step [3000] Discriminator Loss: -0.7851330041885376 Generator Loss: -0.048479028046131134\nEpoch [217/240] Step [3600] Discriminator Loss: -0.5736618638038635 Generator Loss: -0.11752665042877197\nEpoch [217/240] Step [4200] Discriminator Loss: -0.6394015550613403 Generator Loss: -0.10420355200767517\nEpoch [217/240] Step [4800] Discriminator Loss: -0.7012064456939697 Generator Loss: -0.05920431762933731\nEpoch [217/240] Step [5400] Discriminator Loss: -0.7041428089141846 Generator Loss: -0.09376346319913864\nEpoch [217/240] Step [6000] Discriminator Loss: -0.5777684450149536 Generator Loss: -0.09497721493244171\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  91%|█████████ | 218/240 [2:20:21<14:06, 38.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [217/240] Avg Discriminator Loss: -0.55001310081709 Avg Generator Loss: -0.14906277453642844\nEpoch [218/240] Step [0] Discriminator Loss: -0.8092119097709656 Generator Loss: -0.08812260627746582\nEpoch [218/240] Step [600] Discriminator Loss: -0.5990110039710999 Generator Loss: -0.17045900225639343\nEpoch [218/240] Step [1200] Discriminator Loss: -0.6032468676567078 Generator Loss: -0.12754681706428528\nEpoch [218/240] Step [1800] Discriminator Loss: -0.46063488721847534 Generator Loss: -0.321638286113739\nEpoch [218/240] Step [2400] Discriminator Loss: -0.5570274591445923 Generator Loss: -0.28338176012039185\nEpoch [218/240] Step [3000] Discriminator Loss: -0.7056211233139038 Generator Loss: -0.07374261319637299\nEpoch [218/240] Step [3600] Discriminator Loss: -0.5553803443908691 Generator Loss: -0.22567200660705566\nEpoch [218/240] Step [4200] Discriminator Loss: -0.7221251726150513 Generator Loss: -0.18098804354667664\nEpoch [218/240] Step [4800] Discriminator Loss: -0.6047574877738953 Generator Loss: -0.18020693957805634\nEpoch [218/240] Step [5400] Discriminator Loss: -0.5601319074630737 Generator Loss: -0.2902177572250366\nEpoch [218/240] Step [6000] Discriminator Loss: -0.4166049361228943 Generator Loss: -0.2144462615251541\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  91%|█████████▏| 219/240 [2:21:00<13:28, 38.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [218/240] Avg Discriminator Loss: -0.47746124740812806 Avg Generator Loss: -0.19388593247863073\nEpoch [219/240] Step [0] Discriminator Loss: -0.8727130889892578 Generator Loss: 0.0011806357651948929\nEpoch [219/240] Step [600] Discriminator Loss: -0.6937878727912903 Generator Loss: -0.03752269595861435\nEpoch [219/240] Step [1200] Discriminator Loss: -0.8817335367202759 Generator Loss: -0.030453424900770187\nEpoch [219/240] Step [1800] Discriminator Loss: -0.6197910308837891 Generator Loss: -0.0668436586856842\nEpoch [219/240] Step [2400] Discriminator Loss: -0.7279804348945618 Generator Loss: -0.11616970598697662\nEpoch [219/240] Step [3000] Discriminator Loss: -0.660922110080719 Generator Loss: -0.1623927652835846\nEpoch [219/240] Step [3600] Discriminator Loss: -0.6306686997413635 Generator Loss: -0.14171093702316284\nEpoch [219/240] Step [4200] Discriminator Loss: -0.6465350389480591 Generator Loss: -0.17822737991809845\nEpoch [219/240] Step [4800] Discriminator Loss: -0.11995663493871689 Generator Loss: -0.5634081363677979\nEpoch [219/240] Step [5400] Discriminator Loss: 0.13678589463233948 Generator Loss: -0.8968058228492737\nEpoch [219/240] Step [6000] Discriminator Loss: -0.12517483532428741 Generator Loss: 0.03328485041856766\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  92%|█████████▏| 220/240 [2:21:38<12:49, 38.49s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [219/240] Avg Discriminator Loss: -0.4410449210349675 Avg Generator Loss: -0.22091988585684652\nEpoch [220/240] Step [0] Discriminator Loss: -0.6385332942008972 Generator Loss: -0.022339675575494766\nEpoch [220/240] Step [600] Discriminator Loss: -0.9097187519073486 Generator Loss: 0.013536153361201286\nEpoch [220/240] Step [1200] Discriminator Loss: -0.22023725509643555 Generator Loss: -0.19950860738754272\nEpoch [220/240] Step [1800] Discriminator Loss: -0.6490838527679443 Generator Loss: -0.047149766236543655\nEpoch [220/240] Step [2400] Discriminator Loss: -0.30304867029190063 Generator Loss: -0.2254638373851776\nEpoch [220/240] Step [3000] Discriminator Loss: -0.83603835105896 Generator Loss: -0.051104746758937836\nEpoch [220/240] Step [3600] Discriminator Loss: -0.5100987553596497 Generator Loss: -0.18219859898090363\nEpoch [220/240] Step [4200] Discriminator Loss: -0.7337096929550171 Generator Loss: -0.061386220157146454\nEpoch [220/240] Step [4800] Discriminator Loss: -0.7568392753601074 Generator Loss: -0.04275655746459961\nEpoch [220/240] Step [5400] Discriminator Loss: -0.4020531177520752 Generator Loss: -0.3644942343235016\nEpoch [220/240] Step [6000] Discriminator Loss: -0.23747652769088745 Generator Loss: -0.4970264732837677\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  92%|█████████▏| 221/240 [2:22:17<12:12, 38.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [220/240] Avg Discriminator Loss: -0.549943245619863 Avg Generator Loss: -0.16993926398988282\nEpoch [221/240] Step [0] Discriminator Loss: -0.5769942998886108 Generator Loss: -0.20952843129634857\nEpoch [221/240] Step [600] Discriminator Loss: -0.5565134286880493 Generator Loss: -0.2587278187274933\nEpoch [221/240] Step [1200] Discriminator Loss: -0.12243634462356567 Generator Loss: -0.24649152159690857\nEpoch [221/240] Step [1800] Discriminator Loss: -0.7093207240104675 Generator Loss: -0.2060837298631668\nEpoch [221/240] Step [2400] Discriminator Loss: -0.5348076820373535 Generator Loss: -0.11610954999923706\nEpoch [221/240] Step [3000] Discriminator Loss: -0.9187742471694946 Generator Loss: -0.026710372418165207\nEpoch [221/240] Step [3600] Discriminator Loss: -0.6801509857177734 Generator Loss: -0.15529955923557281\nEpoch [221/240] Step [4200] Discriminator Loss: -0.735775887966156 Generator Loss: -0.1101427674293518\nEpoch [221/240] Step [4800] Discriminator Loss: -0.70088791847229 Generator Loss: -0.1379995048046112\nEpoch [221/240] Step [5400] Discriminator Loss: -0.6777244806289673 Generator Loss: -0.20046135783195496\nEpoch [221/240] Step [6000] Discriminator Loss: -0.6153260469436646 Generator Loss: -0.3529965579509735\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  92%|█████████▎| 222/240 [2:22:55<11:33, 38.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [221/240] Avg Discriminator Loss: -0.6294089744051734 Avg Generator Loss: -0.17476988968954527\nEpoch [222/240] Step [0] Discriminator Loss: -0.3749975562095642 Generator Loss: -0.344818651676178\nEpoch [222/240] Step [600] Discriminator Loss: -0.5060252547264099 Generator Loss: -0.25383105874061584\nEpoch [222/240] Step [1200] Discriminator Loss: -0.699630618095398 Generator Loss: -0.1403733193874359\nEpoch [222/240] Step [1800] Discriminator Loss: -0.746147632598877 Generator Loss: -0.14255642890930176\nEpoch [222/240] Step [2400] Discriminator Loss: -0.12691105902194977 Generator Loss: -0.17754879593849182\nEpoch [222/240] Step [3000] Discriminator Loss: -0.7282388806343079 Generator Loss: -0.10504835844039917\nEpoch [222/240] Step [3600] Discriminator Loss: -0.26427915692329407 Generator Loss: -0.19043414294719696\nEpoch [222/240] Step [4200] Discriminator Loss: -0.8364125490188599 Generator Loss: 0.0007255785167217255\nEpoch [222/240] Step [4800] Discriminator Loss: -0.2260386347770691 Generator Loss: -0.43064218759536743\nEpoch [222/240] Step [5400] Discriminator Loss: 0.1424640417098999 Generator Loss: -0.34625861048698425\nEpoch [222/240] Step [6000] Discriminator Loss: -0.5530485510826111 Generator Loss: -0.10811901092529297\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  93%|█████████▎| 223/240 [2:23:34<10:55, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [222/240] Avg Discriminator Loss: -0.35697689210320566 Avg Generator Loss: -0.21133830011464083\nEpoch [223/240] Step [0] Discriminator Loss: -0.5170976519584656 Generator Loss: -0.03328489884734154\nEpoch [223/240] Step [600] Discriminator Loss: -0.5547619462013245 Generator Loss: -0.24220232665538788\nEpoch [223/240] Step [1200] Discriminator Loss: -0.4787307381629944 Generator Loss: -0.5322394371032715\nEpoch [223/240] Step [1800] Discriminator Loss: -0.37521541118621826 Generator Loss: -0.4499622583389282\nEpoch [223/240] Step [2400] Discriminator Loss: -0.5481114387512207 Generator Loss: -0.17977941036224365\nEpoch [223/240] Step [3000] Discriminator Loss: -0.6554174423217773 Generator Loss: -0.09268281608819962\nEpoch [223/240] Step [3600] Discriminator Loss: 0.08593355864286423 Generator Loss: -0.26068103313446045\nEpoch [223/240] Step [4200] Discriminator Loss: -0.7615848183631897 Generator Loss: -0.09772191941738129\nEpoch [223/240] Step [4800] Discriminator Loss: -0.8077611327171326 Generator Loss: -0.0328025296330452\nEpoch [223/240] Step [5400] Discriminator Loss: -0.4769744873046875 Generator Loss: -0.5158807039260864\nEpoch [223/240] Step [6000] Discriminator Loss: 0.14822113513946533 Generator Loss: -0.77065509557724\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  93%|█████████▎| 224/240 [2:24:13<10:17, 38.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [223/240] Avg Discriminator Loss: -0.4223689158402738 Avg Generator Loss: -0.25913449204202754\nEpoch [224/240] Step [0] Discriminator Loss: 0.2206181138753891 Generator Loss: -0.9241648316383362\nEpoch [224/240] Step [600] Discriminator Loss: 0.31134361028671265 Generator Loss: -0.5673309564590454\nEpoch [224/240] Step [1200] Discriminator Loss: -0.5929369926452637 Generator Loss: 0.04235341399908066\nEpoch [224/240] Step [1800] Discriminator Loss: 0.08185327053070068 Generator Loss: -0.0067355334758758545\nEpoch [224/240] Step [2400] Discriminator Loss: -0.7308679819107056 Generator Loss: -0.06161484122276306\nEpoch [224/240] Step [3000] Discriminator Loss: -0.5658767819404602 Generator Loss: -0.23754727840423584\nEpoch [224/240] Step [3600] Discriminator Loss: -0.7905426025390625 Generator Loss: -0.0366022102534771\nEpoch [224/240] Step [4200] Discriminator Loss: -0.6570521593093872 Generator Loss: -0.16519926488399506\nEpoch [224/240] Step [4800] Discriminator Loss: -0.9221387505531311 Generator Loss: -0.014113251119852066\nEpoch [224/240] Step [5400] Discriminator Loss: -0.8264147639274597 Generator Loss: -0.04743228852748871\nEpoch [224/240] Step [6000] Discriminator Loss: -0.8949941396713257 Generator Loss: -0.01758432760834694\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  94%|█████████▍| 225/240 [2:24:51<09:38, 38.59s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [224/240] Avg Discriminator Loss: -0.5464465228547325 Avg Generator Loss: -0.17878451585537675\nEpoch [225/240] Step [0] Discriminator Loss: -0.7850350737571716 Generator Loss: -0.07145386934280396\nEpoch [225/240] Step [600] Discriminator Loss: -0.9211643934249878 Generator Loss: -0.013904701918363571\nEpoch [225/240] Step [1200] Discriminator Loss: -0.8471423983573914 Generator Loss: -0.10361877828836441\nEpoch [225/240] Step [1800] Discriminator Loss: -0.3344617784023285 Generator Loss: -0.38078680634498596\nEpoch [225/240] Step [2400] Discriminator Loss: -0.5073916912078857 Generator Loss: -0.2704507112503052\nEpoch [225/240] Step [3000] Discriminator Loss: -0.811237096786499 Generator Loss: -0.08411314338445663\nEpoch [225/240] Step [3600] Discriminator Loss: 0.49810224771499634 Generator Loss: -0.9774855375289917\nEpoch [225/240] Step [4200] Discriminator Loss: 0.2883732318878174 Generator Loss: -0.7817102670669556\nEpoch [225/240] Step [4800] Discriminator Loss: -0.04729671776294708 Generator Loss: -0.06698326021432877\nEpoch [225/240] Step [5400] Discriminator Loss: -0.4452226459980011 Generator Loss: -0.0992160215973854\nEpoch [225/240] Step [6000] Discriminator Loss: 0.390857994556427 Generator Loss: -0.011546282097697258\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  94%|█████████▍| 226/240 [2:25:30<09:00, 38.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [225/240] Avg Discriminator Loss: -0.26098001707386187 Avg Generator Loss: -0.3190209669378269\nEpoch [226/240] Step [0] Discriminator Loss: -0.6573148965835571 Generator Loss: -0.0882108062505722\nEpoch [226/240] Step [600] Discriminator Loss: -0.4136953353881836 Generator Loss: -0.1287948489189148\nEpoch [226/240] Step [1200] Discriminator Loss: -0.7595314979553223 Generator Loss: -0.09995788335800171\nEpoch [226/240] Step [1800] Discriminator Loss: -0.7967333793640137 Generator Loss: -0.08271237462759018\nEpoch [226/240] Step [2400] Discriminator Loss: -0.7628048062324524 Generator Loss: -0.058242883533239365\nEpoch [226/240] Step [3000] Discriminator Loss: -0.8830207586288452 Generator Loss: -0.05431663990020752\nEpoch [226/240] Step [3600] Discriminator Loss: -0.4131966233253479 Generator Loss: -0.26036930084228516\nEpoch [226/240] Step [4200] Discriminator Loss: -0.5995591282844543 Generator Loss: -0.18671289086341858\nEpoch [226/240] Step [4800] Discriminator Loss: -0.6898022294044495 Generator Loss: -0.14417582750320435\nEpoch [226/240] Step [5400] Discriminator Loss: -0.6562680006027222 Generator Loss: -0.16627272963523865\nEpoch [226/240] Step [6000] Discriminator Loss: -0.28159523010253906 Generator Loss: -0.23592308163642883\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  95%|█████████▍| 227/240 [2:26:08<08:20, 38.51s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [226/240] Avg Discriminator Loss: -0.5179423167755752 Avg Generator Loss: -0.1634235589086136\nEpoch [227/240] Step [0] Discriminator Loss: -0.4371348023414612 Generator Loss: -0.3166563808917999\nEpoch [227/240] Step [600] Discriminator Loss: -0.7526341676712036 Generator Loss: -0.06563195586204529\nEpoch [227/240] Step [1200] Discriminator Loss: -0.713654637336731 Generator Loss: -0.10819514095783234\nEpoch [227/240] Step [1800] Discriminator Loss: -0.1387529969215393 Generator Loss: -0.5024545788764954\nEpoch [227/240] Step [2400] Discriminator Loss: -0.6408126950263977 Generator Loss: -0.17343589663505554\nEpoch [227/240] Step [3000] Discriminator Loss: -0.7282320261001587 Generator Loss: -0.13826589286327362\nEpoch [227/240] Step [3600] Discriminator Loss: -0.003989405930042267 Generator Loss: -0.8288657665252686\nEpoch [227/240] Step [4200] Discriminator Loss: -0.5149745941162109 Generator Loss: -0.014327719807624817\nEpoch [227/240] Step [4800] Discriminator Loss: 0.020568370819091797 Generator Loss: -0.21187403798103333\nEpoch [227/240] Step [5400] Discriminator Loss: -0.7885826826095581 Generator Loss: -0.09248153865337372\nEpoch [227/240] Step [6000] Discriminator Loss: -0.21384963393211365 Generator Loss: -0.5954656004905701\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  95%|█████████▌| 228/240 [2:26:47<07:42, 38.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [227/240] Avg Discriminator Loss: -0.35524927358050923 Avg Generator Loss: -0.2960903467644593\nEpoch [228/240] Step [0] Discriminator Loss: -0.5492320656776428 Generator Loss: -0.12376359105110168\nEpoch [228/240] Step [600] Discriminator Loss: -0.7474014759063721 Generator Loss: -0.13864190876483917\nEpoch [228/240] Step [1200] Discriminator Loss: -0.7828932404518127 Generator Loss: -0.03997933864593506\nEpoch [228/240] Step [1800] Discriminator Loss: -0.7628329396247864 Generator Loss: -0.10402635484933853\nEpoch [228/240] Step [2400] Discriminator Loss: -0.04568284749984741 Generator Loss: -0.22056037187576294\nEpoch [228/240] Step [3000] Discriminator Loss: -0.7503727674484253 Generator Loss: -0.08936356753110886\nEpoch [228/240] Step [3600] Discriminator Loss: -0.488653302192688 Generator Loss: -0.13763995468616486\nEpoch [228/240] Step [4200] Discriminator Loss: -0.7891726493835449 Generator Loss: -0.0744759663939476\nEpoch [228/240] Step [4800] Discriminator Loss: -0.8084691166877747 Generator Loss: -0.08473531901836395\nEpoch [228/240] Step [5400] Discriminator Loss: -0.5988092422485352 Generator Loss: -0.17218659818172455\nEpoch [228/240] Step [6000] Discriminator Loss: -0.8028982281684875 Generator Loss: -0.07213564962148666\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  95%|█████████▌| 229/240 [2:27:25<07:04, 38.56s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [228/240] Avg Discriminator Loss: -0.6328776332757848 Avg Generator Loss: -0.16448246401772176\nEpoch [229/240] Step [0] Discriminator Loss: 0.2255861759185791 Generator Loss: -0.9290026426315308\nEpoch [229/240] Step [600] Discriminator Loss: -0.1482679843902588 Generator Loss: -0.16585524380207062\nEpoch [229/240] Step [1200] Discriminator Loss: -0.6638768911361694 Generator Loss: -0.07465419918298721\nEpoch [229/240] Step [1800] Discriminator Loss: -0.5651138424873352 Generator Loss: -0.06010332331061363\nEpoch [229/240] Step [2400] Discriminator Loss: 0.21769580245018005 Generator Loss: -0.10921631753444672\nEpoch [229/240] Step [3000] Discriminator Loss: -0.7499774694442749 Generator Loss: -0.12778453528881073\nEpoch [229/240] Step [3600] Discriminator Loss: -0.8662806153297424 Generator Loss: -0.02662729285657406\nEpoch [229/240] Step [4200] Discriminator Loss: 0.2576848864555359 Generator Loss: -0.4702662229537964\nEpoch [229/240] Step [4800] Discriminator Loss: -0.34045830368995667 Generator Loss: -0.4642799496650696\nEpoch [229/240] Step [5400] Discriminator Loss: -0.30375146865844727 Generator Loss: -0.4203110337257385\nEpoch [229/240] Step [6000] Discriminator Loss: -0.6465535163879395 Generator Loss: -0.20858658850193024\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  96%|█████████▌| 230/240 [2:28:04<06:25, 38.57s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [229/240] Avg Discriminator Loss: -0.4950939925326096 Avg Generator Loss: -0.18818760809962784\nEpoch [230/240] Step [0] Discriminator Loss: -0.2883130609989166 Generator Loss: -0.5120404362678528\nEpoch [230/240] Step [600] Discriminator Loss: -0.7091840505599976 Generator Loss: -0.16764388978481293\nEpoch [230/240] Step [1200] Discriminator Loss: -0.7724621295928955 Generator Loss: -0.06315259635448456\nEpoch [230/240] Step [1800] Discriminator Loss: -0.7838558554649353 Generator Loss: -0.13532577455043793\nEpoch [230/240] Step [2400] Discriminator Loss: -0.8330926299095154 Generator Loss: -0.06799369305372238\nEpoch [230/240] Step [3000] Discriminator Loss: -0.5920329093933105 Generator Loss: -0.26943710446357727\nEpoch [230/240] Step [3600] Discriminator Loss: -0.5378472805023193 Generator Loss: -0.13136518001556396\nEpoch [230/240] Step [4200] Discriminator Loss: -0.6603959202766418 Generator Loss: -0.1797996461391449\nEpoch [230/240] Step [4800] Discriminator Loss: -0.8110940456390381 Generator Loss: -0.09283383935689926\nEpoch [230/240] Step [5400] Discriminator Loss: -0.6569673418998718 Generator Loss: -0.1699363887310028\nEpoch [230/240] Step [6000] Discriminator Loss: -0.524645209312439 Generator Loss: -0.3255751430988312\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  96%|█████████▋| 231/240 [2:28:43<05:47, 38.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [230/240] Avg Discriminator Loss: -0.6032685572520281 Avg Generator Loss: -0.2095138493707001\nEpoch [231/240] Step [0] Discriminator Loss: -0.4847065508365631 Generator Loss: -0.30660828948020935\nEpoch [231/240] Step [600] Discriminator Loss: -0.7540940046310425 Generator Loss: -0.026586167514324188\nEpoch [231/240] Step [1200] Discriminator Loss: -0.8056576251983643 Generator Loss: -0.05755177140235901\nEpoch [231/240] Step [1800] Discriminator Loss: -0.6984012722969055 Generator Loss: -0.1233506128191948\nEpoch [231/240] Step [2400] Discriminator Loss: -0.7153195738792419 Generator Loss: -0.12937340140342712\nEpoch [231/240] Step [3000] Discriminator Loss: -0.22466568648815155 Generator Loss: -0.3736523389816284\nEpoch [231/240] Step [3600] Discriminator Loss: 0.33810219168663025 Generator Loss: -0.3757386803627014\nEpoch [231/240] Step [4200] Discriminator Loss: -0.7651574015617371 Generator Loss: -0.09850262105464935\nEpoch [231/240] Step [4800] Discriminator Loss: -0.49699336290359497 Generator Loss: -0.1527806520462036\nEpoch [231/240] Step [5400] Discriminator Loss: -0.8487138152122498 Generator Loss: -0.05837010592222214\nEpoch [231/240] Step [6000] Discriminator Loss: -0.8105300068855286 Generator Loss: -0.054337985813617706\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  97%|█████████▋| 232/240 [2:29:21<05:07, 38.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [231/240] Avg Discriminator Loss: -0.5123829478636767 Avg Generator Loss: -0.15558025558844155\nEpoch [232/240] Step [0] Discriminator Loss: -0.5266399383544922 Generator Loss: -0.27738261222839355\nEpoch [232/240] Step [600] Discriminator Loss: -0.6265362501144409 Generator Loss: -0.19322144985198975\nEpoch [232/240] Step [1200] Discriminator Loss: -0.8004626631736755 Generator Loss: -0.0661778450012207\nEpoch [232/240] Step [1800] Discriminator Loss: -0.5014166235923767 Generator Loss: -0.330841988325119\nEpoch [232/240] Step [2400] Discriminator Loss: -0.5957593321800232 Generator Loss: -0.19011950492858887\nEpoch [232/240] Step [3000] Discriminator Loss: -0.7055182456970215 Generator Loss: -0.08720437437295914\nEpoch [232/240] Step [3600] Discriminator Loss: -0.7727871537208557 Generator Loss: -0.04317343235015869\nEpoch [232/240] Step [4200] Discriminator Loss: -0.8605082035064697 Generator Loss: -0.021075665950775146\nEpoch [232/240] Step [4800] Discriminator Loss: -0.7593011856079102 Generator Loss: -0.050416842103004456\nEpoch [232/240] Step [5400] Discriminator Loss: -0.34068411588668823 Generator Loss: -0.5292916297912598\nEpoch [232/240] Step [6000] Discriminator Loss: -0.4279631972312927 Generator Loss: -0.30954709649086\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  97%|█████████▋| 233/240 [2:30:00<04:29, 38.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [232/240] Avg Discriminator Loss: -0.5272826634811394 Avg Generator Loss: -0.21961393475450658\nEpoch [233/240] Step [0] Discriminator Loss: -0.4725717604160309 Generator Loss: -0.27591773867607117\nEpoch [233/240] Step [600] Discriminator Loss: -0.7899957299232483 Generator Loss: -0.11527606844902039\nEpoch [233/240] Step [1200] Discriminator Loss: -0.2675882577896118 Generator Loss: -0.212826669216156\nEpoch [233/240] Step [1800] Discriminator Loss: -0.270971417427063 Generator Loss: -0.41220608353614807\nEpoch [233/240] Step [2400] Discriminator Loss: -0.7300624251365662 Generator Loss: -0.1387043297290802\nEpoch [233/240] Step [3000] Discriminator Loss: -0.6943808794021606 Generator Loss: -0.17463862895965576\nEpoch [233/240] Step [3600] Discriminator Loss: -0.6664062142372131 Generator Loss: -0.18773861229419708\nEpoch [233/240] Step [4200] Discriminator Loss: -0.6296155452728271 Generator Loss: -0.19397592544555664\nEpoch [233/240] Step [4800] Discriminator Loss: 0.6459513306617737 Generator Loss: -0.9641884565353394\nEpoch [233/240] Step [5400] Discriminator Loss: 0.38703274726867676 Generator Loss: -0.9605690240859985\nEpoch [233/240] Step [6000] Discriminator Loss: 0.25127002596855164 Generator Loss: -0.9727286696434021\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  98%|█████████▊| 234/240 [2:30:38<03:51, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [233/240] Avg Discriminator Loss: -0.160614767517799 Avg Generator Loss: -0.4202559615584302\nEpoch [234/240] Step [0] Discriminator Loss: 0.30538037419319153 Generator Loss: -0.9529288411140442\nEpoch [234/240] Step [600] Discriminator Loss: -0.3765910267829895 Generator Loss: -0.020470909774303436\nEpoch [234/240] Step [1200] Discriminator Loss: -0.1131351888179779 Generator Loss: -0.3264048099517822\nEpoch [234/240] Step [1800] Discriminator Loss: -0.17772474884986877 Generator Loss: -0.02295367605984211\nEpoch [234/240] Step [2400] Discriminator Loss: -0.6767799854278564 Generator Loss: -0.06302373111248016\nEpoch [234/240] Step [3000] Discriminator Loss: -0.7457634806632996 Generator Loss: -0.0687493085861206\nEpoch [234/240] Step [3600] Discriminator Loss: 0.5902153849601746 Generator Loss: -0.16217969357967377\nEpoch [234/240] Step [4200] Discriminator Loss: -0.1936318278312683 Generator Loss: -0.3392522931098938\nEpoch [234/240] Step [4800] Discriminator Loss: -0.06947070360183716 Generator Loss: -0.39454084634780884\nEpoch [234/240] Step [5400] Discriminator Loss: -0.46643394231796265 Generator Loss: -0.24057115614414215\nEpoch [234/240] Step [6000] Discriminator Loss: -0.6875279545783997 Generator Loss: -0.1462220847606659\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  98%|█████████▊| 235/240 [2:31:16<03:12, 38.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [234/240] Avg Discriminator Loss: -0.31612222217323577 Avg Generator Loss: -0.21632802959415556\nEpoch [235/240] Step [0] Discriminator Loss: 0.22989431023597717 Generator Loss: -0.20481286942958832\nEpoch [235/240] Step [600] Discriminator Loss: -0.7289219498634338 Generator Loss: -0.019990988075733185\nEpoch [235/240] Step [1200] Discriminator Loss: 0.2621733248233795 Generator Loss: -0.7663605809211731\nEpoch [235/240] Step [1800] Discriminator Loss: -0.5426160097122192 Generator Loss: -0.10185647010803223\nEpoch [235/240] Step [2400] Discriminator Loss: -0.5237851142883301 Generator Loss: -0.011105367913842201\nEpoch [235/240] Step [3000] Discriminator Loss: -0.829147458076477 Generator Loss: -0.013047633692622185\nEpoch [235/240] Step [3600] Discriminator Loss: -0.5342021584510803 Generator Loss: -0.1477046012878418\nEpoch [235/240] Step [4200] Discriminator Loss: -0.8547191619873047 Generator Loss: -0.06641044467687607\nEpoch [235/240] Step [4800] Discriminator Loss: -0.1635943055152893 Generator Loss: -0.06193957105278969\nEpoch [235/240] Step [5400] Discriminator Loss: -0.8097341060638428 Generator Loss: -0.06061035022139549\nEpoch [235/240] Step [6000] Discriminator Loss: -0.6829718351364136 Generator Loss: -0.31779003143310547\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  98%|█████████▊| 236/240 [2:31:55<02:33, 38.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [235/240] Avg Discriminator Loss: -0.5113899112293572 Avg Generator Loss: -0.18565439682917825\nEpoch [236/240] Step [0] Discriminator Loss: -0.40415453910827637 Generator Loss: -0.05800769478082657\nEpoch [236/240] Step [600] Discriminator Loss: -0.5977262258529663 Generator Loss: -0.14179843664169312\nEpoch [236/240] Step [1200] Discriminator Loss: 0.1136963963508606 Generator Loss: -0.43946540355682373\nEpoch [236/240] Step [1800] Discriminator Loss: -0.8103711009025574 Generator Loss: -0.0566411092877388\nEpoch [236/240] Step [2400] Discriminator Loss: -0.484150767326355 Generator Loss: -0.07274322211742401\nEpoch [236/240] Step [3000] Discriminator Loss: -0.683998167514801 Generator Loss: -0.14243659377098083\nEpoch [236/240] Step [3600] Discriminator Loss: -0.09953784942626953 Generator Loss: -0.1771111935377121\nEpoch [236/240] Step [4200] Discriminator Loss: -0.773064911365509 Generator Loss: -0.09861880540847778\nEpoch [236/240] Step [4800] Discriminator Loss: -0.45038050413131714 Generator Loss: -0.2983701527118683\nEpoch [236/240] Step [5400] Discriminator Loss: -0.13734757900238037 Generator Loss: -0.45571061968803406\nEpoch [236/240] Step [6000] Discriminator Loss: -0.7574477791786194 Generator Loss: -0.08892624080181122\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  99%|█████████▉| 237/240 [2:32:34<01:55, 38.57s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [236/240] Avg Discriminator Loss: -0.5960680227794927 Avg Generator Loss: -0.14654722398030998\nEpoch [237/240] Step [0] Discriminator Loss: -0.6867853403091431 Generator Loss: -0.31236687302589417\nEpoch [237/240] Step [600] Discriminator Loss: -0.6649764180183411 Generator Loss: -0.09098292887210846\nEpoch [237/240] Step [1200] Discriminator Loss: -0.5285337567329407 Generator Loss: -0.36380714178085327\nEpoch [237/240] Step [1800] Discriminator Loss: -0.7757992148399353 Generator Loss: -0.11038610339164734\nEpoch [237/240] Step [2400] Discriminator Loss: 0.2189663052558899 Generator Loss: -0.3900255262851715\nEpoch [237/240] Step [3000] Discriminator Loss: -0.6616202592849731 Generator Loss: -0.17705795168876648\nEpoch [237/240] Step [3600] Discriminator Loss: -0.4484556317329407 Generator Loss: -0.3964306712150574\nEpoch [237/240] Step [4200] Discriminator Loss: -0.247954860329628 Generator Loss: -0.49040064215660095\nEpoch [237/240] Step [4800] Discriminator Loss: -0.6963397860527039 Generator Loss: -0.11946561932563782\nEpoch [237/240] Step [5400] Discriminator Loss: -0.702335000038147 Generator Loss: -0.21513326466083527\nEpoch [237/240] Step [6000] Discriminator Loss: -0.58452308177948 Generator Loss: -0.3543758690357208\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  99%|█████████▉| 238/240 [2:33:12<01:17, 38.55s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [237/240] Avg Discriminator Loss: -0.5098065369840943 Avg Generator Loss: -0.22001728458473316\nEpoch [238/240] Step [0] Discriminator Loss: -0.49041974544525146 Generator Loss: -0.3383527994155884\nEpoch [238/240] Step [600] Discriminator Loss: -0.7590556740760803 Generator Loss: -0.1223672553896904\nEpoch [238/240] Step [1200] Discriminator Loss: -0.6684762835502625 Generator Loss: -0.15734589099884033\nEpoch [238/240] Step [1800] Discriminator Loss: -0.8544725179672241 Generator Loss: -0.04877302050590515\nEpoch [238/240] Step [2400] Discriminator Loss: -0.7087993621826172 Generator Loss: -0.07164695858955383\nEpoch [238/240] Step [3000] Discriminator Loss: -0.2836955487728119 Generator Loss: -0.3050934076309204\nEpoch [238/240] Step [3600] Discriminator Loss: -0.8175770044326782 Generator Loss: -0.0404915027320385\nEpoch [238/240] Step [4200] Discriminator Loss: -0.5283909440040588 Generator Loss: -0.39434170722961426\nEpoch [238/240] Step [4800] Discriminator Loss: -0.8235962390899658 Generator Loss: -0.05397532880306244\nEpoch [238/240] Step [5400] Discriminator Loss: -0.7445293664932251 Generator Loss: -0.1025211438536644\nEpoch [238/240] Step [6000] Discriminator Loss: -0.7780539989471436 Generator Loss: -0.09077687561511993\n","output_type":"stream"},{"name":"stderr","text":"Epochs: 100%|█████████▉| 239/240 [2:33:51<00:38, 38.57s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [238/240] Avg Discriminator Loss: -0.5969785897286384 Avg Generator Loss: -0.1592950340524152\nEpoch [239/240] Step [0] Discriminator Loss: -0.8441711664199829 Generator Loss: -0.03446711227297783\nEpoch [239/240] Step [600] Discriminator Loss: -0.7787603139877319 Generator Loss: -0.1484573632478714\nEpoch [239/240] Step [1200] Discriminator Loss: -0.47877538204193115 Generator Loss: -0.29456380009651184\nEpoch [239/240] Step [1800] Discriminator Loss: -0.17604291439056396 Generator Loss: -0.3850020170211792\nEpoch [239/240] Step [2400] Discriminator Loss: -0.5608961582183838 Generator Loss: -0.05403145030140877\nEpoch [239/240] Step [3000] Discriminator Loss: -0.8711806535720825 Generator Loss: -0.009590968489646912\nEpoch [239/240] Step [3600] Discriminator Loss: -0.7036116123199463 Generator Loss: -0.14325125515460968\nEpoch [239/240] Step [4200] Discriminator Loss: -0.6567186117172241 Generator Loss: -0.10688464343547821\nEpoch [239/240] Step [4800] Discriminator Loss: -0.7876711487770081 Generator Loss: -0.05729978159070015\nEpoch [239/240] Step [5400] Discriminator Loss: 1.287679672241211 Generator Loss: -0.41854575276374817\nEpoch [239/240] Step [6000] Discriminator Loss: -0.7141721844673157 Generator Loss: -0.11610207706689835\n","output_type":"stream"},{"name":"stderr","text":"Epochs: 100%|██████████| 240/240 [2:34:32<00:00, 38.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [239/240] Avg Discriminator Loss: -0.6015678360621571 Avg Generator Loss: -0.14322057605171815\njaqnvi\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Training finished.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nimport os\nfrom transformers import BertTokenizer, BertModel\n\n# Load the trained generator model\ngen_model = Stage1Generator().to(device)\ngen_model.load_state_dict(torch.load('generator_epoch_19.pth'))  # Load the final epoch model\ngen_model.eval()  # Set the model to evaluation mode\n\n# Function to generate image from text embedding\ndef generate_image_from_text(text_embedding, save_path):\n    # Convert the text embedding to tensor and send it to device\n    text_embedding = torch.tensor(text_embedding).unsqueeze(0).to(device)  # Add batch dimension\n\n    # Generate random noise (latent vector)\n    noise = torch.randn(1, latent_dim, device=device)  # Single noise vector for 1 image\n\n    # Generate the image using the generator\n    with torch.no_grad():\n        generated_image, _ = gen_model(text_embedding, noise)  # Pass the embedding and noise to generator\n\n    # Function to save and show the image\n    save_and_show_image(generated_image[0], save_path)\n\n# Function to save and display the generated image\ndef save_and_show_image(img, path):\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    if isinstance(img, torch.Tensor):\n        img = img.detach().permute(1, 2, 0).cpu().numpy()  # Convert CHW to HWC and move to CPU\n    ax.imshow(img)\n    ax.axis(\"off\")\n    ax.set_title(\"Generated Image from Text\")\n    \n    # Save image\n    plt.savefig(path)\n    \n    # Show image\n    plt.show()\n    \n    # Close plot to avoid memory issues\n    plt.close()\n\n# Example: Assuming you have a function to convert text into embeddings (e.g., using a pre-trained model)\ndef text_to_embedding(text):\n    # Dummy embedding for demonstration, replace this with your actual text embedding process\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    model = BertModel.from_pretrained('bert-base-uncased')\n    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n    \n    with torch.no_grad():\n                outputs = model(**inputs)\n\n            # Extract the [CLS] token embedding (for the whole sentence)\n    cls_embedding = outputs.last_hidden_state[:, 0, :]\n    \n    return cls_embedding\n\n# Generate an image based on text\ntext_description = \"white lily\"\ntext_embedding = text_to_embedding(text_description)\n\n# Directory to save generated image\noutput_dir = 'text_generated_images'\nos.makedirs(output_dir, exist_ok=True)\n\n# Generate and save the image based on the text\nimg_save_path = os.path.join(output_dir, 'generated_img_from_text.png')\ngenerate_image_from_text(text_embedding, img_save_path)\n\nprint(\"Image generation based on text complete.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T05:44:01.742528Z","iopub.execute_input":"2024-10-16T05:44:01.742941Z","iopub.status.idle":"2024-10-16T05:44:02.637043Z","shell.execute_reply.started":"2024-10-16T05:44:01.742891Z","shell.execute_reply":"2024-10-16T05:44:02.636130Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3026197346.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  gen_model.load_state_dict(torch.load('generator_epoch_19.pth'))  # Load the final epoch model\n/tmp/ipykernel_30/3026197346.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  text_embedding = torch.tensor(text_embedding).unsqueeze(0).to(device)  # Add batch dimension\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Image generation based on text complete.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}